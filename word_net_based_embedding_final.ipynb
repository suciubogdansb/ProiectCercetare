{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cZ3CwJUlEl4",
    "outputId": "39d9045c-14e8-4932-ceb5-5d0e50897f12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.66.5)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 scipy-1.15.1 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk numpy matplotlib torch tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sgVuDuUY2_i6",
    "outputId": "9a4877a3-60d5-48fd-ed92-aad63c02d6e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipdb\n",
      "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: ipython>=7.31.1 in /opt/conda/lib/python3.11/site-packages (from ipdb) (8.29.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipdb) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.31.1->ipdb) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.31.1->ipdb) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.31.1->ipdb) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=7.31.1->ipdb) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=7.31.1->ipdb) (1.16.0)\n",
      "Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: ipdb\n",
      "Successfully installed ipdb-0.13.13\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nGOQf0UoT2a",
    "outputId": "4a20f400-afcc-4f03-b913-0d345e4e77b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet2022 to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet2022, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet2022')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "_A3iUC7CIHG8"
   },
   "outputs": [],
   "source": [
    "lema = WordNetLemmatizer()\n",
    "stopword = set(stopwords.words('english'))\n",
    "\n",
    "def process_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lema.lemmatize(token) for token in tokens if token.isalpha() and token not in stopword]\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "id": "x4kwZ-aTqF-d"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "\n",
    "def build_wordnet_vocab(max_synsets_per_pos=None):\n",
    "    vocab = set()\n",
    "    definitions = {}\n",
    "\n",
    "    poses = ['a', 'r', 's', 'v', 'n']\n",
    "\n",
    "    for pos in poses:\n",
    "        for i, synset in enumerate(wn.all_synsets(pos)):\n",
    "            if max_synsets_per_pos is not None and i >= max_synsets_per_pos:\n",
    "                break\n",
    "\n",
    "            word = synset.name().split('.')[0]\n",
    "            gloss = synset.definition()\n",
    "            tokens = process_text(gloss)\n",
    "            if not tokens:\n",
    "                continue\n",
    "            definitions[word] = tokens\n",
    "            vocab.update(tokens + [word])\n",
    "\n",
    "    # Introduce <UNK> token\n",
    "    vocab.add('<UNK>')\n",
    "\n",
    "    word_to_id = {word: idx for idx, word in enumerate(sorted(vocab))}\n",
    "    id_to_word = {idx: word for word, idx in word_to_id.items()}\n",
    "    return definitions, word_to_id, id_to_word\n",
    "\n",
    "definitions, word_to_id, id_to_word = build_wordnet_vocab()\n",
    "\n",
    "# Initialize embeddings randomly (will later load pre-trained embeddings if available)\n",
    "vocab_size = len(word_to_id)\n",
    "embedding_dim = 300  # Define embedding size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8UmDh2ekqrNH",
    "outputId": "d6283bbf-8e17-482e-cfdd-c63719e3e08b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96081"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ZDo6pd1FIfAk",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "501712cb-eb1e-41b7-e1f8-9d93cadc0d08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'able': ['usually',\n",
       "  'followed',\n",
       "  'necessary',\n",
       "  'mean',\n",
       "  'skill',\n",
       "  'authority',\n",
       "  'something'],\n",
       " 'unable': ['usually', 'followed', 'necessary', 'mean', 'skill'],\n",
       " 'abaxial': ['facing', 'away', 'axis', 'organ', 'organism'],\n",
       " 'adaxial': ['nearest', 'facing', 'toward', 'axis', 'organ', 'organism'],\n",
       " 'acroscopic': ['facing', 'side', 'toward', 'apex'],\n",
       " 'basiscopic': ['facing', 'side', 'toward', 'base'],\n",
       " 'abducent': ['especially',\n",
       "  'muscle',\n",
       "  'drawing',\n",
       "  'away',\n",
       "  'midline',\n",
       "  'body',\n",
       "  'adjacent',\n",
       "  'part'],\n",
       " 'adducent': ['especially',\n",
       "  'muscle',\n",
       "  'bringing',\n",
       "  'together',\n",
       "  'drawing',\n",
       "  'toward',\n",
       "  'midline',\n",
       "  'body',\n",
       "  'toward',\n",
       "  'adjacent',\n",
       "  'part'],\n",
       " 'nascent': ['born', 'beginning'],\n",
       " 'emergent': ['coming', 'existence'],\n",
       " 'dissilient': ['bursting', 'open', 'force', 'ripe', 'seed', 'vessel'],\n",
       " 'parturient': ['giving', 'birth'],\n",
       " 'dying': ['associated', 'process', 'passing', 'life', 'ceasing'],\n",
       " 'moribund': ['point', 'death', 'breathing', 'last'],\n",
       " 'last': ['occurring', 'time', 'death'],\n",
       " 'abridged': ['used', 'text', 'shortened', 'condensing', 'rewriting'],\n",
       " 'cut': ['unexcused', 'absence', 'class'],\n",
       " 'half-length': ['abridged', 'half', 'original', 'length'],\n",
       " 'potted': ['british', 'informal', 'summarized', 'abridged'],\n",
       " 'unabridged': ['used', 'text', 'shortened'],\n",
       " 'full-length': ['complete'],\n",
       " 'absolute': ['perfect', 'complete', 'pure'],\n",
       " 'direct': ['lacking', 'compromising', 'mitigating', 'element', 'exact'],\n",
       " 'implicit': ['without', 'doubt', 'reserve'],\n",
       " 'infinite': ['total'],\n",
       " 'living': ['informal', 'absolute'],\n",
       " 'relative': ['estimated', 'comparison', 'absolute', 'complete'],\n",
       " 'relational': ['relation', 'related'],\n",
       " 'absorbent': ['power',\n",
       "  'capacity',\n",
       "  'tendency',\n",
       "  'absorb',\n",
       "  'soak',\n",
       "  'something',\n",
       "  'liquid',\n",
       "  'energy',\n",
       "  'etc'],\n",
       " 'absorbefacient': ['inducing', 'promoting', 'absorption'],\n",
       " 'assimilating': ['capable',\n",
       "  'taking',\n",
       "  'gas',\n",
       "  'light',\n",
       "  'liquid',\n",
       "  'solution',\n",
       "  'assimilative',\n",
       "  'substance'],\n",
       " 'hygroscopic': ['absorbing', 'moisture', 'air'],\n",
       " 'receptive': ['able', 'absorb', 'liquid', 'repellent'],\n",
       " 'shock-absorbent': ['capacity', 'absorb', 'energy', 'impact'],\n",
       " 'spongy': ['like',\n",
       "  'sponge',\n",
       "  'able',\n",
       "  'absorb',\n",
       "  'liquid',\n",
       "  'yield',\n",
       "  'back',\n",
       "  'compressed'],\n",
       " 'thirsty': ['able', 'take', 'large', 'quantity', 'moisture'],\n",
       " 'nonabsorbent': ['capable', 'absorbing', 'soaking', 'liquid'],\n",
       " 'repellent': ['incapable', 'absorbing', 'mixing'],\n",
       " 'adsorbent': ['capacity',\n",
       "  'tendency',\n",
       "  'adsorb',\n",
       "  'cause',\n",
       "  'accumulate',\n",
       "  'surface'],\n",
       " 'chemisorptive': ['capacity',\n",
       "  'adsorb',\n",
       "  'chemical',\n",
       "  'contrasted',\n",
       "  'physical',\n",
       "  'force'],\n",
       " 'nonadsorbent': ['lacking',\n",
       "  'capacity',\n",
       "  'adsorb',\n",
       "  'cause',\n",
       "  'accumulate',\n",
       "  'surface'],\n",
       " 'absorbable': ['capable', 'absorbed', 'taken', 'pore', 'surface'],\n",
       " 'adsorbable': ['capable', 'adsorbed', 'accumulated', 'surface', 'solid'],\n",
       " 'abstemious': ['sparing',\n",
       "  'consumption',\n",
       "  'especially',\n",
       "  'food',\n",
       "  'drink',\n",
       "  'john',\n",
       "  'galsworthy'],\n",
       " 'abstinent': ['indulging', 'appetite', 'especially', 'food', 'drink'],\n",
       " 'ascetic': ['practicing', 'great', 'william', 'james'],\n",
       " 'gluttonous': ['given',\n",
       "  'excess',\n",
       "  'consumption',\n",
       "  'especially',\n",
       "  'food',\n",
       "  'drink'],\n",
       " 'crapulous': ['given', 'gross', 'intemperance', 'eating', 'drinking'],\n",
       " 'crapulent': ['suffering', 'excessive', 'eating', 'drinking'],\n",
       " 'edacious': ['devouring', 'craving', 'food', 'great', 'quantity'],\n",
       " 'greedy': ['wanting', 'eat', 'drink', 'one', 'reasonably', 'consume'],\n",
       " 'hoggish': ['resembling', 'swine', 'coarsely', 'gluttonous', 'greedy'],\n",
       " 'overgreedy': ['excessively', 'gluttonous'],\n",
       " 'abstract': ['existing', 'mind', 'separated', 'embodiment'],\n",
       " 'conceptional': ['nature', 'notion', 'concept'],\n",
       " 'conceptual': ['characterized', 'concept', 'formation'],\n",
       " 'ideal': ['constituting',\n",
       "  'existing',\n",
       "  'form',\n",
       "  'idea',\n",
       "  'mental',\n",
       "  'image',\n",
       "  'conception'],\n",
       " 'ideological': ['concerned', 'suggestive', 'idea'],\n",
       " 'concrete': ['capable', 'perceived', 'sens', 'abstract', 'imaginary'],\n",
       " 'objective': ['belonging',\n",
       "  'immediate',\n",
       "  'experience',\n",
       "  'actual',\n",
       "  'thing',\n",
       "  'event'],\n",
       " 'real': ['capable', 'treated', 'fact'],\n",
       " 'abundant': ['present', 'great', 'quantity'],\n",
       " 'abounding': ['existing', 'abundance'],\n",
       " 'ample': ['affording', 'abundant', 'supply'],\n",
       " 'copious': ['large', 'number', 'quantity', 'especially', 'discourse'],\n",
       " 'easy': ['obtained',\n",
       "  'little',\n",
       "  'effort',\n",
       "  'sacrifice',\n",
       "  'often',\n",
       "  'obtained',\n",
       "  'illegally'],\n",
       " 'exuberant': ['produced', 'growing', 'extreme', 'abundance'],\n",
       " 'thick': ['abounding', 'lot'],\n",
       " 'long': ['normal', 'necessary'],\n",
       " 'overabundant': ['excessively', 'abundant'],\n",
       " 'plentiful': ['existing', 'great', 'number', 'quantity'],\n",
       " 'rampant': ['plant', 'lush', 'unchecked', 'growth'],\n",
       " 'rank': ['growing', 'profusely'],\n",
       " 'superabundant': ['excessively', 'abundant'],\n",
       " 'teeming': ['abundantly', 'filled', 'especially', 'living', 'thing'],\n",
       " 'torrential': ['pouring', 'abundance'],\n",
       " 'verdant': ['characterized', 'abundance', 'verdure'],\n",
       " 'scarce': ['deficient', 'quantity', 'number', 'compared', 'demand'],\n",
       " 'rare': ['widely', 'distributed'],\n",
       " 'tight': ['affected', 'scarcity', 'expensive', 'borrow'],\n",
       " 'abused': ['subjected', 'cruel', 'treatment'],\n",
       " 'battered': ['exhibiting',\n",
       "  'symptom',\n",
       "  'resulting',\n",
       "  'repeated',\n",
       "  'physical',\n",
       "  'emotional',\n",
       "  'injury'],\n",
       " 'unabused': ['physically', 'abused', 'treated', 'properly'],\n",
       " 'acceptable': ['worthy', 'acceptance', 'satisfactory'],\n",
       " 'bankable': ['acceptable', 'bank'],\n",
       " 'unexceptionable': ['completely',\n",
       "  'acceptable',\n",
       "  'open',\n",
       "  'exception',\n",
       "  'reproach'],\n",
       " 'unobjectionable': ['objectionable'],\n",
       " 'unacceptable': ['acceptable', 'welcome'],\n",
       " 'exceptionable': ['liable',\n",
       "  'objection',\n",
       "  'debate',\n",
       "  'used',\n",
       "  'something',\n",
       "  'one',\n",
       "  'might',\n",
       "  'take',\n",
       "  'exception'],\n",
       " 'accessible': ['capable', 'reached'],\n",
       " 'approachable': ['easily', 'approached'],\n",
       " 'come-at-able': ['capable', 'reached', 'attained'],\n",
       " 'handy': ['skillful', 'hand'],\n",
       " 'inaccessible': ['capable', 'reached', 'great', 'difficulty'],\n",
       " 'outback': ['inaccessible', 'sparsely', 'populated'],\n",
       " 'pathless': ['lacking', 'pathway'],\n",
       " 'unapproachable': ['inaccessibly', 'located', 'situated'],\n",
       " 'un-come-at-able': ['difficult', 'reach', 'attain'],\n",
       " 'accommodating': ['helpful', 'bringing', 'harmonious', 'adaptation'],\n",
       " 'complaisant': ['showing', 'cheerful', 'willingness', 'favor', 'others'],\n",
       " 'unaccommodating': ['accommodating'],\n",
       " 'disobliging': ['intentionally', 'unaccommodating'],\n",
       " 'accurate': ['conforming',\n",
       "  'exactly',\n",
       "  'almost',\n",
       "  'exactly',\n",
       "  'fact',\n",
       "  'standard',\n",
       "  'performing',\n",
       "  'total',\n",
       "  'accuracy'],\n",
       " 'close': ['marked', 'fidelity', 'original'],\n",
       " 'dead-on': ['accurate', 'point', 'peter'],\n",
       " 'high-fidelity': ['characterized',\n",
       "  'minimal',\n",
       "  'distortion',\n",
       "  'sound',\n",
       "  'reproduction'],\n",
       " 'surgical': ['performed', 'great', 'precision'],\n",
       " 'straight': ['keeping', 'fact'],\n",
       " 'true': ['accurately', 'placed', 'thrown'],\n",
       " 'veracious': ['precisely', 'accurate'],\n",
       " 'inaccurate': ['exact'],\n",
       " 'away': ['baseball', 'pitch', 'far', 'side', 'home', 'plate', 'batter'],\n",
       " 'faulty': ['characterized',\n",
       "  'error',\n",
       "  'agreeing',\n",
       "  'model',\n",
       "  'following',\n",
       "  'established',\n",
       "  'rule',\n",
       "  'wrong',\n",
       "  'side',\n",
       "  'road'],\n",
       " 'unfaithful': ['trustworthy'],\n",
       " 'wide': ['target'],\n",
       " 'accustomed': ['often', 'followed', 'habit', 'adapted'],\n",
       " 'used_to': ['habit', 'henry', 'david', 'thoreau'],\n",
       " 'unaccustomed': ['habituated', 'unfamiliar'],\n",
       " 'new': ['unfamiliar'],\n",
       " 'unused': ['infrequently', 'exposed'],\n",
       " 'acidic': ['containing',\n",
       "  'acid',\n",
       "  'solution',\n",
       "  'excess',\n",
       "  'hydrogen',\n",
       "  'atom',\n",
       "  'ph',\n",
       "  'less'],\n",
       " 'acid': ['characteristic', 'acid'],\n",
       " 'acid-forming': ['yielding', 'acid', 'aqueous', 'solution'],\n",
       " 'alkaline': ['relating', 'containing', 'alkali', 'ph', 'greater'],\n",
       " 'alkalescent': ['tending', 'become', 'alkaline', 'slightly', 'alkaline'],\n",
       " 'basic': ['denoting', 'nature', 'containing', 'base'],\n",
       " 'base-forming': ['yielding', 'base', 'aqueous', 'solution'],\n",
       " 'saltlike': ['resembling',\n",
       "  'compound',\n",
       "  'formed',\n",
       "  'replacing',\n",
       "  'hydrogen',\n",
       "  'acid',\n",
       "  'metal'],\n",
       " 'amphoteric': ['characteristic',\n",
       "  'acid',\n",
       "  'base',\n",
       "  'capable',\n",
       "  'reacting',\n",
       "  'either'],\n",
       " 'acid-loving': ['thriving',\n",
       "  'relatively',\n",
       "  'acidic',\n",
       "  'environment',\n",
       "  'especially',\n",
       "  'plant',\n",
       "  'requiring',\n",
       "  'ph',\n",
       "  'well'],\n",
       " 'acidophilic': ['especially',\n",
       "  'bacteria',\n",
       "  'growing',\n",
       "  'well',\n",
       "  'acid',\n",
       "  'medium'],\n",
       " 'alkaline-loving': ['thriving',\n",
       "  'relatively',\n",
       "  'alkaline',\n",
       "  'environment',\n",
       "  'especially',\n",
       "  'plant',\n",
       "  'requiring',\n",
       "  'ph'],\n",
       " 'acknowledged': ['recognized', 'made', 'known', 'admitted'],\n",
       " 'accepted': ['generally', 'approved', 'compelling', 'recognition'],\n",
       " 'self-confessed': ['owned'],\n",
       " 'assumptive': ['accepted', 'real', 'true', 'without', 'proof'],\n",
       " 'declarable': ['must', 'declared'],\n",
       " 'given': ['acknowledged', 'supposition'],\n",
       " 'putative': ['purported',\n",
       "  'commonly',\n",
       "  'put',\n",
       "  'forth',\n",
       "  'accepted',\n",
       "  'true',\n",
       "  'inconclusive',\n",
       "  'ground'],\n",
       " 'unacknowledged': ['recognized', 'admitted'],\n",
       " 'unappreciated': ['value', 'acknowledged'],\n",
       " 'unavowed': ['openly', 'made', 'known'],\n",
       " 'unconfessed': ['admitted'],\n",
       " 'unrecognized': ['recognized'],\n",
       " 'acquisitive': ['eager',\n",
       "  'acquire',\n",
       "  'possess',\n",
       "  'thing',\n",
       "  'especially',\n",
       "  'material',\n",
       "  'possession',\n",
       "  'idea'],\n",
       " 'accumulative': ['increasing', 'successive', 'addition'],\n",
       " 'avaricious': ['immoderately', 'desirous', 'acquiring', 'wealth'],\n",
       " 'possessive': ['desirous', 'owning'],\n",
       " 'plundering': ['given', 'taking', 'force', 'desired'],\n",
       " 'predaceous': ['living',\n",
       "  'given',\n",
       "  'victimizing',\n",
       "  'others',\n",
       "  'personal',\n",
       "  'gain',\n",
       "  'peter',\n",
       "  'prescott'],\n",
       " 'rapacious': ['excessively', 'greedy', 'grasping'],\n",
       " 'sordid': ['meanly', 'avaricious', 'mercenary'],\n",
       " 'unacquisitive': ['acquisitive',\n",
       "  'interested',\n",
       "  'acquiring',\n",
       "  'owning',\n",
       "  'anything'],\n",
       " 'acropetal': ['leaf',\n",
       "  'flower',\n",
       "  'developing',\n",
       "  'opening',\n",
       "  'succession',\n",
       "  'base',\n",
       "  'apex'],\n",
       " 'basipetal': ['leaf',\n",
       "  'flower',\n",
       "  'developing',\n",
       "  'opening',\n",
       "  'succession',\n",
       "  'apex',\n",
       "  'base'],\n",
       " 'active': ['sun',\n",
       "  'characterized',\n",
       "  'increased',\n",
       "  'occurrence',\n",
       "  'sunspot',\n",
       "  'flare',\n",
       "  'radio',\n",
       "  'emission'],\n",
       " 'about': ['move'],\n",
       " 'acrobatic': ['vigorously', 'active'],\n",
       " 'agile': ['moving', 'quickly', 'lightly'],\n",
       " 'hot': ['marked', 'excited', 'activity'],\n",
       " 'hyperactive': ['active', 'normal'],\n",
       " 'on_the_go': ['person', 'busy', 'active'],\n",
       " 'sporty': ['appropriate', 'sport', 'engagement', 'sport'],\n",
       " 'inactive': ['exerting', 'influence', 'change'],\n",
       " 'desk-bound': ['restricted',\n",
       "  'working',\n",
       "  'office',\n",
       "  'rather',\n",
       "  'active',\n",
       "  'physical',\n",
       "  'capacity'],\n",
       " 'abeyant': ['inactive', 'capable', 'becoming', 'active'],\n",
       " 'hypoactive': ['abnormally', 'inactive'],\n",
       " 'inert': ['slow', 'apathetic'],\n",
       " 'sedentary': ['requiring', 'sitting', 'little', 'activity'],\n",
       " 'activated': ['rendered',\n",
       "  'active',\n",
       "  'rendered',\n",
       "  'radioactive',\n",
       "  'luminescent',\n",
       "  'photosensitive',\n",
       "  'conductive'],\n",
       " 'off': ['performing', 'scheduled', 'duty'],\n",
       " 'retired': ['longer', 'active', 'work', 'profession'],\n",
       " 'brisk': ['active'],\n",
       " 'bustling': ['full', 'energetic', 'noisy', 'activity'],\n",
       " 'busy': ['crowded', 'characterized', 'much', 'activity'],\n",
       " 'going': ['advancing', 'toward', 'goal'],\n",
       " 'open': ['ready', 'business'],\n",
       " 'springy': ['movement', 'light', 'confidently', 'active'],\n",
       " 'dark': ['giving', 'performance', 'closed'],\n",
       " 'dead': ['physically', 'inactive'],\n",
       " 'dull': ['business', 'active', 'brisk'],\n",
       " 'idle': ['active', 'use'],\n",
       " 'strikebound': ['closed', 'immobilized', 'strike'],\n",
       " 'progressive': ['advancing', 'severity'],\n",
       " 'dead-end': ['lacking', 'opportunity', 'development', 'advancement'],\n",
       " 'flat': ['commercially', 'inactive'],\n",
       " 'indolent': ['tumor', 'slow', 'heal', 'develop', 'usually', 'painless'],\n",
       " 'latent': ['potentially', 'existing', 'presently', 'evident', 'realized'],\n",
       " 'quiescent': ['active', 'activated'],\n",
       " 'activist': ['advocating', 'engaged', 'activism'],\n",
       " 'hands-on': ['involving', 'active', 'participation'],\n",
       " 'proactive': ['policy',\n",
       "  'person',\n",
       "  'action',\n",
       "  'controlling',\n",
       "  'situation',\n",
       "  'causing',\n",
       "  'something',\n",
       "  'happen',\n",
       "  'rather',\n",
       "  'waiting',\n",
       "  'respond',\n",
       "  'happens'],\n",
       " 'passive': ['expressing',\n",
       "  'subject',\n",
       "  'sentence',\n",
       "  'patient',\n",
       "  'action',\n",
       "  'denoted',\n",
       "  'verb'],\n",
       " 'hands-off': ['involving', 'participation', 'intervention'],\n",
       " 'resistless': ['offering', 'resistance', 'theodore', 'roosevelt'],\n",
       " 'eruptive': ['actively', 'spewing', 'lava'],\n",
       " 'dormant': ['volcano', 'erupting', 'extinct'],\n",
       " 'extinct': ['volcano', 'permanently', 'inactive'],\n",
       " 'alive': ['capable', 'erupting'],\n",
       " 'stative': ['used',\n",
       "  'verb',\n",
       "  'participial',\n",
       "  'adjective',\n",
       "  'expressing',\n",
       "  'existence',\n",
       "  'state',\n",
       "  'rather',\n",
       "  'action'],\n",
       " 'counteractive': ['opposing',\n",
       "  'neutralizing',\n",
       "  'mitigating',\n",
       "  'effect',\n",
       "  'contrary',\n",
       "  'action'],\n",
       " 'surface-active': ['capable',\n",
       "  'lowering',\n",
       "  'surface',\n",
       "  'tension',\n",
       "  'liquid',\n",
       "  'used',\n",
       "  'especially',\n",
       "  'detergent'],\n",
       " 'quiet': ['sun',\n",
       "  'characterized',\n",
       "  'low',\n",
       "  'level',\n",
       "  'surface',\n",
       "  'phenomenon',\n",
       "  'like',\n",
       "  'sunspot'],\n",
       " 'actual': ['presently',\n",
       "  'existing',\n",
       "  'fact',\n",
       "  'merely',\n",
       "  'potential',\n",
       "  'possible'],\n",
       " 'effective': ['existing', 'fact', 'theoretical', 'real'],\n",
       " 'potential': ['existing', 'possibility'],\n",
       " 'acute': ['experiencing', 'rapid', 'onset', 'short', 'severe', 'course'],\n",
       " 'subacute': ['less',\n",
       "  'acute',\n",
       "  'relating',\n",
       "  'disease',\n",
       "  'present',\n",
       "  'person',\n",
       "  'symptom'],\n",
       " 'chronic': ['recurrent', 'characterized', 'long', 'suffering'],\n",
       " 'degenerative': ['illness',\n",
       "  'marked',\n",
       "  'gradual',\n",
       "  'deterioration',\n",
       "  'organ',\n",
       "  'cell',\n",
       "  'along',\n",
       "  'loss',\n",
       "  'function'],\n",
       " 'virulent': ['infectious', 'ability', 'cause', 'disease'],\n",
       " 'highly_infective': ['microorganism', 'extremely', 'infective'],\n",
       " 'deadly': ['disease', 'rapid', 'course', 'violent', 'effect'],\n",
       " 'avirulent': ['virulent', 'unable', 'produce', 'disease'],\n",
       " 'adaptive': ['capacity', 'adaptation'],\n",
       " 'accommodative': ['tending',\n",
       "  'reconcile',\n",
       "  'accommodate',\n",
       "  'bringing',\n",
       "  'harmony'],\n",
       " 'adaptational': ['relating', 'adaptation'],\n",
       " 'adjustive': ['conducive', 'adjustment'],\n",
       " 'maladaptive': ['showing', 'faulty', 'adaptation'],\n",
       " 'dysfunctional': ['trait',\n",
       "  'condition',\n",
       "  'failing',\n",
       "  'serve',\n",
       "  'adjustive',\n",
       "  'purpose'],\n",
       " 'maladjustive': ['poorly', 'adjusted'],\n",
       " 'addicted': ['compulsively', 'physiologically', 'dependent', 'something'],\n",
       " 'alcoholic': ['addicted', 'alcohol', 'carl', 'van', 'doren'],\n",
       " 'dependent': ['addicted', 'drug'],\n",
       " 'unaddicted': ['addicted'],\n",
       " 'clean': ['free', 'clumsiness', 'precisely', 'deftly', 'executed'],\n",
       " 'addictive': ['causing', 'characterized', 'addiction'],\n",
       " 'nonaddictive': ['causing', 'characterized', 'addiction'],\n",
       " 'additive': ['characterized', 'produced', 'addition'],\n",
       " 'addable': ['capable', 'added', 'added'],\n",
       " 'extra': ['added'],\n",
       " 'complemental': ['acting',\n",
       "  'providing',\n",
       "  'complement',\n",
       "  'something',\n",
       "  'completes',\n",
       "  'whole'],\n",
       " 'incremental': ['increasing', 'gradually', 'regular', 'degree', 'addition'],\n",
       " 'intercalary': ['day',\n",
       "  'month',\n",
       "  'inserted',\n",
       "  'make',\n",
       "  'calendar',\n",
       "  'year',\n",
       "  'correspond',\n",
       "  'solar',\n",
       "  'year'],\n",
       " 'summational': ['relating', 'summation', 'produced', 'summation'],\n",
       " 'supplementary': ['added', 'complete', 'make', 'deficiency'],\n",
       " 'subtractive': ['constituting', 'involving', 'subtraction'],\n",
       " 'ablative': ['tending',\n",
       "  'ablate',\n",
       "  'removed',\n",
       "  'vaporized',\n",
       "  'high',\n",
       "  'temperature'],\n",
       " 'reductive': ['characterized', 'causing', 'diminution', 'curtailment'],\n",
       " 'addressed': ['mail', 'marked', 'destination'],\n",
       " 'self-addressed': ['addressed'],\n",
       " 'unaddressed': ['addressed'],\n",
       " 'adequate': ['requisite', 'quality', 'resource', 'meet', 'task'],\n",
       " 'adequate_to': ['requisite', 'quality'],\n",
       " 'competent': ['adequate', 'purpose'],\n",
       " 'inadequate': ['lacking', 'requisite', 'quality', 'resource', 'meet', 'task'],\n",
       " 'deficient': ['inadequate', 'amount', 'degree'],\n",
       " 'incapable': ['meeting', 'requirement'],\n",
       " 'short-handed': ['inadequate', 'number', 'worker', 'assistant', 'etc'],\n",
       " 'adhesive': ['tending', 'adhere'],\n",
       " 'adherent': ['sticking', 'fast'],\n",
       " 'agglutinate': ['united', 'glue'],\n",
       " 'bondable': ['capable',\n",
       "  'holding',\n",
       "  'together',\n",
       "  'cohering',\n",
       "  'particle',\n",
       "  'mass'],\n",
       " 'coherent': ['sticking', 'together'],\n",
       " 'cohesive': ['causing', 'cohesion'],\n",
       " 'gluey': ['sticky', 'property', 'adhesive'],\n",
       " 'gooey': ['soft', 'sticky'],\n",
       " 'gum-like': ['resembling', 'chewing', 'gum'],\n",
       " 'gummed': ['covered', 'adhesive', 'gum'],\n",
       " 'pitchy': ['characteristic', 'pitch', 'tar'],\n",
       " 'self-sealing': ['seal', 'without', 'application', 'moisture'],\n",
       " 'stick-on': ['something',\n",
       "  'paper',\n",
       "  'label',\n",
       "  'postage',\n",
       "  'stamp',\n",
       "  'gummed',\n",
       "  'advance'],\n",
       " 'sticky': ['covered', 'adhesive', 'material'],\n",
       " 'nonadhesive': ['tending', 'adhere'],\n",
       " 'nonglutinous': ['resembling', 'glue', 'texture'],\n",
       " 'nonresinous': ['resin'],\n",
       " 'ungummed': ['treated', 'adhesive', 'gum'],\n",
       " 'adjective': ['relating',\n",
       "  'court',\n",
       "  'practice',\n",
       "  'procedure',\n",
       "  'opposed',\n",
       "  'principle',\n",
       "  'law'],\n",
       " 'substantive': ['defining',\n",
       "  'right',\n",
       "  'duty',\n",
       "  'opposed',\n",
       "  'giving',\n",
       "  'rule',\n",
       "  'right',\n",
       "  'duty',\n",
       "  'established'],\n",
       " 'adoptable': ['suitable', 'eligible', 'adoption'],\n",
       " 'unadoptable': ['difficult', 'place', 'adoptive', 'home'],\n",
       " 'adorned': ['provided',\n",
       "  'something',\n",
       "  'intended',\n",
       "  'increase',\n",
       "  'beauty',\n",
       "  'distinction'],\n",
       " 'beady': ['covered', 'bead', 'jewel', 'sequin'],\n",
       " 'bedaubed': ['ornamented', 'vulgar', 'showy', 'fashion'],\n",
       " 'bespectacled': ['wearing', 'face', 'adorned', 'eyeglass', 'eyeglass'],\n",
       " 'brocaded': ['embellished',\n",
       "  'raised',\n",
       "  'pattern',\n",
       "  'created',\n",
       "  'pressure',\n",
       "  'embroidery'],\n",
       " 'buttony': ['ornamented', 'many', 'button'],\n",
       " 'carbuncled': ['set', 'carbuncle'],\n",
       " 'champleve': ['metal',\n",
       "  'area',\n",
       "  'separated',\n",
       "  'metal',\n",
       "  'filled',\n",
       "  'colored',\n",
       "  'enamel',\n",
       "  'fired'],\n",
       " 'a_cappella': ['without', 'musical', 'accompaniment'],\n",
       " 'ad': ['christian',\n",
       "  'era',\n",
       "  'used',\n",
       "  'date',\n",
       "  'supposed',\n",
       "  'year',\n",
       "  'christ',\n",
       "  'born'],\n",
       " 'ce': ['period',\n",
       "  'coinciding',\n",
       "  'christian',\n",
       "  'era',\n",
       "  'preferred',\n",
       "  'writer',\n",
       "  'christians'],\n",
       " 'bc': ['christian',\n",
       "  'era',\n",
       "  'used',\n",
       "  'following',\n",
       "  'date',\n",
       "  'supposed',\n",
       "  'year',\n",
       "  'christ',\n",
       "  'born'],\n",
       " 'bce': ['period', 'common', 'era', 'preferred', 'writer', 'christians'],\n",
       " 'horseback': ['back', 'horse'],\n",
       " 'barely': ['short', 'time'],\n",
       " 'just': ['moment', 'ago'],\n",
       " 'hardly': ['almost'],\n",
       " 'anisotropically': ['anisotropic', 'manner'],\n",
       " 'annoyingly': ['annoying', 'manner', 'annoying', 'degree'],\n",
       " 'basically': ['essence', 'bottom', 'one', 'nature'],\n",
       " 'blessedly': ['blessed', 'manner'],\n",
       " 'boiling': ['extremely'],\n",
       " 'enviably': ['enviable', 'manner'],\n",
       " 'pointedly': ['manner', 'make', 'something', 'clearly', 'evident'],\n",
       " 'negatively': ['harmful', 'manner'],\n",
       " 'kindly': ['kind', 'manner', 'kindness'],\n",
       " 'unkindly': ['unkind', 'manner', 'unkindness'],\n",
       " 'merely': ['nothing'],\n",
       " 'simply': ['absolutely', 'altogether', 'really'],\n",
       " 'plainly': ['simple', 'manner', 'without', 'extravagance', 'embellishment'],\n",
       " 'anciently': ['ancient', 'time', 'long', 'ago'],\n",
       " 'arguably': ['shown', 'argument'],\n",
       " 'unabashedly': ['unabashed', 'manner'],\n",
       " 'automatically': ['reflex', 'manner'],\n",
       " 'alarmingly': ['alarming', 'manner'],\n",
       " 'vastly': ['exceedingly', 'great', 'extent', 'degree'],\n",
       " 'grossly': ['gross', 'manner'],\n",
       " 'largely': ['large', 'part', 'mainly', 'chiefly'],\n",
       " 'significantly': ['significant', 'manner'],\n",
       " 'insignificantly': ['significant', 'degree', 'amount'],\n",
       " 'appreciably': ['noticeable', 'degree'],\n",
       " 'ultrasonically': ['ultrasonic', 'mean'],\n",
       " 'smartly': ['stylish', 'manner'],\n",
       " 'approximately': ['quantity', 'imprecise', 'fairly', 'close', 'correct'],\n",
       " 'absolutely': ['completely',\n",
       "  'without',\n",
       "  'qualification',\n",
       "  'used',\n",
       "  'informally',\n",
       "  'intensifier'],\n",
       " 'partially': ['part', 'degree', 'wholly'],\n",
       " 'half': ['partially', 'extent', 'half'],\n",
       " 'wholly': ['complete',\n",
       "  'degree',\n",
       "  'full',\n",
       "  'entire',\n",
       "  'extent',\n",
       "  'whole',\n",
       "  'often',\n",
       "  'used',\n",
       "  'informally',\n",
       "  'wholly'],\n",
       " 'entirely': ['without', 'others', 'included', 'involved'],\n",
       " 'plumb': ['exactly'],\n",
       " 'perfectly': ['perfect', 'faultless', 'way'],\n",
       " 'pat': ['completely', 'perfectly'],\n",
       " 'please': ['used', 'polite', 'request'],\n",
       " 'imperfectly': ['imperfect', 'faulty', 'way', 'jane', 'austen'],\n",
       " 'amiss': ['improper', 'mistaken', 'unfortunate', 'manner'],\n",
       " 'fully': ['greatest',\n",
       "  'degree',\n",
       "  'extent',\n",
       "  'completely',\n",
       "  'entirely',\n",
       "  'full',\n",
       "  'sense',\n",
       "  'used',\n",
       "  'combining',\n",
       "  'form'],\n",
       " 'only': ['except'],\n",
       " 'well': ['wise', 'advantageous', 'hence', 'advisable'],\n",
       " 'ill': ['unfavorably', 'disapproval'],\n",
       " 'isotropically': ['isotropic', 'manner'],\n",
       " 'badly': ['evilly', 'wickedly'],\n",
       " 'satisfactorily': ['satisfactory', 'manner'],\n",
       " 'okay': ['satisfactory',\n",
       "  'adequate',\n",
       "  'manner',\n",
       "  'alright',\n",
       "  'nonstandard',\n",
       "  'variant',\n",
       "  'right'],\n",
       " 'unsatisfactorily': ['unsatisfactory', 'manner'],\n",
       " 'prosperously': ['manner', 'prosperous', 'people'],\n",
       " 'worse': ['comparative',\n",
       "  'ill',\n",
       "  'less',\n",
       "  'effective',\n",
       "  'successful',\n",
       "  'desirable',\n",
       "  'manner'],\n",
       " 'worst': ['highest', 'degree', 'inferiority', 'badness'],\n",
       " 'even': ['full', 'extent'],\n",
       " 'even_as': ['time'],\n",
       " \"e'en\": ['even'],\n",
       " 'rather': ['great', 'small', 'extent'],\n",
       " 'quite': ['actually', 'truly', 'extreme'],\n",
       " 'always': ['time', 'event'],\n",
       " 'con_brio': ['liveliness', 'spirit'],\n",
       " 'conjecturally': ['manner',\n",
       "  'involving',\n",
       "  'inclined',\n",
       "  'conjecture',\n",
       "  'supposition'],\n",
       " 'consecutively': ['consecutive', 'manner'],\n",
       " 'constantly': ['without', 'variation', 'change', 'every', 'case'],\n",
       " 'coterminously': ['coterminous', 'manner'],\n",
       " 'never': ['certainly', 'circumstance'],\n",
       " 'occasionally': [],\n",
       " 'sometime': ['indefinite', 'unstated', 'time'],\n",
       " 'sometimes': ['certain', 'occasion', 'certain', 'case', 'always'],\n",
       " 'equally': ['degree', 'often', 'followed'],\n",
       " 'long_ago': ['distant', 'comparatively', 'distant', 'past', 'scottish'],\n",
       " 'pretty_much': ['degree'],\n",
       " 'much': [],\n",
       " 'that_much': ['certain', 'degree'],\n",
       " 'palmately': ['palmate', 'manner'],\n",
       " 'paradoxically': ['paradoxical', 'manner'],\n",
       " 'parasitically': ['parasitic', 'manner'],\n",
       " 'conformably': ['conformable', 'manner'],\n",
       " 'conventionally': ['conventional', 'manner'],\n",
       " 'unconventionally': ['unconventional', 'manner'],\n",
       " 'pathogenically': ['pathogenic', 'manner'],\n",
       " 'pictorially': ['pictorial', 'manner'],\n",
       " 'not': ['negation', 'word', 'group', 'word'],\n",
       " 'nothing': ['respect', 'degree'],\n",
       " 'no': ['referring', 'degree', 'certain', 'quality', 'present'],\n",
       " 'any': ['degree', 'extent'],\n",
       " 'none': ['way'],\n",
       " 'either': ['negative',\n",
       "  'statement',\n",
       "  'used',\n",
       "  'intensive',\n",
       "  'meaning',\n",
       "  'something',\n",
       "  'like',\n",
       "  'likewise',\n",
       "  'also'],\n",
       " 'bloody': ['extremely'],\n",
       " 'anywhere': ['place', 'anyplace', 'used', 'informally', 'anywhere'],\n",
       " 'nowhere': ['anywhere', 'place'],\n",
       " 'somewhere': ['place', 'someplace', 'used', 'informally', 'somewhere'],\n",
       " 'everywhere': ['place', 'everyplace', 'used', 'informally', 'everywhere'],\n",
       " 'high_and_low': ['everywhere'],\n",
       " 'somehow': ['unspecified', 'reason'],\n",
       " 'anyhow': ['way', 'whatsoever'],\n",
       " 'as_it_is': ['actual', 'state', 'affair', 'often', 'contrary', 'expectation'],\n",
       " 'however': ['contrast', 'hand'],\n",
       " 'yet': ['within', 'indefinite', 'time', 'unspecified', 'future', 'time'],\n",
       " 'so_far': ['used', 'superlative'],\n",
       " 'lightly': ['indifference', 'without', 'dejection'],\n",
       " 'besides': ['addition'],\n",
       " 'fugally': ['fugal', 'style'],\n",
       " 'furthermore': ['addition'],\n",
       " 'farther': ['greater',\n",
       "  'distance',\n",
       "  'time',\n",
       "  'space',\n",
       "  'farther',\n",
       "  'used',\n",
       "  'frequently',\n",
       "  'physical',\n",
       "  'sense'],\n",
       " 'further': ['addition', 'furthermore'],\n",
       " 'farthest': ['greatest',\n",
       "  'distance',\n",
       "  'space',\n",
       "  'time',\n",
       "  'farthest',\n",
       "  'used',\n",
       "  'often',\n",
       "  'furthest',\n",
       "  'physical',\n",
       "  'sense'],\n",
       " 'furthest': ['greatest',\n",
       "  'degree',\n",
       "  'extent',\n",
       "  'advanced',\n",
       "  'stage',\n",
       "  'furthest',\n",
       "  'used',\n",
       "  'often',\n",
       "  'farthest',\n",
       "  'abstract',\n",
       "  'sense'],\n",
       " 'futilely': ['futile', 'unproductive', 'manner'],\n",
       " 'still': ['reference',\n",
       "  'action',\n",
       "  'condition',\n",
       "  'without',\n",
       "  'change',\n",
       "  'interruption',\n",
       "  'cessation'],\n",
       " 'no_longer': [],\n",
       " 'anymore': ['present', 'usually', 'used', 'negative'],\n",
       " 'already': ['prior', 'specified', 'implied', 'time'],\n",
       " 'very': ['used',\n",
       "  'intensifier',\n",
       "  'real',\n",
       "  'sometimes',\n",
       "  'used',\n",
       "  'informally',\n",
       "  'really',\n",
       "  'rattling',\n",
       "  'informal'],\n",
       " 'fabulously': ['exceedingly', 'extremely'],\n",
       " 'mighty': ['southern', 'regional', 'intensive', 'great', 'degree'],\n",
       " 'good_and': ['completely', 'thoroughly'],\n",
       " 'fucking': ['intensifier', 'colloquial'],\n",
       " 'henceforth': ['time', 'forth'],\n",
       " 'hereafter': ['future', 'life', 'state'],\n",
       " 'hereunder': ['term', 'agreement'],\n",
       " 'instantaneously': ['without', 'delay'],\n",
       " 'mildly': ['moderate', 'degree'],\n",
       " 'a_bit': ['small', 'degree', 'somewhat'],\n",
       " 'anon': ['another', 'time'],\n",
       " 'soon': ['near', 'future'],\n",
       " 'asap': ['soon', 'possible'],\n",
       " 'shortly': ['short', 'distance'],\n",
       " 'momentarily': ['moment'],\n",
       " 'shoulder-to-shoulder': ['side', 'side', 'close', 'together'],\n",
       " 'soonest': ['least', 'delay'],\n",
       " 'spiritedly': ['spirited', 'lively', 'manner', 'animation', 'vivacity'],\n",
       " 'sportively': ['merry', 'sportive', 'manner'],\n",
       " 'stormily': ['stormy', 'violent', 'manner'],\n",
       " 'frequently': ['many', 'time', 'short', 'interval'],\n",
       " 'oftener': ['often', 'frequently'],\n",
       " 'rarely': ['often'],\n",
       " 'curiously': ['manner', 'differing', 'usual', 'expected'],\n",
       " 'reasonably': ['moderately', 'sufficient', 'extent', 'degree'],\n",
       " 'unreasonably': ['degree', 'exceeds', 'bound', 'reason', 'moderation'],\n",
       " 'slightly': ['small', 'degree', 'extent'],\n",
       " 'movingly': ['moving', 'manner'],\n",
       " 'extensively': ['widespread', 'way'],\n",
       " 'intrinsically': ['respect', 'inherent', 'nature'],\n",
       " 'decidedly': ['without', 'question', 'beyond', 'doubt'],\n",
       " 'truly': ['accordance', 'truth', 'fact', 'reality'],\n",
       " 'indeed': ['truth', 'often', 'tends', 'intensify'],\n",
       " 'in_the_lurch': ['difficult', 'vulnerable', 'position'],\n",
       " 'in_truth': ['fact', 'used', 'intensifier', 'sentence', 'modifier'],\n",
       " 'forsooth': ['archaic',\n",
       "  'word',\n",
       "  'originally',\n",
       "  'meaning',\n",
       "  'truth',\n",
       "  'usually',\n",
       "  'used',\n",
       "  'express',\n",
       "  'disbelief'],\n",
       " 'in_utero': ['uterus'],\n",
       " 'in_vacuo': ['isolation', 'without', 'reference', 'anything', 'else'],\n",
       " 'naturally': ['might', 'expected'],\n",
       " 'unnaturally': ['manner', 'variance', 'natural', 'normal'],\n",
       " 'clearly': ['without', 'doubt', 'question'],\n",
       " 'unclearly': ['manner', 'unclear'],\n",
       " 'obviously': ['unmistakably',\n",
       "  'plain',\n",
       "  'often',\n",
       "  'used',\n",
       "  'informally',\n",
       "  'plainly'],\n",
       " 'apparently': ['appearance', 'alone', 'hardy'],\n",
       " 'again': ['anew'],\n",
       " 'withal': ['together'],\n",
       " 'by_chance': ['without', 'advance', 'planning'],\n",
       " 'unexpectedly': ['way', 'expected'],\n",
       " 'out_of_the_way': ['extraordinary', 'unusual'],\n",
       " 'in_the_way': ['forming', 'hindrance', 'impediment', 'obstruction'],\n",
       " 'specifically': ['distinction', 'others'],\n",
       " 'generally': ['without', 'distinction', 'one', 'others'],\n",
       " 'nonspecifically': ['without', 'specificity'],\n",
       " 'fortunately': ['good', 'fortune'],\n",
       " 'happily': ['joyous', 'manner'],\n",
       " 'sadly': ['unfortunate', 'way'],\n",
       " 'unfortunately': ['bad', 'luck'],\n",
       " 'therefore': ['used',\n",
       "  'introduce',\n",
       "  'logical',\n",
       "  'conclusion',\n",
       "  'fact',\n",
       "  'reason',\n",
       "  'result'],\n",
       " 'ergo': ['used', 'sentence', 'connector', 'therefore', 'consequently'],\n",
       " 'hence': ['place'],\n",
       " 'thence': ['circumstance', 'source'],\n",
       " 'therefor': ['formal', 'usage', 'especially', 'legal', 'usage'],\n",
       " 'vocationally': ['affecting', 'pursuit', 'vocation', 'occupation'],\n",
       " 'face_to_face': ['involving', 'close', 'contact', 'confronting'],\n",
       " 'one-on-one': ['two', 'person', 'direct', 'encounter'],\n",
       " 'face-to-face': ['directly', 'facing'],\n",
       " 'vis-a-vis': ['literally', 'face', 'face'],\n",
       " 'tete_a_tete': ['without',\n",
       "  'intrusion',\n",
       "  'third',\n",
       "  'person',\n",
       "  'intimate',\n",
       "  'privacy'],\n",
       " 'if_not': ['perhaps',\n",
       "  'indicating',\n",
       "  'possibility',\n",
       "  'remarkable',\n",
       "  'greater',\n",
       "  'better',\n",
       "  'sooner'],\n",
       " 'beyond': ['farther', 'side', 'observer'],\n",
       " 'otherwise': ['respect', 'way'],\n",
       " 'additionally': ['addition', 'way', 'addition', 'furthermore'],\n",
       " 'extremely': ['extreme', 'degree'],\n",
       " 'drop-dead': ['extremely'],\n",
       " 'beyond_measure': ['excess', 'without', 'limit'],\n",
       " 'madly': ['used', 'intensive', 'extremely'],\n",
       " 'inordinately': ['extremely'],\n",
       " 'by_far': ['considerable', 'margin'],\n",
       " 'head_and_shoulders_above': ['outstandingly', 'superior'],\n",
       " 'excessively': ['degree', 'exceeding', 'normal', 'proper', 'limit'],\n",
       " 'ultimately': ['end', 'result', 'succession', 'process'],\n",
       " 'finally': ['unspecified', 'period', 'time', 'especially', 'long', 'delay'],\n",
       " 'presently': ['time', 'period'],\n",
       " 'nowadays': ['time', 'nancy', 'mitford'],\n",
       " 'immediately': ['without', 'delay', 'hesitation', 'time', 'intervening'],\n",
       " 'now': ['prefatory',\n",
       "  'transitional',\n",
       "  'indicates',\n",
       "  'change',\n",
       "  'subject',\n",
       "  'activity'],\n",
       " 'now_now': ['interjection', 'rebuke'],\n",
       " 'aggressively': ['aggressive', 'manner'],\n",
       " 'shrilly': ['shrill', 'voice'],\n",
       " 'steadily': ['steady', 'rate', 'pace'],\n",
       " 'unhappily': ['unpleasant', 'way'],\n",
       " 'firm': ['resolute', 'determination'],\n",
       " 'squarely': ['straight', 'direct', 'way'],\n",
       " 'directly': ['without', 'deviation'],\n",
       " 'due': ['directly', 'exactly', 'straight'],\n",
       " 'variously': ['diverse', 'way'],\n",
       " 'indefatigably': ['indefatigable', 'energy'],\n",
       " 'biradially': ['biradial', 'manner'],\n",
       " 'bitterly': ['indicating', 'something', 'hard', 'accept'],\n",
       " 'very_well': ['expression',\n",
       "  'agreement',\n",
       "  'normally',\n",
       "  'occurring',\n",
       "  'beginning',\n",
       "  'sentence'],\n",
       " 'all_right': ['without', 'doubt', 'used', 'reinforce', 'assertion'],\n",
       " 'swiftly': ['swift', 'manner'],\n",
       " 'openly': ['open', 'way'],\n",
       " 'practically': ['almost', 'nearly'],\n",
       " 'presumably': ['reasonable', 'assumption'],\n",
       " 'clinquant': ['glittering', 'gold', 'silver'],\n",
       " 'crested': ['bearing', 'heraldic', 'device'],\n",
       " 'crocketed': ['gable',\n",
       "  'spire',\n",
       "  'furnished',\n",
       "  'crocket',\n",
       "  'ornament',\n",
       "  'form',\n",
       "  'curved',\n",
       "  'bent',\n",
       "  'foliage'],\n",
       " 'feathery': ['adorned', 'feather', 'plume'],\n",
       " 'frilled': ['decorative', 'ruffle', 'frill'],\n",
       " 'fringed': ['decorative', 'edging', 'hanging', 'cord', 'strip'],\n",
       " 'gilt-edged': ['gilded', 'edge', 'page', 'book'],\n",
       " 'inflamed': ['adorned', 'tongue', 'flame'],\n",
       " 'inlaid': ['adorned', 'inlay'],\n",
       " 'inwrought': ['decorative', 'pattern', 'worked', 'woven'],\n",
       " 'tessellated': ['decorated',\n",
       "  'small',\n",
       "  'piece',\n",
       "  'colored',\n",
       "  'glass',\n",
       "  'stone',\n",
       "  'fitted',\n",
       "  'together',\n",
       "  'mosaic'],\n",
       " 'mounted': ['decorated',\n",
       "  'applied',\n",
       "  'ornamentation',\n",
       "  'often',\n",
       "  'used',\n",
       "  'combination'],\n",
       " 'paneled': ['fitted', 'decorated', 'panel', 'wainscoting'],\n",
       " 'studded': ['dotted',\n",
       "  'adorned',\n",
       "  'stud',\n",
       "  'nailhead',\n",
       "  'usually',\n",
       "  'used',\n",
       "  'combination'],\n",
       " 'tapestried': ['hung', 'decorated', 'tapestry'],\n",
       " 'tasseled': ['fringed', 'adorned', 'tassel'],\n",
       " 'tricked-out': ['decorated', 'particular', 'way'],\n",
       " 'tufted': ['adorned', 'tuft'],\n",
       " 'plain': ['lacking', 'embellishment', 'ornamentation'],\n",
       " 'untufted': ['adorned', 'tuft'],\n",
       " 'clever': ['showing', 'inventiveness', 'skill'],\n",
       " 'coordinated': ['dexterous',\n",
       "  'use',\n",
       "  'one',\n",
       "  'set',\n",
       "  'muscle',\n",
       "  'movement',\n",
       "  'mary',\n",
       "  'mccarthy'],\n",
       " 'deft': ['skillful', 'physical', 'movement', 'especially', 'hand'],\n",
       " 'light-fingered': ['nimble',\n",
       "  'finger',\n",
       "  'literally',\n",
       "  'figuratively',\n",
       "  'especially',\n",
       "  'stealing',\n",
       "  'picking',\n",
       "  'pocket',\n",
       "  'harry',\n",
       "  'hansen',\n",
       "  'time'],\n",
       " 'quick-witted': ['mentally', 'nimble', 'resourceful'],\n",
       " 'bumbling': ['lacking',\n",
       "  'physical',\n",
       "  'movement',\n",
       "  'skill',\n",
       "  'especially',\n",
       "  'hand',\n",
       "  'mary',\n",
       "  'vorse'],\n",
       " 'inept': ['revealing', 'lack', 'perceptiveness', 'judgment', 'finesse'],\n",
       " 'uncoordinated': ['lacking',\n",
       "  'skillful',\n",
       "  'effective',\n",
       "  'interaction',\n",
       "  'muscle',\n",
       "  'movement'],\n",
       " 'unmechanical': ['person', 'lacking', 'mechanical', 'skill'],\n",
       " 'beneficial': ['promoting', 'enhancing'],\n",
       " 'plus': ['involving', 'advantage', 'good'],\n",
       " 'discriminatory': ['manifesting', 'partiality'],\n",
       " 'minus': ['involving', 'disadvantage', 'harm'],\n",
       " 'audacious': ['disposed', 'venture', 'take', 'risk'],\n",
       " 'sporting': ['involving', 'risk', 'willingness', 'take', 'risk'],\n",
       " 'swaggering': ['flamboyantly', 'adventurous'],\n",
       " 'safe': ['undertaking', 'secure', 'risk'],\n",
       " 'better': ['comparative',\n",
       "  'superlative',\n",
       "  'well',\n",
       "  'wiser',\n",
       "  'advantageous',\n",
       "  'hence',\n",
       "  'advisable'],\n",
       " 'considered': ['carefully', 'weighed'],\n",
       " 'aerobiotic': ['living', 'active', 'presence', 'oxygen'],\n",
       " 'oxidative': ['taking', 'place', 'presence', 'oxygen'],\n",
       " 'artistic': ['satisfying', 'aesthetic', 'standard', 'sensibility'],\n",
       " 'cosmetic': ['serving', 'aesthetic', 'purpose', 'beautifying', 'body'],\n",
       " 'painterly': ['quality', 'unique', 'art', 'painting'],\n",
       " 'sensuous': ['taking', 'delight', 'beauty'],\n",
       " 'inartistic': ['lacking', 'aesthetic', 'sensibility'],\n",
       " 'impressed': ['deeply', 'markedly', 'affected', 'influenced'],\n",
       " 'smitten': ['used', 'combination', 'affected', 'something', 'overwhelming'],\n",
       " 'stage-struck': ['infatuated',\n",
       "  'enthralled',\n",
       "  'theater',\n",
       "  'especially',\n",
       "  'desire',\n",
       "  'act'],\n",
       " 'subject': ['likely', 'affected', 'something'],\n",
       " 'taken': ['affected', 'indisposition'],\n",
       " 'wonder-struck': ['affected', 'overcome', 'wonder'],\n",
       " 'immune': ['usually', 'followed', 'affected', 'given', 'influence'],\n",
       " 'superior': ['often', 'followed', 'affected', 'influenced'],\n",
       " 'unimpressed': ['moved', 'serious', 'regard'],\n",
       " 'uninfluenced': ['influenced', 'affected'],\n",
       " 'agonistic': ['struggling', 'effect'],\n",
       " 'artificial': ['artificially', 'formal'],\n",
       " 'constrained': ['lacking', 'spontaneity', 'natural'],\n",
       " 'elocutionary': ['used', 'style', 'speaking', 'overly', 'embellished'],\n",
       " 'mannered': ['unnatural', 'mannerism'],\n",
       " 'plummy': ['voice', 'affectedly', 'mellow', 'rich'],\n",
       " 'lifelike': ['free', 'artificiality'],\n",
       " 'unmannered': ['without', 'artificiality', 'natural'],\n",
       " 'unselfconscious': [],\n",
       " 'unstilted': ['flowing', 'naturally', 'continuously'],\n",
       " 'assentient': ['expressing', 'agreement', 'consent'],\n",
       " 'dissentient': ['disagreeing', 'especially', 'majority'],\n",
       " 'accepting': ['tolerating', 'without', 'protest'],\n",
       " 'dismissive': ['stopping', 'associate'],\n",
       " 'repudiative': ['rejecting', 'emphatically', 'refusing', 'pay', 'disowning'],\n",
       " 'adrift': ['afloat', 'surface', 'body', 'water'],\n",
       " 'floating': ['borne', 'suspended', 'liquid'],\n",
       " 'waterborne': ['supported', 'water'],\n",
       " 'acrophobic': ['suffering',\n",
       "  'acrophobia',\n",
       "  'abnormally',\n",
       "  'afraid',\n",
       "  'high',\n",
       "  'place'],\n",
       " 'afeard': ['pronunciation', 'afraid'],\n",
       " 'aghast': ['struck', 'fear', 'dread', 'consternation'],\n",
       " 'agoraphobic': ['suffering',\n",
       "  'agoraphobia',\n",
       "  'abnormally',\n",
       "  'afraid',\n",
       "  'open',\n",
       "  'public',\n",
       "  'place'],\n",
       " 'alarmed': ['experiencing', 'sudden', 'sense', 'danger'],\n",
       " 'algophobic': ['suffering', 'algophobia', 'abnormally', 'afraid', 'pain'],\n",
       " 'apprehensive': ['fear', 'dread', 'possible', 'evil', 'harm'],\n",
       " 'hangdog': ['frightened', 'submission', 'compliance'],\n",
       " 'claustrophobic': ['suffering',\n",
       "  'claustrophobia',\n",
       "  'abnormally',\n",
       "  'afraid',\n",
       "  'place'],\n",
       " 'fearful': ['experiencing', 'showing', 'fear'],\n",
       " 'frightened': ['made', 'afraid'],\n",
       " 'horrified': ['stricken', 'horror'],\n",
       " 'hunted': ['reflecting', 'fear', 'terror', 'one', 'hunted'],\n",
       " 'hydrophobic': ['abnormally', 'afraid', 'water'],\n",
       " 'mysophobic': ['suffering',\n",
       "  'mysophobia',\n",
       "  'abnormally',\n",
       "  'afraid',\n",
       "  'dirt',\n",
       "  'contamination'],\n",
       " 'panicky': ['thrown', 'state', 'intense', 'fear', 'desperation'],\n",
       " 'numb': ['frightened',\n",
       "  'unable',\n",
       "  'move',\n",
       "  'stunned',\n",
       "  'paralyzed',\n",
       "  'terror',\n",
       "  'petrified'],\n",
       " 'breathe': ['draw', 'air', 'expel', 'lung'],\n",
       " 'respire': ['breathe', 'easily', 'exertion', 'anxiety'],\n",
       " 'choke': ['breathe',\n",
       "  'great',\n",
       "  'difficulty',\n",
       "  'experiencing',\n",
       "  'strong',\n",
       "  'emotion'],\n",
       " 'hyperventilate': ['produce', 'hyperventilation'],\n",
       " 'aspirate': ['suck', 'air'],\n",
       " 'burp': ['expel', 'gas', 'stomach'],\n",
       " 'force_out': ['emit', 'cause', 'move', 'force', 'effort'],\n",
       " 'hiccup': ['breathe', 'spasmodically', 'make', 'sound'],\n",
       " 'sigh': ['heave', 'utter', 'sigh', 'breathe', 'deeply', 'heavily'],\n",
       " 'exhale': ['give', 'breath', 'odor'],\n",
       " 'hold': ['keep', 'exhaling', 'expelling'],\n",
       " 'sneeze': ['exhale', 'spasmodically', 'irritant', 'entered', 'one', 'nose'],\n",
       " 'inhale': ['draw', 'air'],\n",
       " 'pant': ['breathe', 'noisily', 'one', 'exhausted'],\n",
       " 'cough': ['exhale', 'abruptly', 'one', 'chest', 'cold', 'congestion'],\n",
       " 'hack': ['cough', 'spasmodically'],\n",
       " 'expectorate': ['discharge', 'phlegm', 'sputum', 'lung', 'mouth'],\n",
       " 'snort': ['make', 'snorting', 'sound', 'exhaling', 'hard'],\n",
       " 'wheeze': ['breathe', 'difficulty'],\n",
       " 'puff': ['blow', 'hard', 'loudly'],\n",
       " 'blow': ['free', 'obstruction', 'blowing', 'air'],\n",
       " 'insufflate': ['blow', 'breathe', 'hard'],\n",
       " 'yawn': ['utter', 'yawn', 'lack', 'oxygen', 'one', 'tired'],\n",
       " 'sniff': ['inhale', 'audibly', 'nose'],\n",
       " 'blink': ['briefly', 'shut', 'eye'],\n",
       " 'palpebrate': ['wink', 'blink', 'especially', 'repeatedly'],\n",
       " 'bat': ['wink', 'briefly'],\n",
       " 'wink': ['force', 'go', 'away', 'blinking'],\n",
       " 'squint': ['partly',\n",
       "  'close',\n",
       "  'one',\n",
       "  'eye',\n",
       "  'hit',\n",
       "  'direct',\n",
       "  'blinding',\n",
       "  'light'],\n",
       " 'wince': ['make', 'face', 'indicating', 'disgust', 'dislike'],\n",
       " 'shed': ['cast', 'hair', 'skin', 'horn', 'feather'],\n",
       " 'desquamate': ['peel', 'scale'],\n",
       " 'twitch': ['make', 'uncontrolled', 'short', 'jerky', 'motion'],\n",
       " 'fibrillate': ['make', 'fine', 'irregular', 'rapid', 'twitching', 'movement'],\n",
       " 'move_involuntarily': ['move', 'uncontrolled', 'manner'],\n",
       " 'act_involuntarily': ['act', 'uncontrolled', 'manner'],\n",
       " 'act': ['something', 'people', 'cause', 'happen'],\n",
       " 'fall_over_backwards': ['try', 'hard', 'please', 'someone'],\n",
       " 'presume': ['take', 'liberty', 'act', 'much', 'confidence'],\n",
       " 'vulgarize': ['act', 'vulgar', 'manner'],\n",
       " 'optimize': ['act', 'optimist', 'take', 'sunny', 'view', 'world'],\n",
       " 'quack': ['act', 'medical', 'quack', 'charlatan'],\n",
       " 'menace': ['act', 'threatening', 'manner'],\n",
       " 'make': ['act', 'certain', 'way', 'acquire'],\n",
       " 'swagger': ['act', 'arrogant', 'overly', 'conceited', 'manner'],\n",
       " 'freeze': ['anesthetize', 'cold'],\n",
       " 'wanton': ['behave', 'extremely', 'cruelly', 'brutally'],\n",
       " 'romanticize': ['act', 'romantic', 'way'],\n",
       " 'sentimentalise': ['act',\n",
       "  'sentimental',\n",
       "  'way',\n",
       "  'indulge',\n",
       "  'sentimental',\n",
       "  'thought',\n",
       "  'expression'],\n",
       " 'bungle': ['spoil', 'behaving', 'clumsily', 'foolishly'],\n",
       " 'play': ['act', 'using', 'sword', 'weapon', 'vigorously', 'skillfully'],\n",
       " 'stooge': ['act', 'stooge', 'compliant', 'subordinate', 'manner'],\n",
       " 'shake': ['move', 'tremor'],\n",
       " 'shiver': ['shake', 'cold'],\n",
       " 'rest': ['rest'],\n",
       " 'be_active': ['state', 'action'],\n",
       " 'sleep': ['asleep'],\n",
       " 'bundle': ['sleep', 'fully', 'clothed', 'bed', 'one', 'betrothed'],\n",
       " 'snooze': ['sleep', 'lightly', 'short', 'period', 'time'],\n",
       " 'nap': ['take', 'siesta'],\n",
       " 'oversleep': ['sleep', 'longer', 'intended'],\n",
       " 'sleep_late': ['sleep', 'later', 'usual', 'customary'],\n",
       " 'hibernate': ['sleep', 'winter'],\n",
       " 'estivate': ['sleep', 'summer'],\n",
       " 'drowse': ['verge', 'sleeping'],\n",
       " 'nod': ['let', 'head', 'fall', 'forward', 'drowsiness'],\n",
       " 'zonk_out': ['lose', 'consciousness', 'due', 'sudden', 'trauma', 'example'],\n",
       " 'snore': ['breathe', 'noisily', 'one', 'sleep'],\n",
       " 'fall_asleep': ['change', 'waking', 'sleeping', 'state'],\n",
       " 'bed_down': ['go', 'bed'],\n",
       " 'doss': ['sleep', 'convenient', 'place'],\n",
       " 'go_to_bed': ['prepare', 'sleep'],\n",
       " 'get_up': ['cause', 'rise'],\n",
       " 'wake_up': ['stop', 'sleeping'],\n",
       " 'awaken': ['cause', 'become', 'awake', 'conscious'],\n",
       " 'reawaken': ['awaken'],\n",
       " 'cause_to_sleep': ['make', 'fall', 'asleep'],\n",
       " 'affect': ['act', 'physically', 'effect', 'upon'],\n",
       " 'attack': ['begin', 'injure'],\n",
       " 'ulcerate': ['affect', 'ulcer'],\n",
       " 'wake': ['awake', 'alert'],\n",
       " 'stay_up': ['go', 'bed'],\n",
       " 'keep_up': ['prevent', 'going', 'bed', 'night'],\n",
       " 'hypnotize': ['induce', 'hypnosis'],\n",
       " 'entrance': ['act', 'entering'],\n",
       " 'anesthetize': ['administer', 'anesthetic', 'drug'],\n",
       " 'etherize': ['anesthetize', 'ether'],\n",
       " 'cocainize': ['anesthetize', 'cocaine'],\n",
       " 'chloroform': ['anesthetize', 'chloroform'],\n",
       " 'bring_to': ['return', 'consciousness'],\n",
       " 'sedate': ['cause', 'calm', 'quiet', 'administering', 'sedative'],\n",
       " 'stimulate': ['cause', 'alert', 'energetic'],\n",
       " 'de-energize': ['deprive', 'energy'],\n",
       " 'cathect': ['inject', 'libidinal', 'energy'],\n",
       " 'perk_up': ['gain', 'regain', 'energy'],\n",
       " 'faint': ['pas',\n",
       "  'weakness',\n",
       "  'physical',\n",
       "  'emotional',\n",
       "  'distress',\n",
       "  'due',\n",
       "  'loss',\n",
       "  'blood',\n",
       "  'supply',\n",
       "  'brain'],\n",
       " 'come_to': ['return', 'consciousness'],\n",
       " 'animate': ['give', 'new', 'life', 'energy'],\n",
       " 'refresh': ['make', 'fresh'],\n",
       " 'freshen': ['become', 'make', 'oneself', 'fresh'],\n",
       " 'wash_up': ['wash', 'one', 'face', 'hand'],\n",
       " 'tense': ['become', 'tense', 'nervous', 'uneasy'],\n",
       " 'crick': ['twist', 'body', 'part', 'strained', 'position'],\n",
       " 'relax': ['become', 'less', 'tense', 'rest', 'take', 'one', 'ease'],\n",
       " 'unbend': ['release', 'mental', 'strain', 'tension', 'formality'],\n",
       " 'vege_out': ['engage', 'passive', 'relaxation'],\n",
       " 'sit_back': ['settle', 'comfortable', 'sitting', 'position'],\n",
       " 'limber_up': ['make',\n",
       "  'one',\n",
       "  'body',\n",
       "  'limber',\n",
       "  'suppler',\n",
       "  'stretching',\n",
       "  'prepare',\n",
       "  'strenuous',\n",
       "  'physical',\n",
       "  'activity'],\n",
       " 'stretch': ['extend', 'one', 'limb', 'muscle', 'entire', 'body'],\n",
       " 'spread-eagle': ['stretch', 'completely'],\n",
       " 'exsert': ['thrust', 'extend'],\n",
       " 'hyperextend': ['extend', 'joint', 'beyond', 'normal', 'range'],\n",
       " 'crane': ['stretch', 'neck', 'see', 'better'],\n",
       " 'invigorate': ['impart', 'vigor', 'strength', 'vitality'],\n",
       " 'smile': ['change',\n",
       "  'one',\n",
       "  'facial',\n",
       "  'expression',\n",
       "  'spreading',\n",
       "  'lip',\n",
       "  'often',\n",
       "  'signal',\n",
       "  'pleasure'],\n",
       " 'dimple': ['produce', 'dimple', 'smiling'],\n",
       " 'grin': ['draw',\n",
       "  'back',\n",
       "  'lip',\n",
       "  'reveal',\n",
       "  'teeth',\n",
       "  'smile',\n",
       "  'grimace',\n",
       "  'snarl'],\n",
       " 'beam': ['smile',\n",
       "  'radiantly',\n",
       "  'express',\n",
       "  'joy',\n",
       "  'one',\n",
       "  'facial',\n",
       "  'expression'],\n",
       " 'smirk': ['smile', 'affectedly', 'derisively'],\n",
       " 'fleer': ['smirk', 'contemptuously'],\n",
       " 'bray': ['laugh', 'loudly', 'harshly'],\n",
       " 'bellylaugh': ['laugh', 'deep', 'hearty', 'laugh'],\n",
       " 'roar': ['laugh', 'unrestrainedly', 'heartily'],\n",
       " 'snicker': ['laugh', 'quietly'],\n",
       " 'giggle': ['laugh', 'nervously'],\n",
       " 'break_up': ['laugh', 'unrestrainedly'],\n",
       " 'break': ['escape', 'jail'],\n",
       " 'break_down': ['collapse', 'due', 'fatigue', 'illness', 'sudden', 'attack'],\n",
       " 'drop_like_flies': ['rapidly', 'collapse', 'die', 'drop', 'large', 'number'],\n",
       " 'cramp': ['affect', 'cramp'],\n",
       " 'fall_over': ['fall', 'forward'],\n",
       " 'cackle': ['emit', 'loud', 'unpleasant', 'kind', 'laughing'],\n",
       " 'guffaw': ['laugh', 'boisterously'],\n",
       " 'chuckle': ['laugh', 'quietly', 'restraint'],\n",
       " 'laugh': ['produce', 'laughter'],\n",
       " 'convulse': ['overcome', 'laughter'],\n",
       " 'cachinnate': ['laugh', 'loudly', 'unrestrained', 'way'],\n",
       " 'sneer': ['express', 'scornful', 'smile'],\n",
       " 'frown': ['look',\n",
       "  'angry',\n",
       "  'sullen',\n",
       "  'wrinkle',\n",
       "  'one',\n",
       "  'forehead',\n",
       "  'signal',\n",
       "  'disapproval'],\n",
       " 'glower': ['look', 'fixed', 'gaze'],\n",
       " 'stare': ['fixate', 'one', 'eye'],\n",
       " 'look': ['certain', 'outward', 'facial', 'expression'],\n",
       " 'scowl': ['frown', 'displeasure'],\n",
       " 'shrug': ['raise',\n",
       "  'one',\n",
       "  'shoulder',\n",
       "  'indicate',\n",
       "  'indifference',\n",
       "  'resignation'],\n",
       " 'clap': ['clap', 'one', 'hand', 'together'],\n",
       " 'grimace': ['contort',\n",
       "  'face',\n",
       "  'indicate',\n",
       "  'certain',\n",
       "  'mental',\n",
       "  'emotional',\n",
       "  'state'],\n",
       " 'screw_up': ['twist', 'strained', 'configuration'],\n",
       " 'pout': ['make', 'sad', 'face', 'thrust', 'one', 'lower', 'lip'],\n",
       " 'clear_the_throat': ['clear', 'mucus', 'food', 'one', 'throat'],\n",
       " 'shower': ['take', 'shower', 'wash', 'one', 'body', 'shower'],\n",
       " 'foment': ['bathe', 'warm', 'water', 'medicated', 'lotion'],\n",
       " 'bathe': ['clean', 'one', 'body', 'immersion', 'water'],\n",
       " 'cleanse': ['clean', 'one', 'body', 'part', 'thereof', 'washing'],\n",
       " 'wash': ['cleanse', 'one', 'body', 'soap', 'water'],\n",
       " 'sponge_down': ['wash', 'sponge'],\n",
       " 'scrub': ['wash', 'thoroughly'],\n",
       " 'soap': ['rub', 'soap', 'usually', 'purpose', 'cleaning'],\n",
       " 'gargle': ['rinse', 'one', 'mouth', 'throat', 'mouthwash'],\n",
       " 'shave': ['remove', 'body', 'hair', 'razor'],\n",
       " 'epilate': ['remove', 'body', 'hair'],\n",
       " 'razor': ['shave', 'razor'],\n",
       " 'tonsure': ['shave', 'head', 'newly', 'inducted', 'monk'],\n",
       " 'douche': ['direct', 'spray', 'water', 'bodily', 'cavity', 'cleaning'],\n",
       " 'comb': ['smoothen', 'neaten', 'comb'],\n",
       " 'slick': ['give', 'smooth', 'glossy', 'appearance'],\n",
       " 'dress': ['provide', 'clothes', 'put', 'clothes'],\n",
       " 'bob': ['cut', 'hair', 'style', 'bob'],\n",
       " 'pompadour': ['style', 'woman', 'hair', 'pompadour'],\n",
       " 'marcel': ['make', 'marcel', 'woman', 'hair'],\n",
       " 'wave': ['set', 'wave'],\n",
       " 'gauffer': ['make', 'wavy', 'heated', 'goffering', 'iron'],\n",
       " 'perm': ['give', 'permanent', 'wave'],\n",
       " 'mousse': ['apply', 'styling', 'gel'],\n",
       " 'pomade': ['apply', 'pomade', 'hair'],\n",
       " 'tease': ['ruffle',\n",
       "  'one',\n",
       "  'hair',\n",
       "  'combing',\n",
       "  'end',\n",
       "  'towards',\n",
       "  'scalp',\n",
       "  'full',\n",
       "  'effect'],\n",
       " 'groom': ['care', 'one', 'external', 'appearance'],\n",
       " 'clean_up': ['make', 'oneself', 'clean', 'presentable', 'neat'],\n",
       " 'make_up': ['apply', 'cosmetic', 'one', 'face', 'appear', 'prettier'],\n",
       " 'highlight': ['apply',\n",
       "  'highlighter',\n",
       "  'one',\n",
       "  'cheek',\n",
       "  'eyebrow',\n",
       "  'order',\n",
       "  'make',\n",
       "  'prominent'],\n",
       " 'lipstick': ['apply', 'lipstick'],\n",
       " 'rouge': ['redden', 'applying', 'rouge'],\n",
       " 'condition': ['apply', 'conditioner', 'order', 'make', 'smooth', 'shiny'],\n",
       " 'floss': ['use', 'dental', 'floss', 'clean'],\n",
       " 'shampoo': ['use', 'shampoo', 'hair'],\n",
       " 'powder': ['apply', 'powder'],\n",
       " 'talc': ['apply', 'talcum', 'powder', 'one', 'body'],\n",
       " 'manicure': ['trim', 'carefully', 'neatly'],\n",
       " 'barber': ['perform', 'service', 'barber', 'cut', 'hair', 'beard'],\n",
       " 'pedicure': ['care', 'one', 'foot', 'cutting', 'shaping', 'nail', 'etc'],\n",
       " 'doll_up': ['use', 'special', 'care', 'dressing', 'etc'],\n",
       " 'spruce_up': ['dress', 'groom', 'particular', 'care', 'special', 'occasion'],\n",
       " 'perfume': ['apply', 'perfume'],\n",
       " 'preen': ['dress', 'groom', 'elaborate', 'care'],\n",
       " 'prank': ['dress', 'showily'],\n",
       " 'tart_up': ['dress', 'cheap', 'provocative', 'way'],\n",
       " 'overdress': ['dress', 'warmly'],\n",
       " 'enrobe': ['adorn', 'robe'],\n",
       " 'prim': ['dress', 'primly'],\n",
       " 'bedizen': ['dress', 'garishly', 'tastelessly'],\n",
       " 'dress_down': ['dress', 'informally', 'casually'],\n",
       " 'prink': ['dress', 'carefully', 'finicky', 'manner'],\n",
       " 'reduce': ['take', 'weight'],\n",
       " 'sweat_off': ['lose', 'weight', 'sweating'],\n",
       " 'gain': ['increase', 'one', 'body', 'weight'],\n",
       " 'round': ['become', 'round', 'plump', 'shapely'],\n",
       " 'bundle_up': ['dress', 'warmly'],\n",
       " 'hat': ['put', 'wear', 'hat'],\n",
       " 'try_on': ['put',\n",
       "  'garment',\n",
       "  'order',\n",
       "  'see',\n",
       "  'whether',\n",
       "  'fit',\n",
       "  'look',\n",
       "  'nice'],\n",
       " 'bonnet': ['dress', 'bonnet'],\n",
       " 'wear': ['dressed'],\n",
       " 'cover': ['clothe', 'protection', 'element'],\n",
       " 'jacket': ['put', 'jacket'],\n",
       " 'frock': ['put', 'frock'],\n",
       " 'shirt': ['put', 'shirt'],\n",
       " 'habit': ['put', 'habit'],\n",
       " 'vesture': ['provide', 'cover', 'cloak'],\n",
       " 'underdress': ['dress', 'without', 'sufficient', 'warmth'],\n",
       " 'corset': ['dress', 'corset'],\n",
       " 'shoe': ['furnish', 'shoe'],\n",
       " 'undress': ['get', 'undressed'],\n",
       " 'peel_off': ['take', 'difficulty'],\n",
       " 'take_off': ['remove', 'clothes'],\n",
       " 'scarf': ['wrap', 'adorn', 'scarf'],\n",
       " 'slip_on': ['put', 'ease', 'speed'],\n",
       " 'slip_off': ['take', 'ease', 'speed'],\n",
       " 'coat': ['cover', 'provide', 'coat'],\n",
       " 'cross-dress': ['dress', 'clothes', 'sex'],\n",
       " 'costume': ['dress', 'costume'],\n",
       " 'dandify': ['dress', 'like', 'dandy'],\n",
       " 'vest': ['clothe', 'oneself', 'ecclesiastical', 'garment'],\n",
       " 'inseminate': ['introduce', 'semen', 'female'],\n",
       " 'stratify': ['render',\n",
       "  'fertile',\n",
       "  'preserve',\n",
       "  'placing',\n",
       "  'layer',\n",
       "  'earth',\n",
       "  'sand'],\n",
       " 'quicken': ['show', 'sign', 'life'],\n",
       " 'impregnate': ['fertilize', 'cause', 'grow'],\n",
       " 'inoculate': ['insert', 'bud', 'propagation'],\n",
       " 'cross-fertilize': ['undergo', 'become', 'fertile'],\n",
       " 'pollinate': ['fertilize', 'transfering', 'pollen'],\n",
       " 'conceive': ['become', 'pregnant', 'undergo', 'conception'],\n",
       " 'nick': ['mate', 'successfully', 'livestock'],\n",
       " 'beget': ['make', 'child'],\n",
       " 'ejaculate': ['eject', 'semen'],\n",
       " 'reproduce': ['offspring',\n",
       "  'produce',\n",
       "  'individual',\n",
       "  'given',\n",
       "  'animal',\n",
       "  'plant'],\n",
       " 'propagate': ['cause', 'propagate', 'grafting', 'layering'],\n",
       " 'vegetate': ['propagate', 'asexually'],\n",
       " 'fructify': ['bear', 'fruit'],\n",
       " 'breed': ['young', 'animal', 'reproduce', 'organism'],\n",
       " 'pullulate': ['breed', 'freely', 'abundantly'],\n",
       " 'spawn': ['lay', 'spawn'],\n",
       " 'spat': ['spawn'],\n",
       " 'give_birth': ['cause', 'born'],\n",
       " 'lie_in': ['confinement', 'childbirth'],\n",
       " 'labor': ['undergo', 'effort', 'childbirth'],\n",
       " 'twin': ['give', 'birth', 'twin'],\n",
       " 'drop': ['give', 'birth', 'used', 'animal'],\n",
       " 'foal': ['give', 'birth', 'foal'],\n",
       " 'cub': ['give', 'birth', 'cub'],\n",
       " 'kitten': ['kitten'],\n",
       " 'lamb': ['give', 'birth', 'lamb'],\n",
       " 'litter': ['give', 'birth', 'litter', 'animal'],\n",
       " 'whelp': ['birth'],\n",
       " 'farrow': ['give', 'birth'],\n",
       " 'fawn': ['fawn'],\n",
       " 'calve': ['birth'],\n",
       " 'have_a_bun_in_the_oven': ['pregnant'],\n",
       " 'expect': ['look', 'forward', 'birth', 'child'],\n",
       " 'carry_to_term': ['carry', 'pregnancy'],\n",
       " 'miscarry': ['suffer', 'miscarriage'],\n",
       " 'abort': ['act', 'terminating', 'project', 'procedure', 'completed'],\n",
       " 'entity': ['perceived',\n",
       "  'known',\n",
       "  'inferred',\n",
       "  'distinct',\n",
       "  'existence',\n",
       "  'living',\n",
       "  'nonliving'],\n",
       " 'physical_entity': ['entity', 'physical', 'existence'],\n",
       " 'abstraction': ['general',\n",
       "  'concept',\n",
       "  'formed',\n",
       "  'extracting',\n",
       "  'common',\n",
       "  'feature',\n",
       "  'specific',\n",
       "  'example'],\n",
       " 'thing': ['action'],\n",
       " 'object': ['tangible', 'visible', 'entity', 'entity', 'cast', 'shadow'],\n",
       " 'whole': ['assemblage', 'part', 'regarded', 'single', 'entity'],\n",
       " 'congener': ['whole', 'thing', 'person', 'kind', 'category', 'another'],\n",
       " 'living_thing': ['living', 'living', 'entity'],\n",
       " 'organism': ['living',\n",
       "  'thing',\n",
       "  'develop',\n",
       "  'ability',\n",
       "  'act',\n",
       "  'function',\n",
       "  'independently'],\n",
       " 'benthos': ['organism', 'plant', 'animal', 'live', 'near', 'bottom', 'sea'],\n",
       " 'dwarf': ['plant', 'animal', 'atypically', 'small'],\n",
       " 'heterotroph': ['organism',\n",
       "  'depends',\n",
       "  'complex',\n",
       "  'organic',\n",
       "  'substance',\n",
       "  'nutrition'],\n",
       " 'parent': ['organism', 'plant', 'animal', 'younger', 'one', 'obtained'],\n",
       " 'life': ['living', 'thing', 'collectively'],\n",
       " 'biont': ['discrete', 'unit', 'living', 'matter'],\n",
       " 'cell': ['biology',\n",
       "  'basic',\n",
       "  'structural',\n",
       "  'functional',\n",
       "  'unit',\n",
       "  'organism',\n",
       "  'may',\n",
       "  'exist',\n",
       "  'independent',\n",
       "  'unit',\n",
       "  'life',\n",
       "  'monad',\n",
       "  'may',\n",
       "  'form',\n",
       "  'colony',\n",
       "  'tissue',\n",
       "  'higher',\n",
       "  'plant',\n",
       "  'animal'],\n",
       " 'causal_agent': ['entity',\n",
       "  'produce',\n",
       "  'effect',\n",
       "  'responsible',\n",
       "  'event',\n",
       "  'result'],\n",
       " 'person': ['human'],\n",
       " 'animal': ['living', 'organism', 'characterized', 'voluntary', 'movement'],\n",
       " 'plant': ['botany', 'living', 'organism', 'lacking', 'power', 'locomotion'],\n",
       " 'native': ['indigenous', 'plant', 'animal'],\n",
       " 'natural_object': ['object', 'occurring', 'naturally', 'made', 'man'],\n",
       " 'substance': ['particular',\n",
       "  'kind',\n",
       "  'specie',\n",
       "  'matter',\n",
       "  'uniform',\n",
       "  'property'],\n",
       " 'matter': ['mass', 'occupies', 'space'],\n",
       " 'food': ['substance',\n",
       "  'metabolized',\n",
       "  'animal',\n",
       "  'give',\n",
       "  'energy',\n",
       "  'build',\n",
       "  'tissue'],\n",
       " 'nutrient': ['substance',\n",
       "  'chemical',\n",
       "  'element',\n",
       "  'inorganic',\n",
       "  'compound',\n",
       "  'taken',\n",
       "  'green',\n",
       "  'plant',\n",
       "  'used',\n",
       "  'organic',\n",
       "  'synthesis'],\n",
       " 'artifact': ['object', 'taken', 'whole'],\n",
       " 'article': ['one', 'class', 'artifact'],\n",
       " 'psychological_feature': ['feature', 'mental', 'life', 'living', 'organism'],\n",
       " 'cognition': ['psychological',\n",
       "  'result',\n",
       "  'perception',\n",
       "  'learning',\n",
       "  'reasoning'],\n",
       " 'motivation': ['act', 'motivating', 'providing', 'incentive'],\n",
       " 'attribute': ['abstraction', 'belonging', 'characteristic', 'entity'],\n",
       " 'state': ['way', 'something', 'respect', 'main', 'attribute'],\n",
       " 'feeling': ['experiencing', 'affective', 'emotional', 'state'],\n",
       " 'location': ['point', 'extent', 'space'],\n",
       " 'shape': ['spatial', 'arrangement', 'something', 'distinct', 'substance'],\n",
       " 'time': ['continuum',\n",
       "  'experience',\n",
       "  'event',\n",
       "  'pas',\n",
       "  'future',\n",
       "  'present',\n",
       "  'past'],\n",
       " 'space': ['unlimited', 'expanse', 'everything', 'located'],\n",
       " 'absolute_space': ['physical', 'space', 'independent', 'occupies'],\n",
       " 'phase_space': ['physic',\n",
       "  'ideal',\n",
       "  'space',\n",
       "  'coordinate',\n",
       "  'dimension',\n",
       "  'represent',\n",
       "  'variable',\n",
       "  'required',\n",
       "  'describe',\n",
       "  'system',\n",
       "  'substance'],\n",
       " 'event': ['something', 'happens', 'given', 'place', 'time'],\n",
       " 'process': ['sustained',\n",
       "  'phenomenon',\n",
       "  'one',\n",
       "  'marked',\n",
       "  'gradual',\n",
       "  'change',\n",
       "  'series',\n",
       "  'state'],\n",
       " 'group': ['number', 'entity', 'member', 'considered', 'unit'],\n",
       " 'relation': ['usually',\n",
       "  'plural',\n",
       "  'mutual',\n",
       "  'dealing',\n",
       "  'connection',\n",
       "  'among',\n",
       "  'person',\n",
       "  'group'],\n",
       " 'possession': ['anything', 'owned', 'possessed'],\n",
       " 'social_relation': ['relation', 'living', 'organism', 'especially', 'people'],\n",
       " 'communication': ['something', 'communicated', 'people', 'group'],\n",
       " 'measure': ['much', 'many', 'something', 'quantify'],\n",
       " 'phenomenon': ['state',\n",
       "  'process',\n",
       "  'known',\n",
       "  'sens',\n",
       "  'rather',\n",
       "  'intuition',\n",
       "  'reasoning'],\n",
       " 'kindness': ['kind', 'act'],\n",
       " 'abdominoplasty': ['cosmetic',\n",
       "  'surgery',\n",
       "  'abdomen',\n",
       "  'remove',\n",
       "  'wrinkle',\n",
       "  'tighten',\n",
       "  'skin',\n",
       "  'stomach'],\n",
       " 'accomplishment': ['action', 'accomplishing', 'something'],\n",
       " 'agon': ['festivity',\n",
       "  'ancient',\n",
       "  'greece',\n",
       "  'competitor',\n",
       "  'contended',\n",
       "  'prize'],\n",
       " 'alienation': ['action',\n",
       "  'alienating',\n",
       "  'action',\n",
       "  'causing',\n",
       "  'become',\n",
       "  'unfriendly'],\n",
       " 'application': ['action', 'putting', 'something', 'operation'],\n",
       " 'beachhead': ['initial', 'accomplishment', 'open', 'way', 'development'],\n",
       " 'cakewalk': ['easy', 'accomplishment'],\n",
       " 'feat': ['notable', 'achievement'],\n",
       " 'masterpiece': ['outstanding', 'achievement'],\n",
       " 'masterstroke': ['achievement', 'demonstrating', 'great', 'skill', 'mastery'],\n",
       " 'credit': ['recognition',\n",
       "  'college',\n",
       "  'university',\n",
       "  'course',\n",
       "  'study',\n",
       "  'successfully',\n",
       "  'completed',\n",
       "  'typically',\n",
       "  'measured',\n",
       "  'semester',\n",
       "  'hour'],\n",
       " 'action': ['something', 'done', 'usually', 'opposed', 'something', 'said'],\n",
       " 'res_gestae': ['thing', 'done'],\n",
       " 'course': ['mode', 'action'],\n",
       " 'blind_alley': ['figurative',\n",
       "  'course',\n",
       "  'action',\n",
       "  'unproductive',\n",
       "  'offer',\n",
       "  'hope',\n",
       "  'improvement'],\n",
       " 'collision_course': ['course',\n",
       "  'action',\n",
       "  'following',\n",
       "  'given',\n",
       "  'idea',\n",
       "  'lead',\n",
       "  'conflict',\n",
       "  'continues',\n",
       "  'unabated'],\n",
       " 'interaction': ['mutual', 'reciprocal', 'action', 'interacting'],\n",
       " 'interplay': ['reciprocal', 'action', 'reaction'],\n",
       " 'contact': ['close', 'interaction'],\n",
       " 'brush': ['contact', 'something', 'dangerous', 'undesirable'],\n",
       " 'eye_contact': ['contact', 'occurs', 'two', 'people', 'look', 'directly'],\n",
       " 'fetch': ['action', 'fetching'],\n",
       " 'placement': ['contact',\n",
       "  'established',\n",
       "  'applicant',\n",
       "  'prospective',\n",
       "  'employee'],\n",
       " 'interchange': ['mutual',\n",
       "  'interaction',\n",
       "  'activity',\n",
       "  'reciprocating',\n",
       "  'exchanging',\n",
       "  'especially',\n",
       "  'information'],\n",
       " 'reciprocity': ['mutual', 'exchange', 'commercial', 'privilege'],\n",
       " 'cross-fertilization': ['interchange',\n",
       "  'different',\n",
       "  'culture',\n",
       "  'different',\n",
       "  'way',\n",
       "  'thinking',\n",
       "  'mutually',\n",
       "  'productive',\n",
       "  'beneficial'],\n",
       " 'dealings': ['social', 'verbal', 'interchange', 'usually', 'followed'],\n",
       " 'playing': ['action', 'taking', 'part', 'game', 'sport', 'recreation'],\n",
       " 'boondoggle': ['work', 'little', 'value', 'done', 'merely', 'look', 'busy'],\n",
       " 'bowling': ['playing', 'game', 'tenpin', 'duckpin', 'etc'],\n",
       " 'acquiring': ['act', 'acquiring', 'something'],\n",
       " 'causing': ['act', 'causing', 'something', 'happen'],\n",
       " 'delivery': ['act', 'delivering', 'child'],\n",
       " 'departure': ['act', 'departing'],\n",
       " 'derring-do': ['brave', 'heroic', 'feat'],\n",
       " 'discovery': ['act', 'discovering', 'something'],\n",
       " 'disposal': ['act', 'mean', 'getting', 'rid', 'something'],\n",
       " 'hit': ['conspicuous', 'success'],\n",
       " 'implementation': ['act',\n",
       "  'implementing',\n",
       "  'providing',\n",
       "  'practical',\n",
       "  'mean',\n",
       "  'accomplishing',\n",
       "  'something',\n",
       "  'carrying',\n",
       "  'effect'],\n",
       " 'egress': ['act', 'coming', 'going', 'becoming', 'apparent'],\n",
       " 'equalization': ['act', 'making', 'equal', 'uniform'],\n",
       " 'exhumation': ['act',\n",
       "  'digging',\n",
       "  'something',\n",
       "  'ground',\n",
       "  'especially',\n",
       "  'corpse',\n",
       "  'buried'],\n",
       " 'mitzvah': ['judaism', 'good', 'deed', 'performed', 'religious', 'duty'],\n",
       " 'propulsion': ['act', 'propelling'],\n",
       " 'rally': ['feat', 'mustering', 'strength', 'renewed', 'effort'],\n",
       " 'recovery': ['act',\n",
       "  'regaining',\n",
       "  'saving',\n",
       "  'something',\n",
       "  'lost',\n",
       "  'danger',\n",
       "  'becoming',\n",
       "  'lost'],\n",
       " 'running_away': ['act',\n",
       "  'leaving',\n",
       "  'without',\n",
       "  'permission',\n",
       "  'place',\n",
       "  'expected'],\n",
       " 'stunt': ['difficult',\n",
       "  'unusual',\n",
       "  'dangerous',\n",
       "  'feat',\n",
       "  'usually',\n",
       "  'done',\n",
       "  'gain',\n",
       "  'attention'],\n",
       " 'touch': ['act', 'putting', 'two', 'thing', 'together', 'space'],\n",
       " 'tour_de_force': ['masterly', 'brilliant', 'feat'],\n",
       " 'performance': ['recognized', 'accomplishment'],\n",
       " 'overachievement': ['better',\n",
       "  'expected',\n",
       "  'performance',\n",
       "  'better',\n",
       "  'might',\n",
       "  'predicted',\n",
       "  'intelligence',\n",
       "  'test'],\n",
       " 'underachievement': ['poorer',\n",
       "  'expected',\n",
       "  'performance',\n",
       "  'poorer',\n",
       "  'might',\n",
       "  'predicted',\n",
       "  'intelligence',\n",
       "  'test'],\n",
       " 'record': ['extreme',\n",
       "  'attainment',\n",
       "  'best',\n",
       "  'worst',\n",
       "  'performance',\n",
       "  'ever',\n",
       "  'attested',\n",
       "  'sport'],\n",
       " 'fait_accompli': ['irreversible', 'accomplishment'],\n",
       " 'arrival': ['act', 'arriving', 'certain', 'place'],\n",
       " 'attainment': ['act', 'achieving', 'aim'],\n",
       " 'advent': ['arrival', 'awaited', 'especially', 'something', 'momentous'],\n",
       " 'incursion': ['mistake', 'incurring', 'liability', 'blame'],\n",
       " 'intrusion': ['entrance', 'force', 'without', 'permission', 'welcome'],\n",
       " 'irruption': ['sudden', 'violent', 'entrance', 'bursting'],\n",
       " 'entree': ['act', 'entering'],\n",
       " 'entail': ['act',\n",
       "  'entailing',\n",
       "  'property',\n",
       "  'creation',\n",
       "  'fee',\n",
       "  'tail',\n",
       "  'fee',\n",
       "  'simple'],\n",
       " 'registration': ['act', 'enrolling'],\n",
       " 'appearance': ['act', 'appearing', 'public', 'view'],\n",
       " 'apparition': ['act', 'appearing', 'becoming', 'visible', 'unexpectedly'],\n",
       " 'emergence': ['act', 'emerging'],\n",
       " 'reappearance': ['act', 'someone', 'appearing'],\n",
       " 'comeback': ['return', 'celebrity', 'previously', 'successful', 'activity'],\n",
       " 'return': ['coming', 'returning', 'home'],\n",
       " 'repatriation': ['act', 'returning', 'country', 'origin'],\n",
       " 'penetration': ['act', 'entering', 'something'],\n",
       " 'interpenetration': ['mutual', 'penetration', 'diffusion'],\n",
       " 'market_penetration': ['extent',\n",
       "  'product',\n",
       "  'recognized',\n",
       "  'bought',\n",
       "  'customer',\n",
       "  'particular',\n",
       "  'market'],\n",
       " 'anchorage': ['act', 'anchoring'],\n",
       " 'docking': ['act', 'securing', 'arriving', 'vessel', 'rope'],\n",
       " 'landing': ['act', 'coming', 'earth', 'surface'],\n",
       " 'forced_landing': ['unscheduled',\n",
       "  'airplane',\n",
       "  'landing',\n",
       "  'made',\n",
       "  'circumstance',\n",
       "  'engine',\n",
       "  'failure',\n",
       "  'adverse',\n",
       "  'weather',\n",
       "  'pilot',\n",
       "  'control'],\n",
       " 'breaking_away': ['departing', 'hastily'],\n",
       " 'farewell': ['act', 'departing', 'politely'],\n",
       " 'french_leave': ['abrupt',\n",
       "  'unannounced',\n",
       "  'departure',\n",
       "  'without',\n",
       "  'saying',\n",
       "  'farewell'],\n",
       " 'valediction': ['act', 'saying', 'farewell'],\n",
       " 'disappearance': ['act', 'leaving', 'secretly', 'without', 'explanation'],\n",
       " 'vanishing': ['sudden', 'disappearance', 'sight'],\n",
       " 'withdrawal': ['act', 'withdrawing'],\n",
       " 'effacement': ['withdrawing', 'background', 'making', 'inconspicuous'],\n",
       " 'retreat': ['military',\n",
       "  'withdrawal',\n",
       "  'troop',\n",
       "  'favorable',\n",
       "  'position',\n",
       "  'escape',\n",
       "  'enemy',\n",
       "  'superior',\n",
       "  'force',\n",
       "  'defeat'],\n",
       " 'retirement': ['withdrawal', 'prayer', 'study', 'meditation'],\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "NjVMy4HGIgdr"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_wordnet_pairs(definitions, word_to_id):\n",
    "    pairs = []\n",
    "    for word, tokens in definitions.items():\n",
    "        if word not in word_to_id:\n",
    "            word_id = word_to_id['<UNK>']\n",
    "        else:\n",
    "            word_id = word_to_id[word]\n",
    "\n",
    "        for token in tokens:\n",
    "            if token in word_to_id:\n",
    "                token_id = word_to_id[token]\n",
    "            else:\n",
    "                token_id = word_to_id['<UNK>']\n",
    "            pairs.append((word_id, token_id))\n",
    "    # Remove duplicates\n",
    "    pairs = list(set(pairs))\n",
    "    return pairs\n",
    "\n",
    "wordnet_pairs = generate_wordnet_pairs(definitions, word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbK01bpOsizA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "JT-C_iDfsczb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(pairs, test_size=0.2, val_size=0.1, random_seed=42):\n",
    "    train_val_pairs, test_pairs = train_test_split(pairs, test_size=test_size, random_state=random_seed)\n",
    "    train_pairs, val_pairs = train_test_split(train_val_pairs, test_size=val_size, random_state=random_seed)\n",
    "    return train_pairs, val_pairs, test_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "n0Oc3SCusiJ3"
   },
   "outputs": [],
   "source": [
    "train_pairs, val_pairs, test_pairs = split_data(wordnet_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Gf55U2PWJrzm",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2b7c25e6-a8d4-4f01-f083-0b5d7134f06b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "UACnmlmJJtWq"
   },
   "outputs": [],
   "source": [
    "def generate_negative_samples(pairs, vocab_size, num_negatives=5, random_seed=42):\n",
    "    random.seed(random_seed)\n",
    "    pairs_set = set(pairs)\n",
    "    negatives = []\n",
    "    for word_id, context_id in pairs_set:\n",
    "        for _ in range(num_negatives):\n",
    "            negative_id = random.randint(0, vocab_size - 1)\n",
    "            while (word_id, negative_id) in pairs_set or negative_id == context_id:\n",
    "                negative_id = random.randint(0, vocab_size - 1)\n",
    "            negatives.append((word_id, negative_id))\n",
    "    # Remove duplicates\n",
    "    negatives = list(set(negatives))\n",
    "    return negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "kOhcOpsOKn6o"
   },
   "outputs": [],
   "source": [
    "train_negatives = generate_negative_samples(train_pairs, vocab_size)\n",
    "val_negatives = generate_negative_samples(val_pairs, vocab_size)\n",
    "test_negatives = generate_negative_samples(test_pairs, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "X172x5P6LIyg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "24MSHtAhK_nL"
   },
   "outputs": [],
   "source": [
    "def prepare_training_data(pairs, negative_pairs, word_to_id):\n",
    "    data = pairs + negative_pairs\n",
    "    random.shuffle(data)\n",
    "    pairs_set = set(pairs)\n",
    "    words, contexts, labels = [], [], []\n",
    "    for word_id, context_id in data:\n",
    "        words.append(word_id)\n",
    "        contexts.append(context_id)\n",
    "        labels.append(1 if (word_id, context_id) in pairs_set else 0)\n",
    "    return torch.tensor(words, dtype=torch.long), torch.tensor(contexts, dtype=torch.long), torch.tensor(labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "9axwSFTPs4bX"
   },
   "outputs": [],
   "source": [
    "train_word_ids, train_context_ids, train_labels = prepare_training_data(train_pairs, train_negatives, word_to_id)\n",
    "val_word_ids, val_context_ids, val_labels = prepare_training_data(val_pairs, val_negatives, word_to_id)\n",
    "test_word_ids, test_context_ids, test_labels = prepare_training_data(test_pairs, test_negatives, word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "id": "4xcVT53yMcko"
   },
   "outputs": [],
   "source": [
    "pos_weights = {\n",
    "    'n': 0.8,\n",
    "    'v': 0.78,\n",
    "    'a': 0.7,\n",
    "    'r': 0.25,\n",
    "    's': 0.7,\n",
    "    'no_pos': 0.1\n",
    "}\n",
    "\n",
    "# Function to get POS weight\n",
    "def get_pos_weight(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    if not synsets:\n",
    "        return pos_weights['no_pos']\n",
    "    # Use the first synset (most common sense)\n",
    "    pos = synsets[0].pos()\n",
    "    return pos_weights.get(pos, pos_weights['no_pos'])\n",
    "\n",
    "words_pos_weights = {}\n",
    "for word in word_to_id.keys():\n",
    "    words_pos_weights[word] = get_pos_weight(word)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import torch.nn as nn\n",
    "\n",
    "# Assuming `train_labels` is a list or numpy array of labels in the training set\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels.numpy()\n",
    ")\n",
    "\n",
    "# Convert to tensor and assign to device\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "batch_size = 4096\n",
    "\n",
    "train_dataset = TensorDataset(train_word_ids, train_context_ids, train_labels)\n",
    "val_dataset = TensorDataset(val_word_ids, val_context_ids, val_labels)\n",
    "test_dataset = TensorDataset(test_word_ids, test_context_ids, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "train_weights = [class_weights[label.long()] for label in train_labels]\n",
    "train_weights_tensor = torch.tensor(train_weights, dtype=torch.float32)\n",
    "\n",
    "# Create a weighted random sampler\n",
    "train_sampler = WeightedRandomSampler(train_weights_tensor, len(train_weights_tensor))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "test_weights = [class_weights[label.long()] for label in test_labels]\n",
    "test_weights_tensor = torch.tensor(test_weights, dtype=torch.float32)\n",
    "\n",
    "# Create a weighted random sampler\n",
    "test_sampler = WeightedRandomSampler(test_weights_tensor, len(test_weights_tensor))\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "\n",
    "val_weights = [class_weights[label.long()] for label in val_labels]\n",
    "val_weights_tensor = torch.tensor(val_weights, dtype=torch.float32)\n",
    "\n",
    "# Create a weighted random sampler\n",
    "val_sampler = WeightedRandomSampler(val_weights_tensor, len(val_weights_tensor))\n",
    "\n",
    "val_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 96081\n",
      "Training Pairs: 367999\n",
      "Validation Pairs: 40889\n",
      "Test Pairs: 102222\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "print(f\"Training Pairs: {len(train_pairs)}\")\n",
    "print(f\"Validation Pairs: {len(val_pairs)}\")\n",
    "print(f\"Test Pairs: {len(test_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "id": "jJp-_5DKK77_"
   },
   "outputs": [],
   "source": [
    "class WordNetEmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim=256, dropout_rate=0.4):\n",
    "        super(WordNetEmbeddingModel, self).__init__()\n",
    "        self.input_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.output_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.hidden = nn.Linear(embedding_dim * 2, hidden_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_dim, 1)  # Binary classification\n",
    "\n",
    "    def forward(self, word_ids, context_ids):\n",
    "        # Get input and output embeddings for words and contexts\n",
    "        input_vectors = self.input_embeddings(word_ids)  # Shape: (batch_size, embedding_dim)\n",
    "        context_vectors = self.output_embeddings(context_ids)  # Shape: (batch_size, embedding_dim)\n",
    "\n",
    "        # Concatenate word and context embeddings\n",
    "        combined = torch.cat([input_vectors, context_vectors], dim=1)  # Shape: (batch_size, embedding_dim * 2)\n",
    "        # combined = self.dropout(combined)\n",
    "\n",
    "        # Pass through hidden layers\n",
    "        hidden = self.hidden(combined)  # Shape: (batch_size, hidden_dim)\n",
    "        # hidden = self.activation(hidden)\n",
    "        # hidden = self.dropout(hidden)\n",
    "\n",
    "        # Output layer\n",
    "        scores = self.output(hidden)  # Shape: (batch_size, 1)\n",
    "        scores = torch.squeeze(scores, dim=-1)  # Remove the last dimension (1)\n",
    "\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "id": "2VVUZ5aobjjE"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class POSWeightedLoss(nn.Module):\n",
    "    def __init__(self, pos_weights, id_to_word, class_weights, lambda_div=0.1):\n",
    "        \"\"\"\n",
    "        A loss function that combines BCEWithLogitsLoss with a diversity penalty.\n",
    "        \n",
    "        Args:\n",
    "            pos_weights (dict): POS-based weights for positive samples.\n",
    "            id_to_word (dict): Mapping from IDs to words.\n",
    "            class_weights (torch.Tensor): Weights for class imbalance correction.\n",
    "            lambda_div (float): Weight for the diversity penalty term.\n",
    "        \"\"\"\n",
    "        super(POSWeightedLoss, self).__init__()\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self.pos_weights = pos_weights\n",
    "        self.id_to_word = id_to_word\n",
    "        self.class_weights = class_weights\n",
    "        self.lambda_div = lambda_div\n",
    "\n",
    "    def diversity_loss(self, embeddings):\n",
    "        \"\"\"\n",
    "        Compute a diversity penalty to spread embeddings apart.\n",
    "        \n",
    "        Args:\n",
    "            embeddings (torch.Tensor): Word embeddings (batch_size, embedding_dim).\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Scalar diversity penalty value.\n",
    "        \"\"\"\n",
    "        normalized = F.normalize(embeddings, p=2, dim=1)  # Normalize embeddings\n",
    "        similarity_matrix = torch.mm(normalized, normalized.T)  # Cosine similarity\n",
    "        identity = torch.eye(similarity_matrix.size(0), device=similarity_matrix.device)  # Diagonal identity matrix\n",
    "        diversity_penalty = ((similarity_matrix - identity) ** 2).mean()  # Minimize non-diagonal similarities\n",
    "        return diversity_penalty\n",
    "\n",
    "    def forward(self, scores, output_ids, batch_labels, embeddings):\n",
    "        \"\"\"\n",
    "        Compute the loss with diversity penalty.\n",
    "        \n",
    "        Args:\n",
    "            scores (torch.Tensor): Logits from the model.\n",
    "            output_ids (torch.Tensor): Context word IDs.\n",
    "            batch_labels (torch.Tensor): Labels (1 for positive, 0 for negative).\n",
    "            embeddings (torch.Tensor): Embeddings from the model for the current batch.\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Adjusted loss value.\n",
    "        \"\"\"\n",
    "        loss = self.criterion(scores, batch_labels)\n",
    "        \n",
    "        pos_weights_tensor = torch.tensor(\n",
    "            [self.pos_weights.get(self.id_to_word[output_id.item()], 1.0) for output_id in output_ids],\n",
    "            device=scores.device\n",
    "        )\n",
    "        adjusted_weights = batch_labels * pos_weights_tensor * self.class_weights[1] + (1 - batch_labels) * self.class_weights[0]\n",
    "        weighted_loss = (loss * adjusted_weights).mean()\n",
    "\n",
    "        # Compute diversity penalty\n",
    "        diversity_penalty = self.diversity_loss(embeddings)\n",
    "\n",
    "        # Combine the losses\n",
    "        total_loss = weighted_loss + self.lambda_div * diversity_penalty\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Q6hOd__qZuR",
    "outputId": "204543df-0c74-4571-aa04-a23bbb3acbcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model, loss function, optimizer, and scheduler\n",
    "model = WordNetEmbeddingModel(vocab_size, embedding_dim).to(device)\n",
    "\n",
    "\n",
    "class_weights = class_weights.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=5, min_lr = 1e-7)\n",
    "criterion = POSWeightedLoss(pos_weights=words_pos_weights, id_to_word=id_to_word, class_weights=class_weights).to(device)\n",
    "\n",
    "patience = 12  # Number of epochs to wait for improvement\n",
    "min_delta = 0.000005  # Minimum change in loss to be considered an improvement\n",
    "best_val_loss = float('inf')  # Initialize best loss to infinity\n",
    "epochs_without_improvement = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "id": "E7TlBtf-uRBx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for batch_words, batch_contexts, batch_labels in dataloader:\n",
    "            batch_words = batch_words.to(device)\n",
    "            batch_contexts = batch_contexts.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            scores = model(batch_words, batch_contexts)\n",
    "            predictions = torch.sigmoid(scores) >= 0.5\n",
    "\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_scores.extend(scores.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
    "    roc_auc = roc_auc_score(all_labels, all_scores) if len(set(all_labels)) > 1 else float('nan')\n",
    "    return accuracy, precision, recall, f1, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3u_hPNRvuEd5",
    "outputId": "0071fc64-d03d-437b-fe30-e4e79ed3c14b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: 100%|██████████| 539/539 [00:54<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.5168, Val Loss=0.3616, Accuracy=0.7724, Precision=0.4186, Recall=0.9463, F1=0.5804, ROC-AUC=0.9449, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000: 100%|██████████| 539/539 [00:54<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=0.2783, Val Loss=0.2884, Accuracy=0.8301, Precision=0.4934, Recall=0.9672, F1=0.6534, ROC-AUC=0.9635, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000: 100%|██████████| 539/539 [00:54<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=0.2383, Val Loss=0.2706, Accuracy=0.8408, Precision=0.5109, Recall=0.9759, F1=0.6707, ROC-AUC=0.9654, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000: 100%|██████████| 539/539 [00:53<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=0.2228, Val Loss=0.2659, Accuracy=0.8469, Precision=0.5193, Recall=0.9783, F1=0.6785, ROC-AUC=0.9661, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000: 100%|██████████| 539/539 [00:54<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=0.2166, Val Loss=0.2531, Accuracy=0.8551, Precision=0.5361, Recall=0.9786, F1=0.6927, ROC-AUC=0.9671, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000: 100%|██████████| 539/539 [00:53<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=0.2138, Val Loss=0.2523, Accuracy=0.8536, Precision=0.5329, Recall=0.9798, F1=0.6903, ROC-AUC=0.9675, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000: 100%|██████████| 539/539 [00:55<00:00,  9.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=0.2120, Val Loss=0.2538, Accuracy=0.8551, Precision=0.5339, Recall=0.9810, F1=0.6915, ROC-AUC=0.9678, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000: 100%|██████████| 539/539 [00:53<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=0.2110, Val Loss=0.2561, Accuracy=0.8563, Precision=0.5342, Recall=0.9815, F1=0.6918, ROC-AUC=0.9680, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000: 100%|██████████| 539/539 [00:53<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=0.2104, Val Loss=0.2561, Accuracy=0.8568, Precision=0.5380, Recall=0.9799, F1=0.6946, ROC-AUC=0.9677, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000: 100%|██████████| 539/539 [00:54<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=0.2106, Val Loss=0.2482, Accuracy=0.8598, Precision=0.5444, Recall=0.9803, F1=0.7001, ROC-AUC=0.9679, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000: 100%|██████████| 539/539 [00:53<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=0.2105, Val Loss=0.2610, Accuracy=0.8554, Precision=0.5343, Recall=0.9794, F1=0.6914, ROC-AUC=0.9669, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000: 100%|██████████| 539/539 [00:54<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=0.2102, Val Loss=0.2589, Accuracy=0.8562, Precision=0.5364, Recall=0.9825, F1=0.6939, ROC-AUC=0.9679, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000: 100%|██████████| 539/539 [00:54<00:00,  9.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=0.2101, Val Loss=0.2553, Accuracy=0.8584, Precision=0.5392, Recall=0.9819, F1=0.6961, ROC-AUC=0.9685, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000: 100%|██████████| 539/539 [00:53<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=0.2085, Val Loss=0.2524, Accuracy=0.8599, Precision=0.5440, Recall=0.9806, F1=0.6998, ROC-AUC=0.9673, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000: 100%|██████████| 539/539 [00:53<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=0.2086, Val Loss=0.2562, Accuracy=0.8577, Precision=0.5380, Recall=0.9829, F1=0.6954, ROC-AUC=0.9671, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000: 100%|██████████| 539/539 [00:54<00:00,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=0.2073, Val Loss=0.2538, Accuracy=0.8589, Precision=0.5404, Recall=0.9839, F1=0.6976, ROC-AUC=0.9681, LR: [0.001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000: 100%|██████████| 539/539 [00:53<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss=0.2017, Val Loss=0.2458, Accuracy=0.8664, Precision=0.5555, Recall=0.9879, F1=0.7111, ROC-AUC=0.9690, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000: 100%|██████████| 539/539 [00:53<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss=0.1946, Val Loss=0.2402, Accuracy=0.8720, Precision=0.5648, Recall=0.9889, F1=0.7190, ROC-AUC=0.9697, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000: 100%|██████████| 539/539 [00:54<00:00,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss=0.1917, Val Loss=0.2407, Accuracy=0.8734, Precision=0.5671, Recall=0.9905, F1=0.7213, ROC-AUC=0.9705, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000: 100%|██████████| 539/539 [00:52<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss=0.1895, Val Loss=0.2398, Accuracy=0.8741, Precision=0.5677, Recall=0.9915, F1=0.7220, ROC-AUC=0.9704, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000: 100%|██████████| 539/539 [00:54<00:00,  9.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss=0.1883, Val Loss=0.2362, Accuracy=0.8751, Precision=0.5685, Recall=0.9908, F1=0.7225, ROC-AUC=0.9703, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000: 100%|██████████| 539/539 [00:56<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss=0.1876, Val Loss=0.2329, Accuracy=0.8759, Precision=0.5732, Recall=0.9916, F1=0.7265, ROC-AUC=0.9706, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000: 100%|██████████| 539/539 [00:52<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss=0.1871, Val Loss=0.2347, Accuracy=0.8767, Precision=0.5739, Recall=0.9925, F1=0.7273, ROC-AUC=0.9699, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000: 100%|██████████| 539/539 [00:53<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss=0.1867, Val Loss=0.2353, Accuracy=0.8751, Precision=0.5729, Recall=0.9929, F1=0.7265, ROC-AUC=0.9698, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000: 100%|██████████| 539/539 [00:59<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss=0.1868, Val Loss=0.2369, Accuracy=0.8757, Precision=0.5725, Recall=0.9926, F1=0.7262, ROC-AUC=0.9702, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000: 100%|██████████| 539/539 [00:53<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss=0.1857, Val Loss=0.2382, Accuracy=0.8760, Precision=0.5725, Recall=0.9921, F1=0.7260, ROC-AUC=0.9701, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000: 100%|██████████| 539/539 [00:53<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss=0.1863, Val Loss=0.2357, Accuracy=0.8756, Precision=0.5729, Recall=0.9921, F1=0.7264, ROC-AUC=0.9700, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000: 100%|██████████| 539/539 [00:54<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss=0.1860, Val Loss=0.2315, Accuracy=0.8769, Precision=0.5766, Recall=0.9924, F1=0.7294, ROC-AUC=0.9699, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000: 100%|██████████| 539/539 [00:55<00:00,  9.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss=0.1860, Val Loss=0.2351, Accuracy=0.8758, Precision=0.5739, Recall=0.9923, F1=0.7272, ROC-AUC=0.9700, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000: 100%|██████████| 539/539 [00:54<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss=0.1852, Val Loss=0.2321, Accuracy=0.8766, Precision=0.5735, Recall=0.9925, F1=0.7270, ROC-AUC=0.9700, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000: 100%|██████████| 539/539 [00:53<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss=0.1858, Val Loss=0.2333, Accuracy=0.8750, Precision=0.5705, Recall=0.9915, F1=0.7243, ROC-AUC=0.9697, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000: 100%|██████████| 539/539 [00:53<00:00,  9.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss=0.1850, Val Loss=0.2383, Accuracy=0.8756, Precision=0.5730, Recall=0.9925, F1=0.7266, ROC-AUC=0.9699, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000: 100%|██████████| 539/539 [00:53<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss=0.1856, Val Loss=0.2359, Accuracy=0.8761, Precision=0.5706, Recall=0.9936, F1=0.7249, ROC-AUC=0.9706, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000: 100%|██████████| 539/539 [00:53<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss=0.1852, Val Loss=0.2350, Accuracy=0.8757, Precision=0.5718, Recall=0.9925, F1=0.7256, ROC-AUC=0.9703, LR: [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000: 100%|██████████| 539/539 [00:55<00:00,  9.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss=0.1856, Val Loss=0.2341, Accuracy=0.8754, Precision=0.5707, Recall=0.9936, F1=0.7250, ROC-AUC=0.9703, LR: [1e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000: 100%|██████████| 539/539 [00:53<00:00, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss=0.1847, Val Loss=0.2353, Accuracy=0.8754, Precision=0.5714, Recall=0.9931, F1=0.7255, ROC-AUC=0.9703, LR: [1e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000: 100%|██████████| 539/539 [00:52<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss=0.1850, Val Loss=0.2338, Accuracy=0.8761, Precision=0.5733, Recall=0.9929, F1=0.7269, ROC-AUC=0.9703, LR: [1e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000: 100%|██████████| 539/539 [00:52<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss=0.1839, Val Loss=0.2327, Accuracy=0.8755, Precision=0.5709, Recall=0.9934, F1=0.7251, ROC-AUC=0.9698, LR: [1e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000: 100%|██████████| 539/539 [00:54<00:00,  9.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss=0.1835, Val Loss=0.2373, Accuracy=0.8762, Precision=0.5728, Recall=0.9938, F1=0.7267, ROC-AUC=0.9703, LR: [1e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000: 100%|██████████| 539/539 [00:52<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss=0.1836, Val Loss=0.2321, Accuracy=0.8770, Precision=0.5742, Recall=0.9940, F1=0.7279, ROC-AUC=0.9708, LR: [1e-05]\n",
      "Early stopping triggered after 40 epochs.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    num_train_samples = 0\n",
    "\n",
    "    # Create a tqdm progress bar for the epoch\n",
    "    with tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch + 1}/{epochs}\") as pbar:\n",
    "        for batch_words, batch_contexts, batch_labels in train_dataloader:\n",
    "            batch_words = batch_words.to(device)\n",
    "            batch_contexts = batch_contexts.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scores = model(batch_words, batch_contexts)\n",
    "            embeddings = model.input_embeddings(batch_words)  \n",
    "            loss = criterion(scores, batch_contexts, batch_labels, embeddings)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item() * batch_labels.size(0)\n",
    "            num_train_samples += batch_labels.size(0)\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_train_samples\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    num_val_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_words, batch_contexts, batch_labels in val_dataloader:\n",
    "            batch_words = batch_words.to(device)\n",
    "            batch_contexts = batch_contexts.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            scores = model(batch_words, batch_contexts)\n",
    "            embeddings = model.input_embeddings(batch_words)  # Get input embeddings for diversity loss\n",
    "            loss = criterion(scores, batch_contexts, batch_labels, embeddings)\n",
    "            total_val_loss += loss.item() * batch_labels.size(0)\n",
    "            num_val_samples += batch_labels.size(0)\n",
    "\n",
    "    avg_val_loss = total_val_loss / num_val_samples\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Evaluation Metrics\n",
    "    val_accuracy, val_precision, val_recall, val_f1, val_roc_auc = evaluate(model, val_dataloader, device)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}, \"\n",
    "          f\"Accuracy={val_accuracy:.4f}, Precision={val_precision:.4f}, \"\n",
    "          f\"Recall={val_recall:.4f}, F1={val_f1:.4f}, ROC-AUC={val_roc_auc:.4f}, LR: {scheduler.get_last_lr()}\")\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        if avg_val_loss < best_val_loss-min_delta:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "            break  # Exit the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAcqgGuSkECg",
    "outputId": "bb69e1b1-d6de-440e-bfce-84a7c81cf33d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation:\n",
      "Accuracy: 0.8802\n",
      "Precision: 0.8582\n",
      "Recall: 0.9108\n",
      "F1-Score: 0.8837\n",
      "ROC-AUC: 0.9417\n"
     ]
    }
   ],
   "source": [
    "# Final Evaluation on Test Set\n",
    "def final_evaluation(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for batch_words, batch_contexts, batch_labels in dataloader:\n",
    "            batch_words = batch_words.to(device)\n",
    "            batch_contexts = batch_contexts.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            scores = model(batch_words, batch_contexts)\n",
    "            predictions = torch.sigmoid(scores) >= 0.5\n",
    "\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_scores.extend(scores.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
    "    roc_auc = roc_auc_score(all_labels, all_scores) if len(set(all_labels)) > 1 else float('nan')\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_roc_auc = final_evaluation(model, test_dataloader, device)\n",
    "print(f\"Test Set Evaluation:\\n\"\n",
    "      f\"Accuracy: {test_accuracy:.4f}\\n\"\n",
    "      f\"Precision: {test_precision:.4f}\\n\"\n",
    "      f\"Recall: {test_recall:.4f}\\n\"\n",
    "      f\"F1-Score: {test_f1:.4f}\\n\"\n",
    "      f\"ROC-AUC: {test_roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "epBa7tt1yHb8",
    "outputId": "04b5098d-173d-4779-989e-a6cfe6f5f4d9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAAIjCAYAAAAAxIqtAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAmThJREFUeJzs3Xd8U+XiBvDnZCdt05bulkJL2VBaBEFQBLVQQFmigospqMh1cL3cHw62oqDIFQcuBFEURcQBAgVBGRUUZO9RCpQuoE1nkibn98dp0oa2UEqb0T7fz+d8kpycc/LmTdA8fZcgiqIIIiIiIiIiqjGZqwtARERERETk6RisiIiIiIiIbhKDFRERERER0U1isCIiIiIiIrpJDFZEREREREQ3icGKiIiIiIjoJjFYERERERER3SQGKyIiIiIiopvEYEVERERERHSTGKyIqF4bNWoUoqKianTu9OnTIQhC7RbIzaSkpEAQBCxZssTpry0IAqZPn25/vGTJEgiCgJSUlOueGxUVhVGjRtVqeW7mu0JUU4IgYOLEia4uBhHVAgYrInIJQRCqtW3ZssXVRW3wnn32WQiCgJMnT1Z5zMsvvwxBELB//34nluzGpaWlYfr06di7d6+ri2JnC7dvvfWWq4tSLampqXjqqacQFRUFtVqN4OBgDB48GNu3b3d10Sp1rf++PPXUU64uHhHVIwpXF4CIGqZly5Y5PP7iiy+QlJRUYX+bNm1u6nU++eQTWK3WGp37yiuv4P/+7/9u6vXrg0cffRQLFy7E8uXLMXXq1EqP+frrrxEbG4sOHTrU+HUef/xxDB8+HGq1usbXuJ60tDTMmDEDUVFRiI+Pd3juZr4rDcX27dvRv39/AMATTzyBtm3bIj09HUuWLEGPHj3wv//9D//6179cXMqKevfujREjRlTY37JlSxeUhojqKwYrInKJxx57zOHxn3/+iaSkpAr7r1ZYWAidTlft11EqlTUqHwAoFAooFPzPZNeuXdG8eXN8/fXXlQar5ORknDlzBm+88cZNvY5cLodcLr+pa9yMm/muNARXrlzBAw88AK1Wi+3btyMmJsb+3KRJk5CYmIjnn38enTp1Qvfu3Z1WruLiYqhUKshkVXfCadmy5XX/20JEdLPYFZCI3FavXr3Qvn177N69G3feeSd0Oh1eeuklAMCPP/6Ie++9F+Hh4VCr1YiJicGsWbNgsVgcrnH1uJny3a4+/vhjxMTEQK1W49Zbb8Vff/3lcG5lY6xs4yFWr16N9u3bQ61Wo127dli3bl2F8m/ZsgWdO3eGRqNBTEwMPvroo2qP29q6dSsefPBBNGnSBGq1GpGRkXjhhRdQVFRU4f15e3vjwoULGDx4MLy9vREUFIQXX3yxQl3k5ORg1KhR8PX1hZ+fH0aOHImcnJzrlgWQWq2OHj2KPXv2VHhu+fLlEAQBDz/8MEwmE6ZOnYpOnTrB19cXXl5e6NGjBzZv3nzd16hsjJUoipg9ezYaN24MnU6Hu+66C4cOHapw7uXLl/Hiiy8iNjYW3t7e0Ov16NevH/bt22c/ZsuWLbj11lsBAKNHj7Z3B7ONL6tsjFVBQQH+/e9/IzIyEmq1Gq1atcJbb70FURQdjruR70VNZWZmYuzYsQgJCYFGo0FcXByWLl1a4bhvvvkGnTp1go+PD/R6PWJjY/G///3P/rzZbMaMGTPQokULaDQaBAQE4I477kBSUtI1X/+jjz5Ceno65s2b5xCqAECr1WLp0qUQBAEzZ84EAPz9998QBKHSMq5fvx6CIOCXX36x77tw4QLGjBmDkJAQe/0tXrzY4bwtW7ZAEAR88803eOWVVxAREQGdTgeDwXD9CryO8v+96d69O7RaLaKjo7Fo0aIKx1b3s7Barfjf//6H2NhYaDQaBAUFoW/fvvj7778rHHu9705eXh6ef/55hy6YvXv3rvTfJBG5Bv8US0Ru7dKlS+jXrx+GDx+Oxx57DCEhIQCkH+He3t6YNGkSvL298dtvv2Hq1KkwGAyYN2/eda+7fPly5OXl4cknn4QgCJg7dy7uv/9+nD59+rotF9u2bcOqVaswYcIE+Pj44N1338XQoUORmpqKgIAAAMA///yDvn37IiwsDDNmzIDFYsHMmTMRFBRUrff93XffobCwEE8//TQCAgKwa9cuLFy4EOfPn8d3333ncKzFYkFiYiK6du2Kt956Cxs3bsTbb7+NmJgYPP300wCkgDJo0CBs27YNTz31FNq0aYMffvgBI0eOrFZ5Hn30UcyYMQPLly/HLbfc4vDa3377LXr06IEmTZogOzsbn376KR5++GGMGzcOeXl5+Oyzz5CYmIhdu3ZV6H53PVOnTsXs2bPRv39/9O/fH3v27EGfPn1gMpkcjjt9+jRWr16NBx98ENHR0cjIyMBHH32Enj174vDhwwgPD0ebNm0wc+ZMTJ06FePHj0ePHj0AoMrWFVEUMXDgQGzevBljx45FfHw81q9fj//85z+4cOEC3nnnHYfjq/O9qKmioiL06tULJ0+exMSJExEdHY3vvvsOo0aNQk5ODp577jkAQFJSEh5++GHcc889ePPNNwEAR44cwfbt2+3HTJ8+HXPmzMETTzyBLl26wGAw4O+//8aePXvQu3fvKsvw888/Q6PR4KGHHqr0+ejoaNxxxx347bffUFRUhM6dO6NZs2b49ttvK3zPVqxYAX9/fyQmJgIAMjIycNttt9kDalBQEH799VeMHTsWBoMBzz//vMP5s2bNgkqlwosvvgij0QiVSnXN+isuLkZ2dnaF/Xq93uHcK1euoH///njooYfw8MMP49tvv8XTTz8NlUqFMWPGAKj+ZwEAY8eOxZIlS9CvXz888cQTKCkpwdatW/Hnn3+ic+fO9uOq89156qmnsHLlSkycOBFt27bFpUuXsG3bNhw5csTh3yQRuZBIROQGnnnmGfHq/yT17NlTBCAuWrSowvGFhYUV9j355JOiTqcTi4uL7ftGjhwpNm3a1P74zJkzIgAxICBAvHz5sn3/jz/+KAIQf/75Z/u+adOmVSgTAFGlUoknT56079u3b58IQFy4cKF934ABA0SdTideuHDBvu/EiROiQqGocM3KVPb+5syZIwqCIJ49e9bh/QEQZ86c6XBsx44dxU6dOtkfr169WgQgzp07176vpKRE7NGjhwhA/Pzzz69bpltvvVVs3LixaLFY7PvWrVsnAhA/+ugj+zWNRqPDeVeuXBFDQkLEMWPGOOwHIE6bNs3++PPPPxcBiGfOnBFFURQzMzNFlUol3nvvvaLVarUf99JLL4kAxJEjR9r3FRcXO5RLFKXPWq1WO9TNX3/9VeX7vfq7Yquz2bNnOxz3wAMPiIIgOHwHqvu9qIztOzlv3rwqj1mwYIEIQPzyyy/t+0wmk9itWzfR29tbNBgMoiiK4nPPPSfq9XqxpKSkymvFxcWJ99577zXLVBk/Pz8xLi7umsc8++yzIgBx//79oiiK4pQpU0SlUunwb81oNIp+fn4O34exY8eKYWFhYnZ2tsP1hg8fLvr6+tr/PWzevFkEIDZr1qzSfyOVAVDl9vXXX9uPs/335u2333Yoa3x8vBgcHCyaTCZRFKv/Wfz2228iAPHZZ5+tUKby3+fqfnd8fX3FZ555plrvmYhcg10BicitqdVqjB49usJ+rVZrv5+Xl4fs7Gz06NEDhYWFOHr06HWvO2zYMPj7+9sf21ovTp8+fd1zExISHLpCdejQAXq93n6uxWLBxo0bMXjwYISHh9uPa968Ofr163fd6wOO76+goADZ2dno3r07RFHEP//8U+H4q2c369Gjh8N7Wbt2LRQKhb0FC5DGNN3IRAOPPfYYzp8/jz/++MO+b/ny5VCpVHjwwQft17S1AFitVly+fBklJSXo3LnzDXdZ2rhxI0wmE/71r385dJ+8uvUCkL4ntjE2FosFly5dgre3N1q1alXjrlJr166FXC7Hs88+67D/3//+N0RRxK+//uqw/3rfi5uxdu1ahIaG4uGHH7bvUyqVePbZZ5Gfn4/ff/8dAODn54eCgoJrduvz8/PDoUOHcOLEiRsqQ15eHnx8fK55jO15W9e8YcOGwWw2Y9WqVfZjNmzYgJycHAwbNgyA1DL4/fffY8CAARBFEdnZ2fYtMTERubm5FT7DkSNHOvwbuZ5BgwYhKSmpwnbXXXc5HKdQKPDkk0/aH6tUKjz55JPIzMzE7t27AVT/s/j+++8hCAKmTZtWoTxXdweuznfHz88PO3fuRFpaWrXfNxE5F4MVEbm1iIiISrv5HDp0CEOGDIGvry/0ej2CgoLsg9Nzc3Ove90mTZo4PLaFrCtXrtzwubbzbedmZmaiqKgIzZs3r3BcZfsqk5qailGjRqFRo0b2cVM9e/YEUPH92cZuVFUeADh79izCwsLg7e3tcFyrVq2qVR4AGD58OORyOZYvXw5A6l71ww8/oF+/fg4hdenSpejQoYN9/E5QUBDWrFlTrc+lvLNnzwIAWrRo4bA/KCjI4fUAKcS98847aNGiBdRqNQIDAxEUFIT9+/ff8OuWf/3w8PAKYcI2U6WtfDbX+17cjLNnz6JFixYVJmi4uiwTJkxAy5Yt0a9fPzRu3BhjxoypMFZn5syZyMnJQcuWLREbG4v//Oc/1Zom38fHB3l5edc8xva8rc7i4uLQunVrrFixwn7MihUrEBgYiLvvvhsAkJWVhZycHHz88ccICgpy2Gx/VMnMzHR4nejo6OuWt7zGjRsjISGhwmbrWmwTHh4OLy8vh322mQNtY/+q+1mcOnUK4eHhaNSo0XXLV53vzty5c3Hw4EFERkaiS5cumD59eq2EdiKqPQxWROTWKvurdE5ODnr27Il9+/Zh5syZ+Pnnn5GUlGQfU1KdKbOrmn1OvGpSgto+tzosFgt69+6NNWvW4L///S9Wr16NpKQk+yQLV78/Z82kZxss//3338NsNuPnn39GXl4eHn30UfsxX375JUaNGoWYmBh89tlnWLduHZKSknD33XfX6VTmr7/+OiZNmoQ777wTX375JdavX4+kpCS0a9fOaVOo1/X3ojqCg4Oxd+9e/PTTT/bxYf369XMY43TnnXfi1KlTWLx4Mdq3b49PP/0Ut9xyCz799NNrXrtNmzY4duwYjEZjlcfs378fSqXSIQwPGzYMmzdvRnZ2NoxGI3766ScMHTrUPuOm7fN57LHHKm1VSkpKwu233+7wOjfSWuUJqvPdeeihh3D69GksXLgQ4eHhmDdvHtq1a1eh5ZSIXIeTVxCRx9myZQsuXbqEVatW4c4777TvP3PmjAtLVSY4OBgajabSBXWvtciuzYEDB3D8+HEsXbrUYe2d683adi1NmzbFpk2bkJ+f79BqdezYsRu6zqOPPop169bh119/xfLly6HX6zFgwAD78ytXrkSzZs2watUqh+5OlXWHqk6ZAeDEiRNo1qyZfX9WVlaFVqCVK1firrvuwmeffeawPycnB4GBgfbH1ZmRsfzrb9y4sUIXOFtXU1v5nKFp06bYv38/rFarQ0tJZWVRqVQYMGAABgwYAKvVigkTJuCjjz7Cq6++am8xbdSoEUaPHo3Ro0cjPz8fd955J6ZPn44nnniiyjLcd999SE5OxnfffVfp1OUpKSnYunUrEhISHILPsGHDMGPGDHz//fcICQmBwWDA8OHD7c8HBQXBx8cHFosFCQkJNa+kWpCWloaCggKHVqvjx48DgH3GyOp+FjExMVi/fj0uX75crVar6ggLC8OECRMwYcIEZGZm4pZbbsFrr71W7S7GRFS32GJFRB7H9tfd8n/NNZlM+OCDD1xVJAdyuRwJCQlYvXq1w3iIkydPVuuvy5W9P1EUHabMvlH9+/dHSUkJPvzwQ/s+i8WChQsX3tB1Bg8eDJ1Ohw8++AC//vor7r//fmg0mmuWfefOnUhOTr7hMickJECpVGLhwoUO11uwYEGFY+VyeYWWoe+++w4XLlxw2Gf7wVydaeb79+8Pi8WC9957z2H/O++8A0EQnPpjtn///khPT3foUldSUoKFCxfC29vb3k300qVLDufJZDL7os22lqarj/H29kbz5s2v2RIFAE8++SSCg4Pxn//8p0IXtOLiYowePRqiKFZY66xNmzaIjY3FihUrsGLFCoSFhTn8QUQul2Po0KH4/vvvcfDgwQqvm5WVdc1y1aaSkhJ89NFH9scmkwkfffQRgoKC0KlTJwDV/yyGDh0KURQxY8aMCq9zo62YFoulQpfW4OBghIeHX/dzIyLnYYsVEXmc7t27w9/fHyNHjsSzzz4LQRCwbNkyp3a5up7p06djw4YNuP322/H000/bf6C3b98ee/fuvea5rVu3RkxMDF588UVcuHABer0e33///U2N1RkwYABuv/12/N///R9SUlLQtm1brFq16obHH3l7e2Pw4MH2cVbluwECUqvGqlWrMGTIENx77704c+YMFi1ahLZt2yI/P/+GXsu2HtecOXNw3333oX///vjnn3/w66+/OrRC2V535syZGD16NLp3744DBw7gq6++cmjpAqRWBD8/PyxatAg+Pj7w8vJC165dKx2zM2DAANx11114+eWXkZKSgri4OGzYsAE//vgjnn/++QprOd2sTZs2obi4uML+wYMHY/z48fjoo48watQo7N69G1FRUVi5ciW2b9+OBQsW2FvUnnjiCVy+fBl33303GjdujLNnz2LhwoWIj4+3jwFq27YtevXqhU6dOqFRo0b4+++/7dN4X0tAQABWrlyJe++9F7fccgueeOIJtG3bFunp6ViyZAlOnjyJ//3vf5VOXz9s2DBMnToVGo0GY8eOrTA+6Y033sDmzZvRtWtXjBs3Dm3btsXly5exZ88ebNy4EZcvX65ptQKQWp2+/PLLCvtDQkIcppgPDw/Hm2++iZSUFLRs2RIrVqzA3r178fHHH9uXYajuZ3HXXXfh8ccfx7vvvosTJ06gb9++sFqt2Lp1K+66667r1nd5eXl5aNy4MR544AHExcXB29sbGzduxF9//YW33377puqGiGqRs6chJCKqTFXTrbdr167S47dv3y7edtttolarFcPDw8XJkyeL69evFwGImzdvth9X1XTrlU1tjaum/65quvXKpjxu2rSpw/TfoiiKmzZtEjt27CiqVCoxJiZG/PTTT8V///vfokajqaIWyhw+fFhMSEgQvb29xcDAQHHcuHH2KZjLTxU+cuRI0cvLq8L5lZX90qVL4uOPPy7q9XrR19dXfPzxx8V//vmn2tOt26xZs0YEIIaFhVWY4txqtYqvv/662LRpU1GtVosdO3YUf/nllwqfgyhef7p1URRFi8UizpgxQwwLCxO1Wq3Yq1cv8eDBgxXqu7i4WPz3v/9tP+72228Xk5OTxZ49e4o9e/Z0eN0ff/xRbNu2rX3qe9t7r6yMeXl54gsvvCCGh4eLSqVSbNGihThv3jyH6bJt76W634ur2b6TVW3Lli0TRVEUMzIyxNGjR4uBgYGiSqUSY2NjK3xuK1euFPv06SMGBweLKpVKbNKkifjkk0+KFy9etB8ze/ZssUuXLqKfn5+o1WrF1q1bi6+99pp9OvHrOXPmjDhu3DixSZMmolKpFAMDA8WBAweKW7durfKcEydO2N/Ptm3bKj0mIyNDfOaZZ8TIyEhRqVSKoaGh4j333CN+/PHH9mNs061/99131SqrKF57uvXy3w3bf2/+/vtvsVu3bqJGoxGbNm0qvvfee5WW9XqfhShKyw/MmzdPbN26tahSqcSgoCCxX79+4u7dux3Kd73vjtFoFP/zn/+IcXFxoo+Pj+jl5SXGxcWJH3zwQbXrgYjqniCKbvQnXiKiem7w4ME1muqaiOpWr169kJ2dXWl3RCKi6uAYKyKiOlJUVOTw+MSJE1i7di169erlmgIRERFRneEYKyKiOtKsWTOMGjUKzZo1w9mzZ/Hhhx9CpVJh8uTJri4aERER1TIGKyKiOtK3b198/fXXSE9Ph1qtRrdu3fD6669XWPCWiIiIPB/HWBEREREREd0kjrEiIiIiIiK6SQxWREREREREN4ljrCphtVqRlpYGHx8fCILg6uIQEREREZGLiKKIvLw8hIeHV1jgvDwGq0qkpaUhMjLS1cUgIiIiIiI3ce7cOTRu3LjK5xmsKuHj4wNAqjy9Xu/SspjNZmzYsAF9+vSBUql0aVnqM9az87CunYP17BysZ+dhXTsH69k5WM/OUxt1bTAYEBkZac8IVWGwqoSt+59er3eLYKXT6aDX6/kPrw6xnp2Hde0crGfnYD07D+vaOVjPzsF6dp7arOvrDRHi5BVEREREREQ3icGKiIiIiIjoJjFYERERERER3SSOsSIiIiIityeKIkpKSmCxWFxdlJtmNpuhUChQXFxcL96PO6tOXcvlcigUipteZonBioiIiIjcmslkwsWLF1FYWOjqotQKURQRGhqKc+fOcc3UOlbdutbpdAgLC4NKparxazFYEREREZHbslqtOHPmDORyOcLDw6FSqTw+jFitVuTn58Pb2/uaC87SzbteXYuiCJPJhKysLJw5cwYtWrSo8WfCYEVEREREbstkMsFqtSIyMhI6nc7VxakVVqsVJpMJGo2GwaqOVaeutVotlEolzp49az+2JvhJEhEREZHbYwChulQb3y9+Q4mIiIiIiG4SgxUREREREdFNYrAiIiIiIvIQUVFRWLBggauLQZVgsCIiIiIiqmWCIFS5yeVyvPHGGzW67l9//YXx48ffVNl69eqF559//qauQRVxVkAiIiIiolp28eJF+/0VK1Zg6tSpOHbsGABppjqr1Wp/XhRFWCwWKBTX/2keFBRU+4WlWsEWKyIiIiLyKKIootBU4pJNFMVqlTE0NNS++fr6QhAE++OjR48iMjISv/76Kzp16gS1Wo1t27bh1KlTGDRoEEJCQuDt7Y1bb70VGzdudLju1V0BBUHAp59+iiFDhkCn06FFixb46aefbqp+v//+e7Rr1w5qtRpRUVF4++23HZ7/4IMP0KJFC2g0GoSEhOCBBx6wP7dy5UrExsZCq9UiICAACQkJKCgouKnyeAq2WBERERGRRykyW9B26nqXvPbhmYnQqWrnJ/RLL72Et956C82aNYO/vz/OnTuH/v3747XXXoNarcYXX3yBAQMG4NixY2jSpEmV15kxYwbmzp2LefPmYeHChXj00Udx9uxZNGrU6IbLtHv3bjz00EOYPn06hg0bhh07dmDChAkICAjAqFGj8Pfff+PZZ5/FsmXL0L17d1y+fBlbt24FILXSPfzww5g7dy6GDBmCvLw8bN26tdph1NMxWBERERERucD06dPRu3dv++NGjRohLi7O/njWrFn44Ycf8NNPP2HixIlVXmfUqFF4+OGHAQCvv/463n33XezatQt9+/a94TLNnz8f99xzD1599VUAQMuWLXH48GHMmzcPo0aNQmpqKry8vHDffffBx8cHTZs2RceOHQFIwaqkpAT3338/mjZtCgCIjY294TJ4KgYrN7f1RDb2ZAvoaSyBn1Lp6uIQERERuZxWKcfhmYkue+3a0rlzZ4fH+fn5mD59OtasWWMPKUVFRUhNTb3mdTp06GC/7+XlBb1ej8zMzBqV6ciRIxg0aJDDvttvvx0LFiyAxWJB79690bRpUzRr1gx9+/ZF37597d0Q4+LicM899yA2NhaJiYno06cPHnjgAfj7+9eoLJ6GY6zc3Avf7cfSE3KkG4yuLgoRERGRWxAEATqVwiWbIAi19j68vLwcHr/44ov44Ycf8Prrr2Pr1q3Yu3cvYmNjYTKZrnkd5VV/fBcEwWFyjNrk4+ODPXv24Ouvv0ZYWBimTp2KuLg45OTkQC6XIykpCb/++ivatm2LhQsXolWrVjhz5kydlMXdMFi5OR+11KhoKDa7uCREREREVJe2b9+OUaNGYciQIYiNjUVoaChSUlKcWoY2bdpg+/btFcrVsmVLyOVSa51CoUBCQgLmzp2L/fv3IyUlBb/99hsAKdTdfvvtmDFjBv755x+oVCr88MMPTn0PrsKugG7OR6MEUIz84hJXF4WIiIiI6lCLFi2watUqDBgwAIIg4NVXX62zlqesrCzs3bvXYV9YWBj+/e9/49Zbb8WsWbMwbNgwJCcn47333sMHH3wAAPjll19w+vRp3HnnnfD398fatWthtVrRqlUr7Ny5E5s2bUKfPn0QHByMnTt3IisrC23atKmT9+BuGKzcnI9G+ojyGKyIiIiI6rX58+djzJgx6N69OwIDA/Hf//4XBoOhTl5r+fLlWL58ucO+WbNm4ZVXXsG3336LqVOnYtasWQgLC8PMmTMxatQoAICfnx9WrVqF6dOno7i4GC1atMDXX3+Ndu3a4ciRI/jjjz+wYMECGAwGNG3aFG+//Tb69etXJ+/B3TBYuTlbsDIwWBERERF5pFGjRtmDCQD06tULV65cgV6vdzguKirK3qXO5plnnnF4fHXXwMqmMs/JyblmebZs2XLN54cOHYqhQ4dW+twdd9xR5flt2rTBunXrrnnt+oxjrNyc3tZiZeQYKyIiIiIid8Vg5ea8NdIsL3lFbLEiIiIiInJXDFZurqzFisGKiIiIiMhdMVi5OU5eQURERETk/his3BzXsSIiIiIicn8MVm6OLVZERERERO6PwcrN+dgmr2CwIiIiIiJyWwxWbo4tVkRERERE7o/Bys1xVkAiIiIiIvfHYOXmbC1W+cYSWK0VV9YmIiIiovqrV69eeP755+2Po6KisGDBgmueIwgCVq9efdOvXVvXaSgYrNycbVZAUQTyTWy1IiIiIvIEAwYMQN++fSt9buvWrfD398f+/ftv+Lp//fUXxo8ff7PFczB9+nTEx8dX2H/x4kX069evVl/rakuWLIGfn1+dvoazMFi5ObVSDoUgtVQZijjlOhEREZEnGDt2LJKSknD+/PkKzy1ZsgQdO3ZEhw4dbvi6QUFB0Ol0tVHE6woNDYVarXbKa9UHDFYeoLQ3ICewICIiIgKkrjymAtdsYvWGZtx3330ICgrCkiVLHPbn5+dj5cqVeOyxx3Dp0iU8/PDDiIiIgE6nQ2xsLL7++utrXvfqroAnTpzAnXfeCY1Gg7Zt2yIpKanCOf/973/RsmVL6HQ6NGvWDK+++irMZukP9kuWLMGMGTOwb98+CIIAQRDsZb66K+CBAwdw9913Q6vVIiAgAOPHj0d+fr79+VGjRmHw4MF46623EBYWhoCAADzzzDP216qJ1NRUDBo0CN7e3tDr9XjooYeQkZFhf37fvn2466674OPjA71ej06dOuHvv/8GAJw9exYDBw5EVFQUfHx80K5dO6xdu7bGZbkeRZ1duZref/99zJs3D+np6YiLi8PChQvRpUuXSo9dsmQJRo8e7bBPrVajuLjY/lgURUybNg2ffPIJcnJycPvtt+PDDz9EixYt6vR91CWdHMg3M1gRERERAQDMhcDr4a557ZfSAJXXdQ9TKBQYMWIElixZgpdffhmCIAAAvvvuO1gsFgwdOhTFxcXo1KkT/vvf/0Kv12PNmjV4/PHHERMTU+Xv4fKsVivuv/9+hISEYOfOncjNzXUYj2Xj4+ODJUuWIDw8HAcOHMC4cePg4+ODyZMnY9iwYTh48CDWrVuHjRs3AgB8fX0rXKOgoACJiYno1q0b/vrrL2RmZuKJJ57AxIkTHcLj5s2bERYWhs2bN+PkyZMYNmwY4uPjMW7cuOu+n8reny1U/f777ygpKcEzzzyDYcOGYcuWLQCARx99FB07dsSHH34IuVyOvXv3QqmUlit65plnYDQasWbNGoSEhODo0aPw9va+4XJUl0uD1YoVKzBp0iQsWrQIXbt2xYIFC5CYmIhjx44hODi40nP0ej2OHTtmf2z7ktrMnTsX7777LpYuXYro6Gi8+uqrSExMxOHDh6HRaOr0/dQVjVy6ZVdAIiIiIs8xZswYzJs3D7///jt69eoFAPj8889x//33w9fXF3q9Hi+++KL9+H/9619Yv349vv3222oFq40bN+Lo0aNYv349wsOloPn6669XGBf1yiuv2O9HRUXhxRdfxDfffIPJkydDq9XC29sbCoUCoaGhVb7W8uXLUVxcjC+++AJeXlKwfO+99zBgwAC8+eabCAkJAQD4+/vjvffeg1wuR+vWrXHvvfdi06ZNNQpWmzZtwoEDB3DmzBlERkYCAL744gu0a9cOf/31F2699VakpqbiP//5D1q3bg0ADo0pqampuP/++9GuXTvo9Xo0b978hstwI1warObPn49x48bZW6EWLVqENWvWYPHixfi///u/Ss8RBKHKD10URSxYsACvvPIKBg0aBECq/JCQEKxevRrDhw+vmzdSx7QKEYCAPCODFRERERGUOqnlyFWvXU2tW7dG9+7dsXjxYvTq1QsnT57E1q1bsWnTJgCAxWLBa6+9hm+//RYXLlyAyWSC0Wis9hiqI0eOIDIy0h6qAKBbt24VjluxYgXeffddnDp1Cvn5+SgpKYFer6/2+7C9VlxcnD1UAcDtt98Oq9WKY8eO2YNVu3btIJfL7ceEhYXhwIEDN/Ra5V8zMjLSHqoAoG3btvDz88ORI0dw6623YtKkSXjiiSewbNkyJCQk4MEHH0RMTAwA4Nlnn8XTTz+NX3/9FYmJiXjggQdqNK6tulwWrEwmE3bv3o0pU6bY98lkMiQkJCA5ObnK8/Lz89G0aVNYrVbccssteP3119GuXTsAwJkzZ5Ceno6EhAT78b6+vujatSuSk5OrDFZGoxFGo9H+2GAwAADMZvNN9QmtDWazGdrS72ZOgdHl5amvbPXK+q17rGvnYD07B+vZeVjXzuGO9Ww2myGKIqxWK6xWa9kTCq1rCiSK1R5nBQCjR4/Gc889h4ULF2Lx4sWIiYnBnXfeifz8fMybNw//+9//MH/+fMTGxsLLywsvvPACjEajw3u1vf+rH4ul5Sj/nO2+rb6Sk5Px6KOPYvr06ejTpw98fX2xYsUKzJ8/335sZdcpf73qvpYoilAoFBWuU+Gzu+q5ql67OuWaOnUqhg8fjrVr1+LXX3/FtGnTsHz5cgwZMgRjxoxBQkICVq1aha1bt+KNN97AW2+9hYkTJ1Z6PVEUYTabHYIhUP1/Dy4LVtnZ2bBYLPZ0a2Pr/1iZVq1aYfHixejQoQNyc3Px1ltvoXv37jh06BAaN26M9PR0+zWuvqbtucrMmTMHM2bMqLB/w4YNTpt15Vo0CmmOkb/3HUKjSwddXJr6rbIBn1Q3WNfOwXp2Dtaz87CuncOd6tnWRS0/Px8mk8nVxblhffv2hUwmw+LFi7F06VKMGTPGPuHDH3/8gX79+mHgwIEAYG/9adWqlf0P/SUlJTCZTPbHVqsVxcXFMBgMaNKkCc6dO4fjx4/be3T99ttvAICioiIYDAZs3rwZkZGRDmHi5MmTEEXR4ZrlX6M823WioqKwZMkSXLx40d5qlZSUBJlMhvDwcBgMBpjNZpSUlDhcx2QyVdhXXnFxsUNZyrO9v8OHD6Nx48YAgKNHjyInJwdNmza1nxMaGooxY8ZgzJgxGDt2LD799FPcc889AAA/Pz/7czNmzMBHH32EESNGVHgtk8mEoqIi/PHHHygpcZzXoLCwsNKyX83lk1fciG7dujk0b3bv3h1t2rTBRx99hFmzZtX4ulOmTMGkSZPsjw0GAyIjI9GnT58bbiatbWazGatTpObisKYx6J/Y0qXlqa/MZjOSkpLQu3dv+4BHqhusa+dgPTsH69l5WNfO4Y71XFxcjHPnzsHb29sjx8vbZrKbNWsWDAYDnnzySfj4+CAvLw+tW7fGqlWrcPDgQfj7++Odd95BVlaWfUwQIAVLlUplfyyTyaDRaKDX6zFw4EC0bNkS//rXvzB37lwYDAbMmTMHAKDVaqHX69G+fXucP38ea9euxa233oq1a9dizZo1EATBfs1WrVohNTUVp0+fRuPGjeHj42OfZt12nbFjx+LNN9/Es88+i2nTpiErKwtTpkzBY489Zh+7pFQqoVAoHH4/q1SqCvvK02g0sFqtOH36tMN+tVqNgQMHIjY2FhMmTMD8+fNRUlKCiRMnomfPnujZsyeKioowefJkDB06FNHR0Th//jz27duH+++/H3q9Hi+88AISExMREREBk8mE5ORkh7otr7i4GFqt1j7DYnlVhcKruSxYBQYGQi6XO0yXCAAZGRnXHDhXnlKpRMeOHXHy5EkAsJ+XkZGBsLAwh2tWtuiZjVqtrnSOfqVS6Rb/UZHGWAEFJotblKc+c5fPvCFgXTsH69k5WM/Ow7p2DneqZ4vFAkEQIJPJIJN55kpBTzzxBBYvXoz+/fujcePG9q5tr7zyClJSUtCvXz/odDqMHz8egwcPRm5ursN7tb3/qx/LZDL88MMPGDt2LG677TZERUXh3XfftbeSyWQyDB48GC+88AKeffZZGI1G3HvvvXj11Vcxffp0+zUffPBBrF69Gvfccw9ycnLw+eefY9SoUQBgv463tzfWr1+P5557Dl27doVOp8PQoUMxf/58+3Vs07VfXVbbdSojk8mQn5+PTp06OeyPiYnByZMn8eOPP+Jf//oXevXqBZlMhr59+2LhwoWQyWRQKpW4fPkyRo0ahYyMDAQGBuL+++/HzJkzIZPJYLVa8eyzz+L8+fPQ6/Xo27cv3nnnnUrLIpPJIAhCpd/96v5bcFmwUqlU6NSpEzZt2oTBgwcDkJohN23aVGm/x8pYLBYcOHAA/fv3BwBER0cjNDQUmzZtsgcpg8GAnTt34umnn66Lt+EU9lkBOd06ERERkcfp1q2bfbxQeY0aNXJYJ6oytmnFbVJSUhwet2zZElu3bnXYd/VrzZ07F3PnznXYV35adrVajZUrV1Z47auvExsba+9qWJmr1+wC4LDmVmVGjRplD3GVadKkCX788cdKn1OpVNdc92vhwoWwWq0wGAzQ6/V1Hsxd2hVw0qRJGDlyJDp37owuXbpgwYIFKCgosM8SOGLECERERNibNGfOnInbbrsNzZs3R05ODubNm4ezZ8/iiSeeACAl4ueffx6zZ89GixYt7NOth4eH28ObJ9JygWAiIiIiIrfm0mA1bNgwZGVlYerUqUhPT0d8fDzWrVtnn3wiNTXVIVleuXIF48aNQ3p6Ovz9/dGpUyfs2LEDbdu2tR8zefJkFBQUYPz48cjJycEdd9yBdevWeWSfXBst17EiIiIiInJrLp+8YuLEiVV2/bu66fOdd97BO++8c83rCYKAmTNnYubMmbVVRJfTyqVm2LxiBisiIiIiInfkmSMAGxhNafzlGCsiIiIiIvfEYOUBbF0B2WJFREREDVVlkz8Q1Zba+H4xWHkA2+QVxWYrTCWVr1pNREREVB/Zprqu7iKtRDVh+37dzDIDLh9jRddnm24dkFqtArwrrrlFREREVB/J5XL4+fkhMzMTAKDT6exrI3kqq9UKk8mE4uJij12by1Ncr65FUURhYSEyMzPh5+cHuVxeyVWqh8HKA8gEwEstR4HRgrziEgYrIiIialBCQ0MBwB6uPJ0oiigqKoJWq/X4kOjuqlvXfn5+9u9ZTTFYeQgftQIFRgsMHGdFREREDYwgCAgLC0NwcDDMZs//LWQ2m/HHH3/gzjvvvKmuZ3R91alrpVJ5Uy1VNgxWHsJHo0C6wchFgomIiKjBksvltfID2NXkcjlKSkqg0WgYrOqYM+uanTo9hF4jfRE4MyARERERkfthsPIQ3qWLWRmK2GJFRERERORuGKw8hI+6NFixxYqIiIiIyO0wWHkIfeliVhxjRURERETkfhisPISPWhpjxRYrIiIiIiL3w2DlIXw0bLEiIiIiInJXDFYewsc+eQVbrIiIiIiI3A2DlYdgixURERERkftisPIQeluwMrLFioiIiIjI3TBYeQif0gWCuY4VEREREZH7YbDyEGVdAdliRURERETkbhisPIR98oriEoii6OLSEBERERFReQxWHsJHLQUri1VEkdni4tIQEREREVF5DFYeQqeSQy4TAHBmQCIiIiIid8Ng5SEEQeBaVkREREREborByoPobTMDssWKiIiIiMitMFh5EM4MSERERETknhisPEj5mQGJiIiIiMh9MFh5EFtXQLZYERERERG5FwYrD+JjG2NVxBYrIiIiIiJ3wmDlQTjGioiIiIjIPTFYeRC91tYVkC1WRERERETuhMHKg+jtk1ewxYqIiIiIyJ0wWHmQsskr2GJFREREROROGKw8iH269SK2WBERERERuRMGKw/iwxYrIiIiIiK3xGDlQfRazgpIREREROSOGKw8iH0dK7ZYERERERG5FQYrD2KbFTDfWAKLVXRxaYiIiIiIyIbByoPYWqwAIJ+tVkREREREboPByoOoFDKoFdJHxrWsiIiIiIjcB4OVh9FrOTMgEREREZG7YbDyMPa1rNhiRURERETkNhisPAzXsiIiIiIicj8MVh7GNjMg17IiIiIiInIfDFYeRm9by6qIwYqIiIiIyF0wWHkYvdbWYsWugERERERE7oLBysPYxlhx8goiIiIiIvfBYOVhfNRssSIiIiIicjcMVh6G61gREREREbkfBisPw3WsiIiIiIjcD4OVh7HPCsgWKyIiIiIit8Fg5WFsLVZ5nG6diIiIiMhtMFh5GB+2WBERERERuR0GKw9Tto4VW6yIiIiIiNyFy4PV+++/j6ioKGg0GnTt2hW7du2q1nnffPMNBEHA4MGDHfaPGjUKgiA4bH379q2DkruGrcXKWGKFscTi4tIQERERERHg4mC1YsUKTJo0CdOmTcOePXsQFxeHxMREZGZmXvO8lJQUvPjii+jRo0elz/ft2xcXL160b19//XVdFN8lvEvXsQI45ToRERERkbtwabCaP38+xo0bh9GjR6Nt27ZYtGgRdDodFi9eXOU5FosFjz76KGbMmIFmzZpVeoxarUZoaKh98/f3r6u34HRymWBfJNjACSyIiIiIiNyC4vqH1A2TyYTdu3djypQp9n0ymQwJCQlITk6u8ryZM2ciODgYY8eOxdatWys9ZsuWLQgODoa/vz/uvvtuzJ49GwEBAVVe02g0wmg02h8bDAYAgNlshtns2vBie/3y5fDWKJBnLMGV/GKY/dSuKlq9Ulk9U91gXTsH69k5WM/Ow7p2Dtazc7Cenac26rq65wqiKIo1fpWbkJaWhoiICOzYsQPdunWz7588eTJ+//137Ny5s8I527Ztw/Dhw7F3714EBgZi1KhRyMnJwerVq+3HfPPNN9DpdIiOjsapU6fw0ksvwdvbG8nJyZDL5ZWWZfr06ZgxY0aF/cuXL4dOp7v5N1vL3tgnx8VCARPaWNDKzyUfHxERERFRg1BYWIhHHnkEubm50Ov1VR7nsharG5WXl4fHH38cn3zyCQIDA6s8bvjw4fb7sbGx6NChA2JiYrBlyxbcc889lZ4zZcoUTJo0yf7YYDAgMjISffr0uWblOYPZbEZSUhJ69+4NpVKauGJZ2i5cPJuD1h06ol/7UJeWr76orJ6pbrCunYP17BysZ+dhXTsH69k5WM/OUxt1bevNdj0uC1aBgYGQy+XIyMhw2J+RkYHQ0Iph4dSpU0hJScGAAQPs+6xWKwBAoVDg2LFjiImJqXBes2bNEBgYiJMnT1YZrNRqNdTqil3qlEql23zZy5dFr1UBAIpKRLcpX33hTp95fce6dg7Ws3Ownp2Hde0crGfnYD07z83UdXXPc9nkFSqVCp06dcKmTZvs+6xWKzZt2uTQNdCmdevWOHDgAPbu3WvfBg4ciLvuugt79+5FZGRkpa9z/vx5XLp0CWFhYXX2XpxNr7GtZcVZAYmIiIiI3IFLuwJOmjQJI0eOROfOndGlSxcsWLAABQUFGD16NABgxIgRiIiIwJw5c6DRaNC+fXuH8/38/ADAvj8/Px8zZszA0KFDERoailOnTmHy5Mlo3rw5EhMTnfre6pJtLSvOCkhERERE5B5cGqyGDRuGrKwsTJ06Fenp6YiPj8e6desQEhICAEhNTYVMVv1GNblcjv3792Pp0qXIyclBeHg4+vTpg1mzZlXa1c9T6bWl062zxYqIiIiIyC24fPKKiRMnYuLEiZU+t2XLlmueu2TJEofHWq0W69evr6WSuS97i1UxW6yIiIiIiNyBSxcIpprx4RgrIiIiIiK3wmDlgfSlLVZ5bLEiIiIiInILDFYeyNZiZShiixURERERkTtgsPJAem1pi5WRLVZERERERO6AwcoD6dliRURERETkVhisPJBtVsB8YwlEUXRxaYiIiIiIiMHKA9kmr7BYRRSaLC4uDRERERERMVh5II1SBoVMAMC1rIiIiIiI3AGDlQcSBIFrWRERERERuREGKw9lnxmQLVZERERERC7HYOWhuJYVEREREZH7YLDyULYJLDjGioiIiIjI9RisPJS9xYpjrIiIiIiIXI7BykPZ1rLiGCsiIiIiItdjsPJQenuwYosVEREREZGrMVh5qLLJK9hiRURERETkagxWHqpsunW2WBERERERuRqDlYcqm7yCLVZERERERK7GYOWh9KXBii1WRERERESux2DlofScFZCIiIiIyG0wWHko23TrhiK2WBERERERuRqDlYfysXcFZIsVEREREZGrMVh5KNusgAUmC0osVheXhoiIiIioYWOw8lC2FisAyDeyOyARERERkSsxWHkopVwGrVIOgDMDEhERERG5GoOVB7O1WuUWcZwVEREREZErMVh5MB+uZUVERERE5BYYrDyYbQILzgxIRERERORaDFYezL6WFVusiIiIiIhcisHKg+m5lhURERERkVtgsPJg9harIrZYERERERG5EoOVB2OLFRERERGRe2Cw8mBlk1ewxYqIiIiIyJUYrDyYbbp1A1usiIiIiIhcisHKg+k1bLEiIiIiInIHDFYejC1WRERERETugcHKg/mwxYqIiIiIyC0wWHkwvZazAhIRERERuQMGKw/GdayIiIiIiNwDg5UHs42xMlmsKDZbXFwaIiIiIqKGi8HKg3mrFBAE6T7HWRERERERuQ6DlQeTyQR4qzkzIBERERGRqzFYeTiuZUVERERE5HoMVh7OvpZVEVusiIiIiIhchcHKw7HFioiIiIjI9RisPBzXsiIiIiIicj0GKw9nX8uKwYqIiIiIyGUYrDycXmNrsWJXQCIiIiIiV2Gw8nD2FitOXkFERERE5DIMVh7Ohy1WREREREQux2Dl4fRa2xgrBisiIiIiIldhsPJw9nWsOHkFEREREZHLuDxYvf/++4iKioJGo0HXrl2xa9euap33zTffQBAEDB482GG/KIqYOnUqwsLCoNVqkZCQgBMnTtRByd2DD9exIiIiIiJyOZcGqxUrVmDSpEmYNm0a9uzZg7i4OCQmJiIzM/Oa56WkpODFF19Ejx49Kjw3d+5cvPvuu1i0aBF27twJLy8vJCYmori4uK7ehkvZZgXk5BVERERERK7j0mA1f/58jBs3DqNHj0bbtm2xaNEi6HQ6LF68uMpzLBYLHn30UcyYMQPNmjVzeE4URSxYsACvvPIKBg0ahA4dOuCLL75AWloaVq9eXcfvxjXKWqwYrIiIiIiIXEXhqhc2mUzYvXs3pkyZYt8nk8mQkJCA5OTkKs+bOXMmgoODMXbsWGzdutXhuTNnziA9PR0JCQn2fb6+vujatSuSk5MxfPjwSq9pNBphNBrtjw0GAwDAbDbDbHZtYLG9flXl0JV+gvnGEhiNJshkgrOKVq9cr56p9rCunYP17BysZ+dhXTsH69k5WM/OUxt1Xd1zXRassrOzYbFYEBIS4rA/JCQER48erfScbdu24bPPPsPevXsrfT49Pd1+jauvaXuuMnPmzMGMGTMq7N+wYQN0Ot213obTJCUlVbrfZAEABawisPqXX6Fx2SdaP1RVz1T7WNfOwXp2Dtaz87CunYP17BysZ+e5mbouLCys1nEe8zM8Ly8Pjz/+OD755BMEBgbW6rWnTJmCSZMm2R8bDAZERkaiT58+0Ov1tfpaN8psNiMpKQm9e/eGUqms8Lwoinhp90aYLSK69bwbYb4aF5TS812vnqn2sK6dg/XsHKxn52FdOwfr2TlYz85TG3Vt6812PS4LVoGBgZDL5cjIyHDYn5GRgdDQ0ArHnzp1CikpKRgwYIB9n9VqBQAoFAocO3bMfl5GRgbCwsIcrhkfH19lWdRqNdRqdYX9SqXSbb7s1yqLXqPEpQITikrgNuX1VO70mdd3rGvnYD07B+vZeVjXzsF6dg7Ws/PcTF1X9zyXTV6hUqnQqVMnbNq0yb7ParVi06ZN6NatW4XjW7dujQMHDmDv3r32beDAgbjrrruwd+9eREZGIjo6GqGhoQ7XNBgM2LlzZ6XXrC+4lhURERERkWu5tCvgpEmTMHLkSHTu3BldunTBggULUFBQgNGjRwMARowYgYiICMyZMwcajQbt27d3ON/Pzw8AHPY///zzmD17Nlq0aIHo6Gi8+uqrCA8Pr7DeVX2i13JmQCIiIiIiV3JpsBo2bBiysrIwdepUpKenIz4+HuvWrbNPPpGamgqZ7MYa1SZPnoyCggKMHz8eOTk5uOOOO7Bu3TpoNPV37JG9xaqIiwQTEREREbmCyyevmDhxIiZOnFjpc1u2bLnmuUuWLKmwTxAEzJw5EzNnzqyF0nkGHzVbrIiIiIiIXMmlCwRT7dBrbWOs2GJFREREROQKDFb1gI9GarHi5BVERERERK7BYFUP2MZY5bHFioiIiIjIJRis6gG9rcWqiC1WRERERESuwGBVD7DFioiIiIjItRis6gGuY0VERERE5FoMVvWAfR0rtlgREREREbkEg1U9YBtjxRYrIiIiIiLXYLCqB8omr2CLFRERERGRKzBY1QO2roBFZgvMFquLS0NERERE1PAwWNUDtmAFAPkcZ0VERERE5HQMVvWAQi6DTiUHABg4zoqIiIiIyOkYrOoJrmVFREREROQ6DFb1hH0CC7ZYERERERE5HYNVPWFfy4ozAxIREREROR2DVT2h13ItKyIiIiIiV2Gwqid87F0B2WJFRERERORsDFb1RNnkFWyxIiIiIiJyNgaresI2eQVnBSQiIiIicj4Gq3qibPIKtlgRERERETkbg1U9oec6VkRERERELsNgVU/YZgXkOlZERERERM7HYFVP+LDFioiIiIjIZRis6omyySvYYkVERERE5GwMVvUE17EiIiIiInIdBqt6ovw6VqIourg0REREREQNC4NVPWGbvMJsEWEssbq4NEREREREDQuDVT3hpZJDJkj3uZYVEREREZFzMVjVE4IgcJwVEREREZGLMFjVI7ZxVlzLioiIiIjIuRis6hEf+5TrbLEiIiIiInImBqt6RF9uZkAiIiIiInIeBqt6xD7GqogtVkREREREzsRgVY+wxYqIiIiIyDUYrOoR21pWnLyCiIiIiMi5GKzqER97ixW7AhIRERERORODVT2i56yAREREREQuwWBVj9jXsSpiV0AiIiIiImdisKpHuI4VEREREZFrMFjVI3ptaYsVJ68gIiIiInIqBit3VmKEfPV43H34v4Ap/7qHs8WKiIiIiMg1GKzcmUIN4ewO+BgvQsg4dN3DbetYscWKiIiIiMi5GKzcnBjaAQAgpO+/7rG2Fqt8YwmsVrFOy0VERERERGUYrNxcWbDad91jbbMCiiKQb2J3QCIiIiIiZ6lRsDp37hzOnz9vf7xr1y48//zz+Pjjj2utYCS5kRYrjVIOlUL6SDnOioiIiIjIeWoUrB555BFs3rwZAJCeno7evXtj165dePnllzFz5sxaLWBDJ4bFS3eyjgHmouser+daVkRERERETlejYHXw4EF06dIFAPDtt9+iffv22LFjB7766issWbKkNstHPmEwKnwgiBYg4/B1D9dzZkAiIiIiIqerUbAym81Qq9UAgI0bN2LgwIEAgNatW+PixYu1VzoCBAE52ijp/sW91z3chy1WREREREROV6Ng1a5dOyxatAhbt25FUlIS+vbtCwBIS0tDQEBArRaQgFxdlHTnYnUmsChtsTIyWBEREREROUuNgtWbb76Jjz76CL169cLDDz+MuLg4AMBPP/1k7yJItSdH21S6U40WK71WarFiV0AiIiIiIudR1OSkXr16ITs7GwaDAf7+/vb948ePh06nq7XCkSRXFy3dyTgMlJgAharKY33UUosVuwISERERETlPjVqsioqKYDQa7aHq7NmzWLBgAY4dO4bg4OBaLSABhapAiBpfwGoGso5c81jbGCu2WBEREREROU+NgtWgQYPwxRdfAABycnLQtWtXvP322xg8eDA+/PDDG7rW+++/j6ioKGg0GnTt2hW7du2q8thVq1ahc+fO8PPzg5eXF+Lj47Fs2TKHY0aNGgVBEBw22xgwjyUI9vWsrjfOSq8tbbEqZosVEREREZGz1ChY7dmzBz169AAArFy5EiEhITh79iy++OILvPvuu9W+zooVKzBp0iRMmzYNe/bsQVxcHBITE5GZmVnp8Y0aNcLLL7+M5ORk7N+/H6NHj8bo0aOxfv16h+P69u2Lixcv2revv/66Jm/TrVQ3WNlnBWSLFRERERGR09QoWBUWFsLHxwcAsGHDBtx///2QyWS47bbbcPbs2WpfZ/78+Rg3bhxGjx6Ntm3bYtGiRdDpdFi8eHGlx/fq1QtDhgxBmzZtEBMTg+eeew4dOnTAtm3bHI5Tq9UIDQ21b+XHgXkqe7BK23vN47iOFRERERGR89Vo8ormzZtj9erVGDJkCNavX48XXngBAJCZmQm9Xl+ta5hMJuzevRtTpkyx75PJZEhISEBycvJ1zxdFEb/99huOHTuGN9980+G5LVu2IDg4GP7+/rj77rsxe/bsa04DbzQaYTQa7Y8NBgMAab0us9m1Xepsr28OaAsFADHjIEqMRYCs8o9OpxQAALmFJpeX3ZPY65l1VudY187BenYO1rPzsK6dg/XsHKxn56mNuq7uuYIoiuKNXnzlypV45JFHYLFYcPfddyMpKQkAMGfOHPzxxx/49ddfr3uNtLQ0REREYMeOHejWrZt9/+TJk/H7779j586dlZ6Xm5uLiIgIGI1GyOVyfPDBBxgzZoz9+W+++QY6nQ7R0dE4deoUXnrpJXh7eyM5ORlyubzSa06fPh0zZsyosH/58uXuM8uhaMW9+5+CwlqM31q/jjxt40oPO5Er4L3DcoRoRbwUb3FyIYmIiIiI6pfCwkI88sgjyM3NvWYjUo1arB544AHccccduHjxon0NKwC45557MGTIkJpcstp8fHywd+9e5OfnY9OmTZg0aRKaNWuGXr16AQCGDx9uPzY2NhYdOnRATEwMtmzZgnvuuafSa06ZMgWTJk2yPzYYDIiMjESfPn2q3QJXV8xmM5KSktC7TyJkl+KBc3/izha+EDv0r/T4wxcNeO/wn7DK1ejfv5dTy+rJ7PXcuzeUSqWri1Ovsa6dg/XsHKxn52FdOwfr2TlYz85TG3Vt6812PTUKVgDs45fOnz8PAGjcuPENLQ4cGBgIuVyOjIwMh/0ZGRkIDQ2t8jyZTIbmzZsDAOLj43HkyBHMmTPHHqyu1qxZMwQGBuLkyZNVBiu1Wg21Wl1hv1KpdJsvu1KphCy8I3DuTygyDwLKxyo9rpG3FgCQZyxxm7J7Enf6zOs71rVzsJ6dg/XsPKxr52A9Owfr2Xlupq6re16NJq+wWq2YOXMmfH190bRpUzRt2hR+fn6YNWsWrFZrta6hUqnQqVMnbNq0yeG6mzZtcugaWJ2ylB8fdbXz58/j0qVLCAsLq/Y13VZYaevgNWYGtE1eUWy2wlRSvc+CiIiIiIhuTo1arF5++WV89tlneOONN3D77bcDALZt24bp06ejuLgYr732WrWuM2nSJIwcORKdO3dGly5dsGDBAhQUFGD06NEAgBEjRiAiIgJz5swBII3h6ty5M2JiYmA0GrF27VosW7bMvnZWfn4+ZsyYgaFDhyI0NBSnTp3C5MmT0bx5cyQmJtbkrboXW7BK3w9YrYCsYi721pR9pHnFZgR4V2yJIyIiIiKi2lWjYLV06VJ8+umnGDhwoH1fhw4dEBERgQkTJlQ7WA0bNgxZWVmYOnUq0tPTER8fj3Xr1iEkJAQAkJqaClm58FBQUIAJEybg/Pnz0Gq1aN26Nb788ksMGzYMACCXy7F//34sXboUOTk5CA8PR58+fTBr1qxKu/p5nMCWgEILmPKBy6eAwBYVDpHLBHip5CgwWZBXXMJgRURERETkBDUKVpcvX0br1q0r7G/dujUuX758Q9eaOHEiJk6cWOlzW7ZscXg8e/ZszJ49u8prabXaCosF1ytyBRDaHjj/l9QdsJJgBQB6rdIerIiIiIiIqO7VaIxVXFwc3nvvvQr733vvPXTo0OGmC0XXYB9ntbfKQ3xKuwMairk2AhERERGRM9SoxWru3Lm49957sXHjRvtEE8nJyTh37hzWrl1bqwWkq1RjAguf0gks8hisiIiIiIicokYtVj179sTx48cxZMgQ5OTkICcnB/fffz8OHTqEZcuW1XYZqbzywaqKtZ31tharInYFJCIiIiJyhhqvYxUeHl5hkop9+/bhs88+w8cff3zTBaMqBLUBZEqgOBe4kgI0iq5wiK3Fil0BiYiIiIico0YtVuRCChUQ0la6X0V3QL1WysucvIKIiIiIyDkYrDxRWLx0W0WwYosVEREREZFzMVh5outMYGGbFZAtVkREREREznFDY6zuv//+az6fk5NzM2Wh6irfYiWKgCA4PK23tVgVscWKiIiIiMgZbihY+fr6Xvf5ESNG3FSBqBpC2gKCHCjMBgxpgG+Ew9NssSIiIiIicq4bClaff/55XZWDboRSCwS1BjIPSQsFXxWs9NrSdayMbLEiIiIiInIGjrHyVOHx0m0l46y4jhURERERkXMxWHmqa0xgYZsVMI+zAhIREREROQWDlae6RrDS24NVCURRdGapiIiIiIgaJAYrTxXSHoAA5F0E8jIcnrJNXlFiFVFktrigcEREREREDQuDladSewOBLaT76fsdntKp5JDLpCnYOTMgEREREVHdY7DyZLbugGl7HXYLgmBvteJaVkREREREdY/BypPZFwreW+Epe7BiixURERERUZ1jsPJk9gks9ld4Ss+ZAYmIiIiInIbBypOFxkq3ualA4WWHp9hiRURERETkPAxWnkzrB/hHS/evmnada1kRERERETkPg5Wnq2I9K1tXQEMRW6yIiIiIiOoag5WnswervQ67bV0B2WJFRERERFT3GKw8XXi8dHt1i5XW1hWQLVZERERERHWNwcrThZa2WF0+DRTn2nfr7ZNXsMWKiIiIiKiuMVh5Oq8AwDdSup9+wL67rCsgW6yIiIiIiOoag1V9UMkEFmWTV7DFioiIiIiorjFY1QeVBKuy6dbZYkVEREREVNcYrOoDW7BK22vfpddyVkAiIiIiImdhsKoPwuKl2+zjgKkAQFmLlYEtVkREREREdY7Bqj7wCQG8QwGIQPpBaVfp5BX5xhJYrKILC0dEREREVP8xWNUXV42zsgUrQApXRERERERUdxis6ourgpVaIYdaIX28nBmQiIiIiKhuMVjVF5wZkIiIiIjIZRis6ovweOk26whgLgZQNjOggTMDEhERERHVKQar+kIfAegCAGsJkHkIAFusiIiIiIichcGqvhCECt0B9RquZUVERERE5AwMVvVJhWBVupYVJ68gIiIiIqpTDFb1SRVTrrMrIBERERFR3WKwqk9swSrjEGAxQ68tbbFiV0AiIiIiojrFYFWf+EcDal/AYgIyj8BHzRYrIiIiIiJnYLCqTwQBCOsg3b+4z95ixWBFRERERFS3GKzqm3LjrGxjrNgVkIiIiIiobjFY1Tdh8dLtxX32dawMbLEiIiIiIqpTDFb1ja3FKv0A9CoBANexIiIiIiKqawxW9U1ADKD0AkqKEGBMBQAYithiRURERERUlxis6huZ3D6BhX/OIQBssSIiIiIiqmsMVvVRaXdA7ytSsDKWWGEssbiyRERERERE9RqDVX1UGqxUmQfsuzjlOhERERFR3WGwqo9Kg5WQfgB6tfQRM1gREREREdUdBqv6KLAVoNAApjy0VmUDAAxFHGdFRERERFRXGKzqI7kCCGkPAIhXSDMDssWKiIiIiKjuMFjVV6XdAdvJTgMADJwZkIiIiIiozrg8WL3//vuIioqCRqNB165dsWvXriqPXbVqFTp37gw/Pz94eXkhPj4ey5YtczhGFEVMnToVYWFh0Gq1SEhIwIkTJ+r6bbif0mDVwnIKAKdcJyIiIiKqSy4NVitWrMCkSZMwbdo07NmzB3FxcUhMTERmZmalxzdq1Agvv/wykpOTsX//fowePRqjR4/G+vXr7cfMnTsX7777LhYtWoSdO3fCy8sLiYmJKC4udtbbcg+lwaqp6SQAkV0BiYiIiIjqkEuD1fz58zFu3DiMHj0abdu2xaJFi6DT6bB48eJKj+/VqxeGDBmCNm3aICYmBs899xw6dOiAbdu2AZBaqxYsWIBXXnkFgwYNQocOHfDFF18gLS0Nq1evduI7cwPBbQCZEl7WPDQWsjl5BRERERFRHVK46oVNJhN2796NKVOm2PfJZDIkJCQgOTn5uueLoojffvsNx44dw5tvvgkAOHPmDNLT05GQkGA/ztfXF127dkVycjKGDx9e6bWMRiOMRqP9scFgAACYzWaYza4NJLbXv/FyyKAIag0h4wDaCWeQU9jJ5e/FndW8nulGsa6dg/XsHKxn52FdOwfr2TlYz85TG3Vd3XNdFqyys7NhsVgQEhLisD8kJARHjx6t8rzc3FxERETAaDRCLpfjgw8+QO/evQEA6enp9mtcfU3bc5WZM2cOZsyYUWH/hg0boNPpqv2e6lJSUtINnxNX0ghRAGJlZ/D7qRSsXXu61stV39SknqlmWNfOwXp2Dtaz87CunYP17BysZ+e5mbouLCys1nEuC1Y15ePjg7179yI/Px+bNm3CpEmT0KxZM/Tq1avG15wyZQomTZpkf2wwGBAZGYk+ffpAr9fXQqlrzmw2IykpCb1794ZSqbyhc2W704F1v6O9kIK9ASHo379jHZXS891MPdONYV07B+vZOVjPzsO6dg7Ws3Ownp2nNura1pvtelwWrAIDAyGXy5GRkeGwPyMjA6GhoVWeJ5PJ0Lx5cwBAfHw8jhw5gjlz5qBXr1728zIyMhAWFuZwzfj4+CqvqVaroVarK+xXKpVu82WvUVkadwIAtJedQb6xxG3eiztzp8+8vmNdOwfr2TlYz87DunYO1rNzsJ6d52bqurrnuWzyCpVKhU6dOmHTpk32fVarFZs2bUK3bt2qfR2r1WofHxUdHY3Q0FCHaxoMBuzcufOGrllvhLSDKMgRKBigLMy4/vFERERERFQjLu0KOGnSJIwcORKdO3dGly5dsGDBAhQUFGD06NEAgBEjRiAiIgJz5swBII2F6ty5M2JiYmA0GrF27VosW7YMH374IQBAEAQ8//zzmD17Nlq0aIHo6Gi8+uqrCA8Px+DBg131Nl1HqUWxb3Noc44hvOi4q0tDRERERFRvuTRYDRs2DFlZWZg6dSrS09MRHx+PdevW2SefSE1NhUxW1qhWUFCACRMm4Pz589BqtWjdujW+/PJLDBs2zH7M5MmTUVBQgPHjxyMnJwd33HEH1q1bB41G4/T35w7MIbHQ5hxDlPmkq4tCRERERFRvuXzyiokTJ2LixImVPrdlyxaHx7Nnz8bs2bOveT1BEDBz5kzMnDmztoro2cLigWMr0cJyEqIoQhAEV5eIiIiIiKjecekCwVT3VJHSTIDthBQUmiwuLg0RERERUf3EYFXPqSM6wCoKCBMuI/9SmquLQ0RERERULzFY1XOCRo+zgjT1vPnCXtcWhoiIiIionmKwagBOyWMAAMLFfS4uCRERERFR/cRg1QCcVbcAACgzD7i4JERERERE9RODVQOQpm0FAPC6fNDFJSEiIiIiqp8YrBqASz6tAQBehReAwssuLg0RERERUf3DYNUAKLz8ccoqTWCBP95ybWGIiIiIiOohBqsGQK9RYm7JcOnBn+8D+1a4tkBERERERPUMg1UD4KNRYL31VmwOHiHt+PlZIG2vS8tERERERFSfMFg1AD4aBQBgtd9IoEUfoKQYWPEYUJDt4pIREREREdUPDFYNgF6rBADkGq3A/Z8AjWKA3HPAd6MAi9m1hSMiIiIiqgcYrBoAfWmLVV5xCaD1A4YvB1TeQMpWYMOrri0cEREREVE9wGDVAPhopBarvOLS1qng1sCQj6T7Oz8E9n7topIREREREdUPDFYNgL40WBmKSsp2trkPuHOydP/n54ALe1xQMiIiIiKi+oHBqgHwsXcFvGo8Va8pQMu+gMUoTWaRn+WC0hEREREReT4GqwbANnlFgcmCEou17AmZDLj/YyCgOWC4AHw3kpNZEBERERHVAINVA2BrsQKAfGOJ45Ma39LJLHyAs9uB9S87uXRERERERJ6PwaoBUMpl0CiljzqvuKTiAUGtpJYrANj1EfDPV04sHRERERGR52OwaiBsE1jkFlXR1a91f6Dn/0n3f3kBuLDbSSUjIiIiIvJ8DFYNRLBeDQA4mp5X9UE9/wu06i9NZvHNY0B+ppNKR0RERETk2RisGojEtqEAgB/3Xqj6IJlMWt8qoAWQlwZ8OxIoMTmphEREREREnovBqoEYFB8BANh+MhsZhuKqD9TogYe/BtR6IHUHsP4lJ5WQiIiIiMhzMVg1EE0CdOjU1B9WEfh5X9q1Dw5sUTaZxV+fAP98WfcFJCIiIiLyYAxWDcjgjlKr1Q//XKM7oE2rfkCv0taqX14Azv9dhyUjIiIiIvJsDFYNyH2xYVDIBBxKM+B4xjUmsbC58z9A6/sAiwlY8RiQl1H3hSQiIiIi8kAMVg2Iv5cKvVoFAwBWV6fVSiYDBn8IBLYE8i4C347gZBZERERERJVgsGpghpR2B/xxbxqsVvH6J2j0wPDSySzO/Qms+786LiERERERkedhsGpg7mkTDB+1AhdyivBXyuXqnRTYHBj6KQAB+PszYM8XdVpGIiIiIiJPw2DVwGiUcvSLlda0Wn2tNa2u1jIRuOtl6f4vLwBfPwLsWwEU59ZBKYmIiIiIPAuDVQNkmx1wzf6LMJZYqn9ij38DsQ8B1hLg2Brgh/HA3BjgqweBPcuAwmq2gBERERER1TMMVg3QbdEBCPPVwFBcgs1Hs6p/okwmrW/11DbgzslAYCvAagZObAB+mgjMaw58MQj4ezGQn1l3b4CIiIiIyM0wWDVAMpmAgXHhAKo5O2B5ggCExgJ3vwxM3AVM2Cl1EQyJBUQLcHqL1FXw7VbA5/cCOz8CDNdZkJiIiIiIyMMpXF0Aco3BHSPw0R+n8dvRTOQWmuGrU9bsQsGtpa3nZODSKeDIT8Dhn4C0PcDZbdL262SgcReg7SCg7UDAr0ntvhkiIiIiIhdji1UD1SZMj9ahPjBZrFh78GLtXDQgBrjjBWD8ZuD5A0Di60BkV+m587uADS8DC2KBj3sBW+cDl0/XzusSEREREbkYg1UDZpvE4ocb7Q5YHX5NgG7PAGM3AJOOAv3fAqJ6AIIMSPsH2DQDePcWYPu7gFiN9bSIiIiIiNwYg1UDNjAuHIIA7DpzGeevFNbdC+nDgC7jgFG/AP8+Dty3AIi+E4AIJL0KrH8JsFrr7vWJiIiIiOoYg1UDFu6nxW3RAQCAH/c6aYIJ7yCg82hg5M9An9nSvj8/AL4fA5iLnVMGIiIiIqJaxmDVwA0p7Q64+p8LEJ3dJa/7v4ChnwEyJXDoB+DLoUBRjnPLQERERERUCxisGri+saFQKWQ4kZmPwxcNzi9A7APAY98Dar00g+DivkBuHYz5IiIiIiKqQwxWDZxeo0TvNiEAarCmVW1p1hMYvRbwDgWyjgCf9QYyDrumLFT3OFkJERER1UMMVmSfHfDHvWmwWF30ozc0FngiCQhsBRguAJ/3BVK2u6YsVHfO/AHF+7eg7/4JkC/pC6x6Evh9HnDwe+DiPsCY5+oSEhEREdUIFwgm9GwZBD+dEpl5RiSfuoQ7WgS6piB+TYAx64CvHwbO/QksGwzc/wnQbrBrykO16+D3wA9PQbCYoAaAC39L29W8Q4CA5kCjZtJtQIx06x8NKDXOLjURERFRtTBYEVQKGe6NDcNXO1Pxwz8XXBesAEDXCBixGvj+CeDoL8B3o4C8N4DbnnJdmejm/fkhsO7/AADW1gPxh9gZd7SLgCInBbh0Crh8SrotzAbyM6Tt7NUtlgLg21gKWo1Kw1ZYHNC4M6BQO/0tEREREZXHYEUApNkBv9qZinUHL2L24PbQquSuK4xSCzz0BfDrf4G/PgHW/VfqHpgwA5Cx96pHsVqBTdOB7f+THt86DpaE2chdtx5im/6AUul4fFFOWciyB66T0n2jAcg9J22nt5Sdo9AAkV2AqDuB6B5A+C2AQuWkN0hEREQkYbAiAECnpv5o7K/F+StFSDqSgYFx4a4tkEwO9J8H6MOBTTOAHe8CeenAoPf5o9lTlJiAnyYC+1dIj++ZCtwxCSgpqfocrR8Q0UnayhNFoCDbMWhlHwfO7QIKMoEzf0jbZgBKHdDkNiDqDilshXcE5PxPHREREdUt/togAIAgCBjSMQILfzuJ1f9ccH2wkgoF9JgE+IRJP9APfCt1ERv2JaDRu7p0dC3GPODbEcCp3wBBDgxcCHR8tObXEwRpcWnvICk02YiiFLDO/AGkbAVStgGFl6TXPfWbdIzKG2jSTWrNiroDCIuXgjsRERFRLWKwIrtB8VKw+v14Fi7lGxHg7SbjVuIfln5QrxgBnPkd+Lw/8NhKwCfU1SWrPcY8IOs4kH0MyDomhYXLZwCrufQAofRGuPHHMjnQ6l6g+0RA5VW37wMA8jOBrx4ELu6VWo8e+gJo0btuXksQgKBW0tZlnNT1MOsIcGZrWdAqzgFOJkkbIK2Z1rQ7ENVDClshsa7vYpqXIX23T28BTv8OmAuAoNbSFtwWCC699XLh+EciIiK6JgYrsmse7I0OjX2x/3wu1hy4iBHdolxdpDLNE4DRa4CvHgIyDgCf9pYWFg5q6eqSVZ+tO1v58GS7NdTxGmIX9wF/LwbufhmIf7TuWmwunwaW3Q9cOQPoAoBHvgMad7r+ebVFJgNC2knbbU9JQSvjoBSyzmwFzu4AjLnA8XXSBgAaP2mMVlg8EB4v3erDy4XUOmDMk5YTOL1F2rKOVDwmNVnaytMFAsFtpC2oddmtrlHdlZWIiIiqhcGKHAyOj8D+87n44Z8L7hWsAGmszNgNwJdDpbE2i/sAD68AmnR1dckcWa2A4bxjC1TWMel+0ZWqz/MOAQJbSq0vga2k2e+UOgCla4vZF9a9wceGNOD3N4Gcs8BP/5Jm6OszSwqrtenCHqmlqjAb8GsKPLYKCGxeu69xo2QyIKyDtHV7BrBapJBpa806u0Nq0TqxQdpsvIIcg1Z4PKCPqHnYspiB83+XBakLfwPW8mPNBGmGw2Y9gWa9pNfPPCoFrszS7UqKVLcppa1x5XmHXhW42gL+MTUrKxEREdUIgxU5GBAXjtfWHsE/qTlIyS5AVKATuo7diEbRwNgkYPlD0o/TLwYCQz8FWt9Xty0MNlaL1NUtL00KLIaLpfcvSq1OeRel/ebCKi4gSOt1BbVyDFFBLQGtf92VO/YB4K9Pgd/nApmHpXDa7C4pYIXG3vz1T26UumqaC4DQDsCjKwGfkJu/bm2TyYGIW6Tt9ucAS4nUZfHCbilwpe0Fso4CBVmO3QcBqbWofNAKi5emf6/seyeKUj3bgtTZHYAp3/EY/2gpRDXrBUTfWbHV6erPxVQohfPMcmEr66g0S2J+urSd3mw/XAmglyYSQnMBaDvAOf8+iIiIGjAGK3IQ5KPGHc0D8fvxLKzeewHPJ7hhVzuvAGDkz8DK0VJ3rhWPATIFoPYp3fSlm480yYV9X+lthX0+gFwHhaVIagkrzJLCUd7VwSlNmjxDtFy/jDKl1OLkEJ5aSWsvqXR1X0dXU6ilFpu4h4GtbwM7P5J+hC/qIXUNvPtlqftbTez7BvjxGakFJrqnZ00uIldI62A17ly2z1QIZBySAlfaXuk284jUWnRyo7TZ6AKkliZb2DLmlY2TKsh0fC1dYFmLVHRPwL/pjZVVpZNabcM7Ou4vNkgtopmHpaCVeVhq7cpPh2/xOeC7x6XxZH1mS2UkIiKiOuHyYPX+++9j3rx5SE9PR1xcHBYuXIguXbpUeuwnn3yCL774AgcPHgQAdOrUCa+//rrD8aNGjcLSpUsdzktMTMS6devq7k3UM4M7hkvB6p8LeO6eFhDc8S/dKh0w7Ctp0dm/PpV+1BdduXZXu2tQArgXAPZX42BBJnW90odJYcQnXLrvEy491odLrVJy5fWv5Wy6RkDia8CtT0jT2B/6Adj7JXDwe6D7v4Dbn5WCZnWIojQNftJU6XH7B4DBH3r+dPgqHRB5q7TZmIuksJX2T2ng2id107t6BsLylDppkgxbq1Rwu7qZJEOjr1heAOacizjz9YtokZ0EIWUr8HEvIG44cPergG9E7ZeDiIiogXNpsFqxYgUmTZqERYsWoWvXrliwYAESExNx7NgxBAcHVzh+y5YtePjhh9G9e3doNBq8+eab6NOnDw4dOoSIiLIfCn379sXnn39uf6xWu8nsdh6iT9tQaJUHkXKpEHvP5aBjkzrsonYz5Arg3reA3jOA4lyptcCYV+6+ofRx6a0x96rH5Y4p7aYlKnUQ9OHSFO+2kHR1cPIO9vzpuhtFAw8uAW57BtjwCnDuT+CPucDuJcBdU4COI6699pPVCqx/Cdj5ofS420Sg9yzXz65XV5Taii1b5mIg81BZq9bFfdJixdGlrVKNb3VtyPQKxJHwhxD94Cwof38dOPAdsO9r4NBqaYbI25+rfogmIiKi63JpsJo/fz7GjRuH0aNHAwAWLVqENWvWYPHixfi///u/Csd/9dVXDo8//fRTfP/999i0aRNGjBhh369WqxEaWo+m4nYyL7UCie1CsHpvGlb/c8F9g5WNyuumpxE3G4uxfs1PSLxvMJQqD29xuRGRtwJj1gFHfgY2TpNm9fvlBeDPRdL4qxZ9Ko7NKTECPzwptXYBUhez7v9yftldTampfDFjd+MbKY1D7Po0sOFlaabBP+YBu5dKXUA7Pu75fyggIiJyAy4LViaTCbt378aUKVPs+2QyGRISEpCcnHyNM8sUFhbCbDajUSPHQd9btmxBcHAw/P39cffdd2P27NkICAio8jpGoxFGo9H+2GAwAADMZjPMZnNVpzmF7fWdXY4BHUKxem8aftqXhv8mtoBSXk9bIkqZLVZY5GqYS0oa5iD/Fv2AZvdAtmcJZFvnQcg+Bix/CNaoHrDcPV0aRwQAxQbIV46A7Ow2iDIlLAMWQmz/AHAD309Xfacbmgr1HNIBeOwnCMfWQP7bDAhXzgA/Pwfxz0Ww3DMDYszdLiyt5+L32XlY187BenYO1rPz1EZdV/dcQRTtczQ7VVpaGiIiIrBjxw5069bNvn/y5Mn4/fffsXPnzuteY8KECVi/fj0OHToEjUYDAPjmm2+g0+kQHR2NU6dO4aWXXoK3tzeSk5Mhl1f+V9np06djxowZFfYvX74cOp0LJhpwAxYRmLpbjnyzgPGtLWjn75KvCbmAoqQALTN+RrOsDZCL0pTg5/xvx+mgBMSf+xy+RakokWmwK/pZZOnbu7i0VBOCtQTR2RvRKv1HqCwFAIAMn1gcihiOPG2ki0tHRETkXgoLC/HII48gNzcXen3VE3R5bLB64403MHfuXGzZsgUdOnSo8rjTp08jJiYGGzduxD333FPpMZW1WEVGRiI7O/ualecMZrMZSUlJ6N27N5RK506GMHvtUSxNTsV9saF456Gq67g+cGU9u62cVMi3vAbZoe8ddotewSgZ/o00rXoNsK6do1r1XHQFsm1vQ/b3ZxCsZoiCDGLcI7D0nCKtq0bXxe+z87CunYP17BysZ+epjbo2GAwIDAy8brByWVfAwMBAyOVyZGRkOOzPyMi47viot956C2+88QY2btx4zVAFAM2aNUNgYCBOnjxZZbBSq9WVTnChVCrd5svuirIM7RSJpcmp2Hg0E0arAG+1yyeRrHPu9Jm7XFAM8OBioPszwIZXgbPbgUYxEB77HspG0Td9eda1c1yznpXBQP83gdueBJKmQTjyE4S9X0J26AfgjuelSUlcsTyAB+L32XlY187BenYO1rPz3ExdV/c8lw2cUalU6NSpEzZt2mTfZ7VasWnTJocWrKvNnTsXs2bNwrp169C5c+cqj7M5f/48Ll26hLCwsFopd0MSG+GLZkFeKDZbsf5guquLQ64S0QkYtQZ48g/gqa3SjIJUvzRqBgxbBoxZD0R0lhZ63vwasLATsHe5NAskERERXZNLZySYNGkSPvnkEyxduhRHjhzB008/jYKCAvssgSNGjHCY3OLNN9/Eq6++isWLFyMqKgrp6elIT09Hfr40VXZ+fj7+85//4M8//0RKSgo2bdqEQYMGoXnz5khMTHTJe/RkgiBgSLw0jf3qvRdcXBpyKUGQJrC4ydkXyc01uQ14YiMw9DPAt4m0OPbqp4GPegB/fy4tVUBERESVcmmwGjZsGN566y1MnToV8fHx2Lt3L9atW4eQEKlvf2pqKi5evGg//sMPP4TJZMIDDzyAsLAw+/bWW28BAORyOfbv34+BAweiZcuWGDt2LDp16oStW7dyLasaGlQarLafzEaGodjFpSGiOicIQOwDwMS/gIQZgFoPZBwEfnkeeLsV8OMzwLld0gLRREREZOfyQTMTJ07ExIkTK31uy5YtDo9TUlKueS2tVov169fXUskIAJoE6NCpqT92n72Cn/el4YkezVxdJCJyBqVGGmd1ywhg71fAni+A7OPAP19KW1Ab6bm44YCu0XUvR0REVN/V78WJqFYM7ii1Wv3wD7sDEjU4ukbSAtDP7AJGrwPiHgEUWiDrCLB+itSKtXIMcHoLx2IREVGDxmBF13VfbBgUMgGH0gw4npHn6uIQkSsIAtC0GzDkQ+DFY8C9b0tT7ltMwMHvgS8GAQs7An+8BRguXv96RERE9QyDFV2Xv5cKvVoFAwBWs9WKiDS+wK1PSLNEjv8d6DxWGot1JQX4bRbwTjvg64eBY78ClhJXl5aIiMgpXD7GijzDkI4R2HgkAz/uTcOLfVpBJhNcXSQicgfh8dLWZxZw+EdpLFZqMnBsrbT5hAHxjwIdH6t6qn5RBCxmoKQIMBcD5kKgpBgwF0mbbX9J6XNWC6D2kQKeWi/dakpvlTqpdY2IiMjJGKyoWu5pEwwftQIXcorw99kr6BLNwepEVI7KC4h/RNqyjkkBa9/XQN5FYOtb0hZauqC7Q2gqvS9aaqccgrwsZNlD11UBzHbfKxBo3AXwCqid1yYiogaNwYqqRaOUo19sKL79+zx++OcCgxURVS2oFZD4GnDPNODYGilkndoMpO+vxskCoNRKm0IrzU7ocF8nhSejASjOLbstNkjhTLQARVekrbqC2wHRPYCoHkDU7YDWv8ZvnYiIGi4GK6q2wR0j8O3f57FmfxqmD2wLtULu6iIRkTtTqIB2Q6Ttylkg/QCg0EgBSVEanhzuawG5qmZd+URR6iZoC1kOoeuqAGa7n3NOmt0w85C07VwEQABCY4HoO6Wg1bSb1LpFrmG1AAXZQEEmhNx06AtTgRIjoFS6umR0LaIInP8LyD0PBLYEAlsACq4nSvUfgxVV223RAQjz1eBibjHe/PUYXr2vDQSOZSCi6vBvKm11RRCk7ogqL0AfXv3zCrKBlK3Ama3SbfZxqWUtfT+Q/B4gyICw+NIWrTuBJrcBau86exsNgtUqtSgWZAL5GUB+ZumWARRkOe4rzAZEaRp/BYC7AIhzpwEBMUBw29KtjXTbKBqQ8Q9+LiOK0mLiB1YCB1cBuallzwkyoFEzIKi19HnZbgOaM3DVR4WXAY0fIGt4c+QxWFG1yWQC/q9fazz3zV4s3n4GjbyUmHh3C1cXi4io5rwCy1rVACAvHUjZBpz5Qwpal08DaXukbfv/AJkCCL+lrOtg2C2uLb+7MeYDhgtSS4XhApB7ATCcLwtO+VlSoLLeyGyRAuAVBFHXCObLqVBZCqUAnH0cOLy67DCFRmodsYWtkHbSrT6CE5rUpcungQPfAwdXAllHy/arvKVuwdknAWMucOmktB39pewYQS6F5PKBK6h1aeBSOf+9UM2IovTfyCO/SJ9v9nHANxKIfRDoMAwIbu3qEjoNgxXdkEHxEcjON2HWL4fx1obj8NWp8PhtdfhXaCIiZ/IJBWIfkDZACgb2Fq0/gJxU4Pwuadv6NhRyFW7XREOm3QNEdQca3yotqlwflRjLhaXy4el8WYAqzq3+9bT+gHcI4B0MeAWX3bdvIdJ+XQAgV6DEbMava9ag/523QHn5BJB5GMg8Unp7VJo90tbaWJ5aX9qq1aYsdIV3lGaWpJrJS5dapQ6uBC7sLtsvVwEt+gDthwIt+wIqnfSjO++iFLoyj5Z2vz0qPTYaykLykZ/KriNTAI1ipB/kQaUtW1p/qVuu1q90Iho/hi9XspQAqTtKw9Qa6d9/ebnngG3zpS0sDugwXPpe+IS4prxOwmBFN2zsHdHIKTRh4W8nMfXHg/DTKjEg7ga63hAReQrfCCBuuLQB0lixcl0HBcMFBBYcA3YcA3YskI4Jag1EdgEib5O6DjZq5voWkxITYC4ATIWlMzLa7le2rxAwFUhb3sWyAFWQVb3XUuulViLfiNLbxlJg9SofmIJq9qNYEKQp/Bs1AZrfU7bfagFyzkpBK+NwWei6dEL68X5up7TZyJRA0+5Ay0SgRSIQ2PzGy1IbSoxA2l7pfYXGSuMM3VXRFeDwT1KYOrMVgCjtF2TSmMT2DwBtBkjBpzxBkLrn6sOBmLvL9osiYEhzDFq28GXKA7KPSRt+rLpMSl1ZyCofuKq6b5slVKMHVD5131VNFKXvX0F26ZYldW8tyIIsLwvxZ49A9tvfgF9jqX58wgF9mPRvRe6GP9HNxcDpLcCRn6XlNIoulz2n9AJa9Ja+A9E9gbPbgf0rgBMbgIv7pG3DK0DMXVLIat1f6rpdz7jhp0aeYFLvlsgpNGPZn2cx6du90GuV6NkyyNXFIiKqW7axYh0fA0QR5szjOLjmI8T5FUF2YZfU1cn2A3HPF9I5ukAgsivQpKsUtsLjb35ciShK4xhyU6VWtJxz0l+Ic1KlEGTMcwxMN9T17hoUmrLQ5BtZLkA1LgtSGn3tvNaNkMmlANuoGdD63rL9JSbpM7G3bh2RJlHJTQXO/C5t61+SzmuRKAWtprfXXUuIuUia1CFlu/TD8/xf0pIDgNQtLqQtENFJ2sJvkUK6K39gmwqkhb4Pfg+cSAKs5rLnGt8qdfVqO7hmrRCCUPo9igCaJ5TtF0XpO2xr3co6Kv1BozgHKMqVbo0G6Vhz6R8C8i7W4M0JUqulWl9uGQZ9JUsz6AH1VY8VGqDw0lVh6erwdEm6X77OypEDaAoAyX9UUjSZ9AcIn7DSwBUmBS5b8LLdOqPVtdgghaMjPwMnNwKm/LLntI2AVv2lMNWslzQZkU27wdJWcAk4tEoKWef/kq5xcqPUVbTNAKmrYPSd9WZ8JIMV1YggCJgxsB1yisz4eV8anlq2G18+0QWdmtbTLjBERFcTBKBRM6QG9ET7/v0hUyqlHxHndgLn/gRSdwJp/0g/so6tkTZA6i4V3rE0bN0m3XoFOl5bFKVxSbnnpJaYnNLQZAtPOeekwHSjZArpL8sqXelMjLb7Oumvx0ptufs6qaWpfHjSNXJ969uNUKiksBLS1nF/9kngxHrg+Hrg7A5pnNDOD6VN5S39SGyZKHVr8wmt+esb86Xvw9ntUpi6sLviD21doPRDuiBTCn3pB4DdS6TnlDpp8pSIW6Qt/BbAP6puPwNTAUJy90K++kfg+DrH71lwW6mbbPuhUjnqgiBIrZy+jYEWCZUfY7WUzvKZI90W5VTzfukMoRYTgNLWJKMBMNTNW7FTeUv/xnWBUmutVwAs2gAcP3MBLSP8IS9IBwwXpYCYly4tG5FX+jhtzzWu61MatMKkLrNaf+nfqLbRVbf+pV0p/arXSpefJbVIHflZ+uODxVT2nD4CaH0f0OY+oEn36wd/rwCgyzhpu3RKClj7VwBXUqS1Dvd9LZU/9gGpJSu0fXVq1G0xWFGNyWQC3n4wDoYiM34/noXRn/+Fb5/qhtahLvhrJRGRO/AKkLq4tO4vPS4xSl1gUv+UfmCn/ikFLVvXtB3vSsc1ipHGIRRdKQ1P5wCL8fqv5x0C+DWRWo/8mgB+kdJ9tb40MF0VojgmRRLYXNq6PSP9Rf70FilonUiSJtk4+kvZJAthcWWtWeG3XPuHabFB+ozPbpOC1MW9FVsLfcKkVrGo26XbwJbSfsMFKXhd2A1c2CN1ETTlSeNYUneUna9tVNqqdUtZy5b3NXqMWEpKW1eySrfscvevfpwNpbkAt5U/369paZh6oGJAdRWZXAoMNR3PaC4uXXbBIE2s4bAUw9W3uRX3lxgBnb8UksqFpSofl2/JKWU1m3G8aC2aJ/aHvPzyAVaL9FkY0qRgZb+9COSllQUwo6G0y2SeNEatOgSZFK7sYat8APOXnj+xUfrDUOlsnACAgBZS61Kb+6TvW02DfUAMcNdLQK8pwLldwP5vpLF6eReBHQulLaQ90OEhqTX0RmZ4dRMMVnRTVAoZPnzsFjz+2S7sPnsFj3+2C98/1R1NAnSuLhoRkesp1KXjrbpIj0VRah2xhaxzu6TuTpdPSVt5gkz6EX51cPJrAvg2kf6iX8kPNrpBGj3QdqC0Wa1A+j7g+AaptSZtT9n4kD/mSj+SW/QBWvaRxgtZLUBqstTqlbJNmjij/A9SQPrsygepqsbc2Vpp2g6SHlstQPYJqQy2sJV+QBrXcjJJ2uznNpGClldQxbBUfhxMNRUrfKHsOAzyDg8BjTt7VitldShL19PzDnZ1SSqSyaVW0uu1lBrzywWvdOlzLrxcukC67f5loLB0wXRTnvTdLLpcve9EWHxpmBogze5YmwRB6hrdpCvQ9w3pDxr7v5FakDMOAkkHgaRpQLOeUitW3HCP+Q4yWNFN06kUWDzyVgz7OBlH0/Pw2Gc7sfKpbgjW83/4REQOBEH6q21ADBD/iLSv6Apw7i9pHJBXUFl40kcAci6E61QymdRNM7wj0Ou/UnfME0lSa9apzVJr477l0ibIS0OU6HgN/+jSEHWHdOvXpIZlkUuz4gW3LvuulBiB9IOOYSv7uDRmrPy6UVcTZFJXMa8gqUuaV1Al96XHZpUf1m/8A/373OvYkkLuRe0NqFtIiy9XR4npqtB1dQC7LI2pi+wijVOs6ff2RinUUktYm/ukMhxeDez/VvqDxekt0nc+/mHnlKUWMFhRrfDVKfHFmC54YFEyUi8XYsTiXVgxvht8dfyPMhHRNWn9pRaQln1cXRK6mncw0PFRaSsxSV2kjpeOzbp0QjomsKU0w6AtSNVl9yWFGmjcSdowTtpXnCt1G0zbI7VieAdXDExa/+pPDmA2e0zrAN0AhUqaZMSdpzvXNQI6j5G2y2eAA9+VdZX1EAxWVGuC9Rp8ObYrhi7agaPpeRiz9C98ObYrtKr6MdMLERE1YAqVNHtZ9J1A4mvSODiF2vXdyTS+UpepZj1dWw6i2tQoGug52dWluGF1PIE/NTRNAnRYNrYL9BoFdp+9gqe/2g1TifX6JxIREXkSv0jXhyoicisMVlTrWofq8fnoW6FRyrDlWBZe/G4frFbx+icSEREREXkoBiuqE52aNsKixzpBKRfw0740TPvpEESR4YqIiIiI6icGK6ozvVoFY/5D8RAEYNmfZ/FOUjXXWSAiIiIi8jAMVlSnBsSFY+YgaRXtd387icXbzri4REREREREtY/Biurc47c1xb97S9NlzvzlMFbtOe/iEhERERER1S4GK3KKiXc3x5jbowEA/1m5HxsPZ7i4REREREREtYfBipxCEAS8cm8bDL2lMSxWEc8s34Odpy+5ulhERERERLWCwYqcRiYT8ObQWCS0CYGxxIqxS//GB1tO4kqBydVFIyIiIiK6KQxW5FQKuQzvPdIR3ZoFIN9YgrnrjqHbG5swZdUBHM/Ic3XxiIiIiIhqhMGKnE6jlGPpmC5468E4tA3To9hsxde7UtHnnT/w2Kc7selIBhcUJiIiIiKPonB1AahhUilkeKBTYwy9JQK7zlzG59tTsOFwOradzMa2k9mICtBhVPcoPNA5Et5qfk2JiIiIyL3xFyu5lCAI6NosAF2bBeDc5UIs+/Msvt6VipRLhZj+82G8veE4HuwciVHdo9AkQOfq4hIRERERVYpdAcltRDbS4aX+bfDnlHswa1A7NAvyQp6xBIu3n0HPtzbjiaV/Y8fJbIgiuwkSERERkXthixW5HS+1Ao93i8KjXZvijxNZ+Hx7Cn4/noWNRzKw8UgGWof6YPTtURgUHwGNUu7q4hIRERERMViR+5LJBPRqFYxerYJxMjMfS3ekYOXu8zianof/fn8Ab/x6FI90bYLHb4tCqK/G1cUlIiIiogaMwYo8QvNgb8wa3B4v9mmFFX+nYumOs7iQU4T3N5/CB1tOITrQC+3CfdE+XI/2Eb5oF66Hn07l6mITERERUQPBYEUexVenxPg7YzDm9mhsPJKBxdtTsOvMZZzOKsDprAL8vC/NfmyEnxbtwvVS4IqQbkP0agiC4MJ3QERERET1EYMVeSSFXIa+7cPQt30YsvONOJRmwMELuTicZsDBtFycvVSICzlFuJBThA2HM+znBXqr0La0ZcsWuJo04myDRERERHRzGKzI4wV6q9GzZRB6tgyy7zMUm3E4zYBDaQYcupCLQ2kGnMjMQ3a+CX8cz8Ifx7Psx/qoFWgT5gNtsQyX/kxF00BvNPbXobG/Fl5cQ4uIiIiIqoG/Gqle0muUuK1ZAG5rFmDfV2y24Gh6Hg5eyMWhNClsHb2YhzxjCXalXAEgw+9rjjpcx1+ntIesxv5aRDay3dchwo/Bi4iIiIgk/FVIDYZGKUd8pB/iI/3s+8wWK05m5mNf6mWs+/MAVP6huJBTjPNXipBbZMaVQjOuFObiwIXcSq/ZyEtlD122ABbhp0UjLxV8tUr46VTQaxRQyLlkHBEREVF9xmBFDZpSLkObMD2aB2qhTd+H/v3joVQqAUjdCS9cKcL5K0U4f6UQ5y5Lt7bHhuISXC4w4XKBCfvPVx68bHzUCui1ytKwVXar1yrhp1U57LdvOiW8VArIZZxsg4iIiMjdMVgRVUGvUUIfpkSbMH2lz+cW2YJXIc5dKQtdaTlFyCk0I7fIjHxjCQAgz1iCPGMJLuQU3XA5VAoZtEo5dCo5tEo5tFfd6lS2+wpoVTLoVApoyh1vW0RZFEVYRBEWqwhRBCxWEVbRtqF0v1i6H7Bedd9qFQFI64sBgEwQIAiATAAESPcFQSh9LB0nQNonHSc9tlqtOJQlwLL/IrQqJRRyGZRyAUq5DEq5DAq5AKVMBqVCgEImg8q2r/Q4+/Eymb0sRERERK7GYEVUQ7aWpbbhlQcvQOpqaCiSQlZO6a2hyGwPXrZbaTM57DOWWAEAphIrTCVW5BaZnfXWnECOr04eqJUryRwCXbkQVy7MOYS+crcCpGP0WgVCfbUI02sQ5qdBmK8Gob5ahPtqEOqrgY9GWStlJSIiovqLwYqoDinlMgR4qxHgrb7hc4vNFhSZLCgsvS0yWVBktqDQVIJiswWFpY9tzxVWdt9cgiKTBQAglwmQCdIml0nBQy4TIBcECIIAuUwKGbLSfTJBanWSCaWPS4eJiaUtWNItIEK6L5a2fImQnofDcSJESMeUWKxIz8iEf0AgSqwizBYRJVYrzCUizFYrzBYrSiwizBar9FzprclirbSerNKFIb1LsQafEpBuAI5n5Ff5vLdaURq2pNAV5qu1Pw7300rhS63gGmlEREQNGIMVkZvSlHbj83d1QWqZ2WzG2rVr0b9/Z/t4tuqwdVMssUohq8RS2q3RHuxg79poeyyiNOyVhj6grGtj+YCYU2jGxdwiXMwtLt2KkF5639al80RmPk5kVh2+vFRy+GiUZeWBVAaUe2x7H7bnbPdhP146SqOUI9BbjSAfNQK9VeXuO9428lJxDB4REZGbYLAiIo8gCAIUcgEKOezjxpyhwFiCdEMxLuaUBa603GKklwtiuUVmFJgsKChtHbzp1zRZcKnAhGMZedc8TiZIM1PaglaQtxqBpWGskVaBi/llYY2IiIjqFoMVEdE1eKkViAnyRkyQd5XHFJpKcDG32N7tUnCY0KPc/dLnJOX3lRsLBgEFphJk5xuRnW9EVp4R2fkmZOcZkWV/bMSlAhOsIqTn8k04ml5ZCFPgh4s7MLxLJIZ0bIwgnxvvkkpERETVw2BFRHSTdCrFNYNXXbBYRVwuMNmDlu3Wdj/TUIy/Uy7hdHYBXl97FHPXHcPdrYMx7NZI9GwZxLXViIiIahmDFRGRB5LLBKn7XxWtUGazGat+WgtzeAes3JOGvedysOFwBjYczkCIXo2htzTGQ50jERXo5eSSExER1U8MVkRE9ZRGAdzfuTEe6xaNY+l5+Pbvc/jhnwvIMBjxwZZT+GDLKXSNboRht0aiX/swaFXOG7tGRERU3zBYERE1AK1CffDqfW3x376tsfFIBlb8dQ5/nMjCzjOXsfPMZUz78RAGxodj2K2RiI3w5dTxREREN4jBioioAVEpZOgfG4b+sWFIyynCyt3n8e3f53D+ShG+2pmKr3amonWoDx7qHIkhHSPg76VydZGJiIg8gstHL7///vuIioqCRqNB165dsWvXriqP/eSTT9CjRw/4+/vD398fCQkJFY4XRRFTp05FWFgYtFotEhIScOLEibp+G0REHifcT4tn72mBP/5zF756oisGxoVDpZDhaHoeZv5yGF1f34Rnlu/B9pPZnLadiIjoOlwarFasWIFJkyZh2rRp2LNnD+Li4pCYmIjMzMxKj9+yZQsefvhhbN68GcnJyYiMjESfPn1w4cIF+zFz587Fu+++i0WLFmHnzp3w8vJCYmIiiouLnfW2iIg8ikwm4PbmgXj34Y7466UEzBzUDu3C9TBZrFiz/yIe/XQnhnywA1uOZTJgERERVcGlwWr+/PkYN24cRo8ejbZt22LRokXQ6XRYvHhxpcd/9dVXmDBhAuLj49G6dWt8+umnsFqt2LRpEwCptWrBggV45ZVXMGjQIHTo0AFffPEF0tLSsHr1aie+MyIiz+SrU2JEtyisebYHfvnXHXj8tqbQKGXYey4Hoz7/iwGLiIioCi4bY2UymbB7925MmTLFvk8mkyEhIQHJycnVukZhYSHMZjMaNWoEADhz5gzS09ORkJBgP8bX1xddu3ZFcnIyhg8fXul1jEYjjEaj/bHBYAAgTVdsNptv+L3VJtvru7oc9R3r2XlY185RG/XcKliHqfe2wtN3RuHTbSlY/tc5e8CKa+yLZ++OQY/mAQ16ogt+n52Hde0crGfnYD07T23UdXXPFUQX/dkxLS0NERER2LFjB7p162bfP3nyZPz+++/YuXPnda8xYcIErF+/HocOHYJGo8GOHTtw++23Iy0tDWFhYfbjHnroIQiCgBUrVlR6nenTp2PGjBkV9i9fvhw6na4G746IqP4xmIBNaTJszxBgtkphqqm3iH6NrWjtJ6IB5ysiIqrHCgsL8cgjjyA3Nxd6vb7K4zx2VsA33ngD33zzDbZs2QKNRnNT15oyZQomTZpkf2wwGOzjt65Vec5gNpuRlJSE3r17Q6lUurQs9Rnr2XlY185RV/U8HEBWntHegnU234pFR+UNtgWL32fnYV07B+vZOVjPzlMbdW3rzXY9LgtWgYGBkMvlyMjIcNifkZGB0NDQa5771ltv4Y033sDGjRvRoUMH+37beRkZGQ4tVhkZGYiPj6/yemq1Gmq1usJ+pVLpNl92dypLfcZ6dh7WtXPURT2HN1Ji6sD2eOqu5vj499P4cudZ7Dufi7Ff7EF8pB+eT2iBni2DGlTA4vfZeVjXzsF6dg7Ws/PcTF1X9zyXTV6hUqnQqVMn+8QTAOwTUZTvGni1uXPnYtasWVi3bh06d+7s8Fx0dDRCQ0MdrmkwGLBz585rXpOIiG5csI8Gr9zXFn9MvgtP3BHNSS6IiKhBc+msgJMmTcInn3yCpUuX4siRI3j66adRUFCA0aNHAwBGjBjhMLnFm2++iVdffRWLFy9GVFQU0tPTkZ6ejvz8fACAIAh4/vnnMXv2bPz00084cOAARowYgfDwcAwePNgVb5GIqN5jwCIiInLxGKthw4YhKysLU6dORXp6OuLj47Fu3TqEhIQAAFJTUyGTlWW/Dz/8ECaTCQ888IDDdaZNm4bp06cDkCa/KCgowPjx45GTk4M77rgD69atu+lxWEREdG22gDW+ZzN7F0FbwIqP9MOEXjHoGh0AXx27vRARUf3j8skrJk6ciIkTJ1b63JYtWxwep6SkXPd6giBg5syZmDlzZi2UjoiIblRVAWv8st0AgCaNdGgfoUf7CF/ERviifbgv/L1ULi41ERHRzXF5sCIiovqpfMD65I/TWHcoHecuFyH1ciFSLxdi7YF0+7ERflrERvgitrEv2oXrERvhiwDvipMKERERuSsGKyIiqlPBPhq8fG9bvHxvW+QUmnDwggEH03Jx4EIuDl7IxdlLhbiQU4QLOUVYd6gsbIX7atCutFUrNsIX7SL0CPZht24iInJPDFZEROQ0fjoV7mgRiDtaBNr35RaZcShNClkHLhhw6EIuTmcXIC23GGm5xUg6XLYsR4hejfbhvmge7I2YIG/EBHujeZA3x20REZHLMVgREZFL+WqV6B4TiO4xZWErr9iMQ2kGHLxgC1xS2MowGJFhyMSmo5kO1wj0VtmDVkyQN2KCvNA82BvhvlrIZA1nPS0iInIdBisiInI7PholbmsWgNuaBdj35RtLcOSiAUcuGnAqMx+nsgpwMjMf6YZiZOebkJ1/GTvPXHa4jkYpQ7PAspatmGAvxAR5IzrQCxql3Nlvi4iI6jEGKyIi8gjeagVujWqEW6MaOezPN5bgdFY+TmXl41SmFLZOZeUj5VIBis1WHL5owOGLBodzBAEI99UiyEeNAC8VArxVCPAuu9/Iq/x9FdQKhjAiIro2BisiIvJo3moFOjT2Q4fGfg77SyxWnLtSZA9ap0pvT2bmw1BcYp8wozp81Ap7+GrkpUJgaeDy0yqQmiVAdSQTPlo1dGo5dCo5dEoFtCrpvlYpZ3dEIqIGgMGKiIjqJYVchuhAL0QHeqE3Quz7RVFEdr4JqZcLkJ1vwuUCEy7lG3GpwIRLpY+z8424XCDdL7GKyDOWIM9YgpRLhZW8khzLTu69Zlm0ytKQVRq2dCpF6a0cWpUCOqUcOrXcfpxGKXcIZlqVouJzpbdqhQyCwOBGRORqDFZERNSgCIKAIB81gnyuv06WKIowFJUgu8BYGrqMDmEsO8+IE+fSoPXxR7HZikJzCYpMFhSWbjZFZguKzBagoC7ejxTctKVBS6uUQ6WQQaWQQSmXQV16q5LLoFTIoJQLFfap5NLxKrn0vEohh1IuQARgtYqwioBFFEvvi7CU3lpFSPcrO6b0vigCXmoFGnmp4O+lgr9OCX+ddL+RTgWtit0siah+YLAiIiKqgiAI8NUp4atTIiao4vNmsxlr155H//5doVQ6TvlutYooLpECVpHJggJTif2+FLxK7AGsqNz94tIQZrtvO8d+3yw9NlmsAABRRFmQq4PgVtc0SpkUtHSl3St1ytJbFRrplKVhTAUflQyp+cCulMswWwUU2erCXLF+ikv3la/HsuOkelPIBShkApRyWel9KVRKj2VQygRpv/2+FEaV5Y4t38WzfJuhrQFRKLe3bF/FA9UKGfQaBXw0SviUu9VrpVtvlaJOupOKoghjiVX6Tpql72FugRFn84BTWQXw89LAWyO1qLqqO6tYGuDl7E5LHoDBioiIqA7IZEJpl7+6+V9ticWK4hIrCk0lKDaVtZbZQpepxAqzRYTJYoG5RITRYoW5xApTuduy48odX1K2XxAAuSAFCJnw/+3dfWyV9f3/8dd1bntfWgq9EaggWERtE0FKf2y6WWJbDBFlmW7NUpyRMAsBiZuRjBUyE4xLdHNxbNmN+2MCG2Y4t+gcY1IjAUVMpSzYrzYmsBTolNH7m9NzfX5/nJv2QLmR056rPTwfycm5rs91lb7Pu++W8+7n+lwNvbl1WaHH8HZ4PHJO9PzQOZakroEh/a9nUP/rHdT/egKh595BBYJG/QFbpzv6dbqj/ypetUdq/mBc8jmRWZaU4fOM2nSNHHNbVkzTfrmGPtJMBW0zymf06PnjB2M+f7rPo3S/Wxl+T+iREnpO93uUGX6OjEXGvW5LfYPhGr3gFwN9I35pENoeUl/Ajv6SYeT5JtxY+cMzscPP7gvGYvcjxyNjbpcVrfXhOjfh52BM7Q9GvheGLvh+GrIVtE30a5AVfs5O9SorxausVE/4eXh/+Fjo6+R1u676ax+0jQJBW0O20VAwFMOQbWsoODxuG6PMFK9y0rxK9bq5NNhBNFYAAExCHrdLGW6XMvyT879yY4x6BoPRhutcz6DO9wbCz4M6N6IJOxc+Z6C/X7lZGdH1aCnekevQwuvPLliLduFlkiletyxLCkTemAaNAuE3qkNBWwHbKDBka8gOv4kNv3mNbAfC5wwFbUV6EhN5lonZv/D1hs65+GP6A7a6+gPq6h8KP0Lbnf0BBYKhyykj6/x0VQ3ol+fzuMI3XnGrr69Pttur7oFQ42VM6O6b3QNDOquBcfn8VxK0zUWX2DqpLxBUe9e15SLN51ZmikcKuPXC/70bbppCDdPgkB3dD9j2qLV0OT6Pa/hy2zSfctK9mpI2fAludDs8E5yTFmr6uMHO2JicP40BAMCkZllWdHZjZm7aFc8PXXb5hpYvX3rRZZfJKnKpXucoTVdXf0CdfeHn8DFjjFJ9bqX7h292kuYP3xwlsh1uMNMj2+FmyhOeRRnOc5U8Ho8Ghmx19Q+pJ9xYdQ8Mqbt/SD2DQ6OOd4/YHwqaC27CMtz4Dt+UxaU0n0cpI27IcuHHeFwuBYK2BgK2BoOhyzkHw/sD4ZmmgfAs1EB4lilmP2hrIBDUkG2i6w59I9YWeiNrDCOzW6OM+0asV3RZlroGAuroC30NOvsD6uwLfR06+yLbscc6+gLqCTeFww2iJfWNdkOcy4tcjuoJX7pqSdEmfHDIDv8h9atv+lxW6A+1T0nzKSW8RtPvdsnvHc5FNGfhmcBoTrzDuYmOe0K1FFmHGbqc08i2Q2PGDB8L7Q9vx5xvpJk5abqvtPBL58gpNFYAAAATkGVZSgnPsk3PdPbzX83NXnB5Q0E7OhN5rqtf+985qKX/b4lSfN6L1vrFru0Lr/1zhS+vHeVSv5EzwOd7AzrXG5r5Dc0IB0LbvaEZ4JEzwz2DQdlG4WMBB7JyeXffPI3GCgAAAMAwj9sVugQv3aeiLJ9OZhstKs4ZkxnY2Bngq/+4gaGgOsJN1fneQQ2MmP0bDAbDs4TDs3/DM4HB6Fq1gRFr1iLjlixZlkLrMF2hZyu8JjOyNjN2f8T51vD58wsc+I1CHGisAAAAgOuQ3+PW9Cy3pmelOB1KUrj625IAAAAAAEZFYwUAAAAAcaKxAgAAAIA40VgBAAAAQJxorAAAAAAgTjRWAAAAABAnGisAAAAAiBONFQAAAADEicYKAAAAAOJEYwUAAAAAcaKxAgAAAIA40VgBAAAAQJxorAAAAAAgTjRWAAAAABAnGisAAAAAiBONFQAAAADEicYKAAAAAOJEYwUAAAAAcfI4HcBEZIyRJHV2djociRQIBNTb26vOzk55vV6nw0la5DlxyHVikOfEIM+JQ64TgzwnBnlOnLHIdaQniPQIl0JjNYquri5J0syZMx2OBAAAAMBE0NXVpezs7Eset8yVWq/rkG3bamtrU2ZmpizLcjSWzs5OzZw5U6dOnVJWVpajsSQz8pw45DoxyHNikOfEIdeJQZ4Tgzwnzljk2hijrq4uFRUVyeW69EoqZqxG4XK5NGPGDKfDiJGVlcU3XgKQ58Qh14lBnhODPCcOuU4M8pwY5Dlx4s315WaqIrh5BQAAAADEicYKAAAAAOJEYzXB+f1+NTQ0yO/3Ox1KUiPPiUOuE4M8JwZ5ThxynRjkOTHIc+IkMtfcvAIAAAAA4sSMFQAAAADEicYKAAAAAOJEYwUAAAAAcaKxAgAAAIA40VhNcC+99JJuvPFGpaSkqLy8XO+//77TISWVrVu3yrKsmMf8+fOdDispvPPOO1qxYoWKiopkWZZee+21mOPGGP3oRz9SYWGhUlNTtWzZMn3yySfOBDuJXSnPq1evvqjGq6urnQl2Etu+fbvuvPNOZWZmavr06Vq5cqVaWlpizunv71d9fb2mTp2qjIwMrVq1SmfPnnUo4snpavL8ta997aKaXrt2rUMRT047duxQaWlp9A+mVlRU6M0334wep5bHzpVyTT2Pj2effVaWZWnjxo3RsUTUNY3VBPbHP/5RmzZtUkNDgz788EOVlZWpqqpK7e3tToeWVG699VadPn06+nj33XedDikp9PT0qKysTC+99NKox5977jm9+OKL+uUvf6n33ntP6enpqqqqUn9/f4IjndyulGdJqq6ujqnxXbt2JTDC5NDY2Kj6+nodPnxY+/btUyAQ0L333quenp7oOU888YT++te/as+ePWpsbFRbW5sefPBBB6OefK4mz5L02GOPxdT0c88951DEk9OMGTP07LPP6ujRo/rggw90zz336P7779e///1vSdTyWLpSriXqeawdOXJEv/rVr1RaWhoznpC6NpiwFi9ebOrr66P7wWDQFBUVme3btzsYVXJpaGgwZWVlToeR9CSZvXv3Rvdt2zYFBQXmJz/5SXTs/Pnzxu/3m127djkQYXK4MM/GGFNXV2fuv/9+R+JJZu3t7UaSaWxsNMaE6tfr9Zo9e/ZEzzlx4oSRZA4dOuRUmJPehXk2xpi7777bbNiwwbmgklROTo75zW9+Qy0nQCTXxlDPY62rq8vMmzfP7Nu3Lya3iaprZqwmqMHBQR09elTLli2LjrlcLi1btkyHDh1yMLLk88knn6ioqEhz5sxRbW2tTp486XRISe+zzz7TmTNnYuo7Oztb5eXl1Pc4OHDggKZPn66SkhJ973vf0xdffOF0SJNeR0eHJCk3N1eSdPToUQUCgZianj9/vmbNmkVNx+HCPEe88sorysvL02233aann35avb29ToSXFILBoHbv3q2enh5VVFRQy+PowlxHUM9jp76+Xvfdd19M/UqJ+xntGbN/CWPq888/VzAYVH5+fsx4fn6+Pv74Y4eiSj7l5eX6/e9/r5KSEp0+fVrbtm3TV7/6VR0/flyZmZlOh5e0zpw5I0mj1nfkGMZGdXW1HnzwQc2ePVutra3avHmzampqdOjQIbndbqfDm5Rs29bGjRu1dOlS3XbbbZJCNe3z+TRlypSYc6npazdaniXp29/+toqLi1VUVKRjx47pqaeeUktLi/785z87GO3k09zcrIqKCvX39ysjI0N79+7VggUL1NTURC2PsUvlWqKex9Lu3bv14Ycf6siRIxcdS9TPaBorXNdqamqi26WlpSovL1dxcbH+9Kc/6dFHH3UwMmBsPPzww9Ht22+/XaWlpbrpppt04MABVVZWOhjZ5FVfX6/jx4+zHnOcXSrPa9asiW7ffvvtKiwsVGVlpVpbW3XTTTclOsxJq6SkRE1NTero6NCrr76quro6NTY2Oh1WUrpUrhcsWEA9j5FTp05pw4YN2rdvn1JSUhyLg0sBJ6i8vDy53e6L7lZy9uxZFRQUOBRV8psyZYpuvvlmffrpp06HktQiNUx9J96cOXOUl5dHjV+jdevW6W9/+5vefvttzZgxIzpeUFCgwcFBnT9/PuZ8avraXCrPoykvL5ckavpL8vl8mjt3rhYuXKjt27errKxMP/vZz6jlcXCpXI+Ger42R48eVXt7u+644w55PB55PB41NjbqxRdflMfjUX5+fkLqmsZqgvL5fFq4cKH2798fHbNtW/v374+5Lhdjq7u7W62trSosLHQ6lKQ2e/ZsFRQUxNR3Z2en3nvvPep7nP3nP//RF198QY1/ScYYrVu3Tnv37tW//vUvzZ49O+b4woUL5fV6Y2q6paVFJ0+epKa/hCvleTRNTU2SRE3HybZtDQwMUMsJEMn1aKjna1NZWanm5mY1NTVFH4sWLVJtbW10OxF1zaWAE9imTZtUV1enRYsWafHixfrpT3+qnp4ePfLII06HljSefPJJrVixQsXFxWpra1NDQ4Pcbre+9a1vOR3apNfd3R3zG7fPPvtMTU1Nys3N1axZs7Rx40Y988wzmjdvnmbPnq0tW7aoqKhIK1eudC7oSehyec7NzdW2bdu0atUqFRQUqLW1VT/4wQ80d+5cVVVVORj15FNfX6+dO3fqL3/5izIzM6PX5GdnZys1NVXZ2dl69NFHtWnTJuXm5iorK0vr169XRUWFlixZ4nD0k8eV8tza2qqdO3dq+fLlmjp1qo4dO6YnnnhCd91110W3VsalPf3006qpqdGsWbPU1dWlnTt36sCBA3rrrbeo5TF2uVxTz2MnMzMzZi2mJKWnp2vq1KnR8YTU9ZjdXxDj4uc//7mZNWuW8fl8ZvHixebw4cNOh5RUHnroIVNYWGh8Pp+54YYbzEMPPWQ+/fRTp8NKCm+//baRdNGjrq7OGBO65fqWLVtMfn6+8fv9prKy0rS0tDgb9CR0uTz39vaae++910ybNs14vV5TXFxsHnvsMXPmzBmnw550RsuxJPPyyy9Hz+nr6zOPP/64ycnJMWlpaeaBBx4wp0+fdi7oSehKeT558qS56667TG5urvH7/Wbu3Lnm+9//vuno6HA28Enmu9/9rikuLjY+n89MmzbNVFZWmn/84x/R49Ty2Llcrqnn8XXhrewTUdeWMcaMXZsGAAAAANcf1lgBAAAAQJxorAAAAAAgTjRWAAAAABAnGisAAAAAiBONFQAAAADEicYKAAAAAOJEYwUAAAAAcaKxAgAAAIA40VgBADDGLMvSa6+95nQYAIAEorECACSV1atXy7Ksix7V1dVOhwYASGIepwMAAGCsVVdX6+WXX44Z8/v9DkUDALgeMGMFAEg6fr9fBQUFMY+cnBxJocv0duzYoZqaGqWmpmrOnDl69dVXYz6+ublZ99xzj1JTUzV16lStWbNG3d3dMef87ne/06233iq/36/CwkKtW7cu5vjnn3+uBx54QGlpaZo3b55ef/318X3RAABH0VgBAK47W7Zs0apVq/TRRx+ptrZWDz/8sE6cOCFJ6unpUVVVlXJycnTkyBHt2bNH//znP2Mapx07dqi+vl5r1qxRc3OzXn/9dc2dOzfmc2zbtk3f/OY3dezYMS1fvly1tbU6d+5cQl8nACBxLGOMcToIAADGyurVq/WHP/xBKSkpMeObN2/W5s2bZVmW1q5dqx07dkSPLVmyRHfccYd+8Ytf6Ne//rWeeuopnTp1Sunp6ZKkN954QytWrFBbW5vy8/N1ww036JFHHtEzzzwzagyWZemHP/yhfvzjH0sKNWsZGRl68803WesFAEmKNVYAgKTz9a9/PaZxkqTc3NzodkVFRcyxiooKNTU1SZJOnDihsrKyaFMlSUuXLpVt22ppaZFlWWpra1NlZeVlYygtLY1up6enKysrS+3t7df6kgAAExyNFQAg6aSnp190ad5YSU1NvarzvF5vzL5lWbJtezxCAgBMAKyxAgBcdw4fPnzR/i233CJJuuWWW/TRRx+pp6cnevzgwYNyuVwqKSlRZmambrzxRu3fvz+hMQMAJjZmrAAASWdgYEBnzpyJGfN4PMrLy5Mk7dmzR4sWLdJXvvIVvfLKK3r//ff129/+VpJUW1urhoYG1dXVaevWrfrvf/+r9evX6zvf+Y7y8/MlSVu3btXatWs1ffp01dTUqKurSwcPHtT69esT+0IBABMGjRUAIOn8/e9/V2FhYcxYSUmJPv74Y0mhO/bt3r1bjz/+uAoLC7Vr1y4tWLBAkpSWlqa33npLGzZs0J133qm0tDStWrVKzz//fPTfqqurU39/v1544QU9+eSTysvL0ze+8Y3EvUAAwITDXQEBANcVy7K0d+9erVy50ulQAABJhDVWAAAAABAnGisAAAAAiBNrrAAA1xWugAcAjAdmrAAAAAAgTjRWAAAAABAnGisAAAAAiBONFQAAAADEicYKAAAAAOJEYwUAAAAAcaKxAgAAAIA40VgBAAAAQJz+Pw1RAbcUDraaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COEpfGu_i1uO",
    "outputId": "86cc3369-139e-4ec0-b503-d493905f4a90"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "class WordNet2Vec:\n",
    "    def __init__(self, model: WordNetEmbeddingModel, word_to_id, id_to_word, device): \n",
    "        self.__devve = device\n",
    "        self.__model = model\n",
    "        self.word_to_id = word_to_id\n",
    "        self.id_to_word = id_to_word\n",
    "\n",
    "    def get_vector(self, word: str):\n",
    "        word_id = self.word_to_id.get(word, None)\n",
    "        if word_id is None:\n",
    "            raise Exception(f\"word not found: {word}\")\n",
    "        tensor = torch.tensor([word_id]).to(self.__devve)\n",
    "        emb = self.__model.input_embeddings(tensor)[0].reshape(1, -1).cpu().detach().numpy()\n",
    "        return emb\n",
    "\n",
    "    def calculate_similarity(self, word1: str, word2: str):\n",
    "        emb1 = self.get_vector(word1)\n",
    "        emb2 = self.get_vector(word2)\n",
    "\n",
    "        similarity = cosine_similarity(emb1, emb2)[0][0]\n",
    "        return similarity\n",
    "\n",
    "    def predict(self, word:str, top_k: int = 5):\n",
    "        embedding = self.get_vector(word)\n",
    "\n",
    "        all_embeddings = self.__model.input_embeddings.weight.cpu().detach().numpy()\n",
    "\n",
    "        similarities = cosine_similarity(embedding, all_embeddings).flatten()\n",
    "\n",
    "        # Get the indices of the top k most similar words\n",
    "        top_k_indices = np.argsort(similarities)[::-1][:top_k+1]  # Exclude the input word itself\n",
    "    \n",
    "        # Get the predicted words\n",
    "        predicted_words = [self.id_to_word[idx] for idx in top_k_indices]\n",
    "    \n",
    "        return predicted_words\n",
    "\n",
    "    def evaluate_word_similarity(self, dataset):\n",
    "        similarities = []\n",
    "        human_scores = []\n",
    "\n",
    "        for word1, word2, human_score in dataset:\n",
    "            if word1 in self.word_to_id and word2 in self.word_to_id:\n",
    "                model_similarity = self.calculate_similarity(word1, word2)\n",
    "                similarities.append(model_similarity)\n",
    "                human_scores.append(human_score)\n",
    "\n",
    "        spearman_corr, _ = spearmanr(similarities, human_scores)\n",
    "        pearson_corr, _ = pearsonr(similarities, human_scores)\n",
    "        return {\"spearman\": spearman_corr, \"pearson\": pearson_corr}\n",
    "\n",
    "    def evaluate_word_analogies(self, analogy_dataset):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for w1, w2, w3, w4 in analogy_dataset:\n",
    "            if all(word in self.word_to_id for word in [w1, w2, w3, w4]):\n",
    "                predicted_words = self.predict(w3, top_k=10)\n",
    "                if w4 in predicted_words:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        return accuracy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0U63AXKFbmS0",
    "outputId": "30ae4c3a-c712-4c55-e72b-810742496ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: wordnet_embedding_model_partial2.pth\n",
      "Model saved to Google Drive: /content/drive/MyDrive/wordnet_embedding_model_partial2.pth\n"
     ]
    }
   ],
   "source": [
    "# prompt: save the model in the project and google drive\n",
    "\n",
    "import os\n",
    "\n",
    "# Save the model to the project directory\n",
    "model_save_path = 'wordnet_embedding_model_partial2.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "\n",
    "# Save the model to Google Drive\n",
    "drive_save_path = '/content/drive/MyDrive/wordnet_embedding_model_partial2.pth'  # Update with your desired path\n",
    "torch.save(model.state_dict(), drive_save_path)\n",
    "print(f\"Model saved to Google Drive: {drive_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KoCmKAbZvpsu",
    "outputId": "5070cb51-4c29-4131-a46d-8e48b533d117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'sun' and 'hot': -0.06679953634738922\n",
      "Predicted words: ['sun', 'church_service', 'hulk', 'disbeliever', 'torpedo_boat', 'orifice']\n",
      "Predicted words: ['hot', 'kyphosidae', 'epicalyx', 'bawdy', 'occupied', 'bas_relief']\n"
     ]
    }
   ],
   "source": [
    "wn2vec = WordNet2Vec(model, word_to_id, id_to_word, device)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "word1 = \"sun\"\n",
    "word2 = \"hot\"\n",
    "similarity = wn2vec.calculate_similarity(word1, word2)\n",
    "print(f\"Similarity between '{word1}' and '{word2}': {similarity}\")\n",
    "\n",
    "w1_emb = wn2vec.get_vector(word1)\n",
    "\n",
    "\n",
    "predictions1 = wn2vec.predict(word1)\n",
    "print(f\"Predicted words: {predictions1}\")\n",
    "predictions2 = wn2vec.predict(word2)\n",
    "print(f\"Predicted words: {predictions2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "id": "creXi4nj3dX0"
   },
   "outputs": [],
   "source": [
    "simlex999_file = \"SimLex-999.txt\"\n",
    "simlex999_ds = []\n",
    "\n",
    "with open(simlex999_file, 'r') as file:\n",
    "    _ = file.readline()\n",
    "    for line in file.readlines():\n",
    "        line_split = line.strip().split(\"\\t\")\n",
    "        if len(line_split) >= 4:\n",
    "            w1, w2, score = line_split[0], line_split[1], float(line_split[3])\n",
    "            simlex999_ds.append((w1, w2, score))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUB0Bj-N0pB8",
    "outputId": "ba874a7a-7796-4392-b920-31c0532a121b"
   },
   "outputs": [],
   "source": [
    "ws353_file = \"wordsim353_agreed.txt\"\n",
    "ws353_ds = []\n",
    "\n",
    "with open(ws353_file, 'r') as file:\n",
    "    _ = file.readline()\n",
    "    for line in file.readlines():\n",
    "        line_split = line.strip().split(\"\\t\")\n",
    "        if len(line_split) >= 4:\n",
    "            w1, w2, score = line_split[1], line_split[2], float(line_split[3])\n",
    "            ws353_ds.append((w1, w2, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "id": "7hh0g4Pn3eRm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Similarity - Spearman: 0.0597, Pearson: 0.0665\n"
     ]
    }
   ],
   "source": [
    "results = wn2vec.evaluate_word_similarity(ws353_ds)\n",
    "print(f\"Word Similarity - Spearman: {results['spearman']:.4f}, Pearson: {results['pearson']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "id": "-I_TZVWI1DEB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Similarity - Spearman: -0.0553, Pearson: -0.0680\n"
     ]
    }
   ],
   "source": [
    "results1 = wn2vec.evaluate_word_similarity(simlex999_ds)\n",
    "print(f\"Word Similarity - Spearman: {results1['spearman']:.4f}, Pearson: {results1['pearson']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "id": "hru8fSER3fUC"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "lm3A6kU91O5S",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6bb4a704-4588-4d62-858f-02477cd7df61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'able.a.01',\n",
       "  'lemmas': ['able'],\n",
       "  'definition': \"(usually followed by `to') having the necessary means or skill or know-how or authority to do something\",\n",
       "  'pos': 'a',\n",
       "  'examples': ['able to swim',\n",
       "   'she was able to program her computer',\n",
       "   'we were at last able to buy a car',\n",
       "   'able to get a grant for the project'],\n",
       "  'definition_tokens': ['usually',\n",
       "   'followed',\n",
       "   'by',\n",
       "   'to',\n",
       "   'having',\n",
       "   'the',\n",
       "   'necessary',\n",
       "   'mean',\n",
       "   'or',\n",
       "   'skill',\n",
       "   'or',\n",
       "   'or',\n",
       "   'authority',\n",
       "   'to',\n",
       "   'do',\n",
       "   'something']},\n",
       " {'name': 'unable.a.01',\n",
       "  'lemmas': ['unable'],\n",
       "  'definition': \"(usually followed by `to') not having the necessary means or skill or know-how\",\n",
       "  'pos': 'a',\n",
       "  'examples': ['unable to get to town without a car',\n",
       "   'unable to obtain funds'],\n",
       "  'definition_tokens': ['usually',\n",
       "   'followed',\n",
       "   'by',\n",
       "   'to',\n",
       "   'not',\n",
       "   'having',\n",
       "   'the',\n",
       "   'necessary',\n",
       "   'mean',\n",
       "   'or',\n",
       "   'skill',\n",
       "   'or']},\n",
       " {'name': 'abaxial.a.01',\n",
       "  'lemmas': ['abaxial', 'dorsal'],\n",
       "  'definition': 'facing away from the axis of an organ or organism',\n",
       "  'pos': 'a',\n",
       "  'examples': ['the abaxial surface of a leaf is the underside or side facing away from the stem'],\n",
       "  'definition_tokens': ['facing',\n",
       "   'away',\n",
       "   'from',\n",
       "   'the',\n",
       "   'axis',\n",
       "   'of',\n",
       "   'an',\n",
       "   'organ',\n",
       "   'or',\n",
       "   'organism']},\n",
       " {'name': 'adaxial.a.01',\n",
       "  'lemmas': ['adaxial', 'ventral'],\n",
       "  'definition': 'nearest to or facing toward the axis of an organ or organism',\n",
       "  'pos': 'a',\n",
       "  'examples': ['the upper side of a leaf is known as the adaxial surface'],\n",
       "  'definition_tokens': ['nearest',\n",
       "   'to',\n",
       "   'or',\n",
       "   'facing',\n",
       "   'toward',\n",
       "   'the',\n",
       "   'axis',\n",
       "   'of',\n",
       "   'an',\n",
       "   'organ',\n",
       "   'or',\n",
       "   'organism']},\n",
       " {'name': 'acroscopic.a.01',\n",
       "  'lemmas': ['acroscopic'],\n",
       "  'definition': 'facing or on the side toward the apex',\n",
       "  'pos': 'a',\n",
       "  'examples': [],\n",
       "  'definition_tokens': ['facing',\n",
       "   'or',\n",
       "   'on',\n",
       "   'the',\n",
       "   'side',\n",
       "   'toward',\n",
       "   'the',\n",
       "   'apex']},\n",
       " {'name': 'basiscopic.a.01',\n",
       "  'lemmas': ['basiscopic'],\n",
       "  'definition': 'facing or on the side toward the base',\n",
       "  'pos': 'a',\n",
       "  'examples': [],\n",
       "  'definition_tokens': ['facing',\n",
       "   'or',\n",
       "   'on',\n",
       "   'the',\n",
       "   'side',\n",
       "   'toward',\n",
       "   'the',\n",
       "   'base']},\n",
       " {'name': 'abducent.a.01',\n",
       "  'lemmas': ['abducent', 'abducting'],\n",
       "  'definition': 'especially of muscles; drawing away from the midline of the body or from an adjacent part',\n",
       "  'pos': 'a',\n",
       "  'examples': [],\n",
       "  'definition_tokens': ['especially',\n",
       "   'of',\n",
       "   'muscle',\n",
       "   'drawing',\n",
       "   'away',\n",
       "   'from',\n",
       "   'the',\n",
       "   'midline',\n",
       "   'of',\n",
       "   'the',\n",
       "   'body',\n",
       "   'or',\n",
       "   'from',\n",
       "   'an',\n",
       "   'adjacent',\n",
       "   'part']},\n",
       " {'name': 'adducent.a.01',\n",
       "  'lemmas': ['adducent', 'adductive', 'adducting'],\n",
       "  'definition': 'especially of muscles; bringing together or drawing toward the midline of the body or toward an adjacent part',\n",
       "  'pos': 'a',\n",
       "  'examples': [],\n",
       "  'definition_tokens': ['especially',\n",
       "   'of',\n",
       "   'muscle',\n",
       "   'bringing',\n",
       "   'together',\n",
       "   'or',\n",
       "   'drawing',\n",
       "   'toward',\n",
       "   'the',\n",
       "   'midline',\n",
       "   'of',\n",
       "   'the',\n",
       "   'body',\n",
       "   'or',\n",
       "   'toward',\n",
       "   'an',\n",
       "   'adjacent',\n",
       "   'part']},\n",
       " {'name': 'nascent.a.01',\n",
       "  'lemmas': ['nascent'],\n",
       "  'definition': 'being born or beginning',\n",
       "  'pos': 'a',\n",
       "  'examples': ['the nascent chicks', 'a nascent insurgency'],\n",
       "  'definition_tokens': ['being', 'born', 'or', 'beginning']},\n",
       " {'name': 'emergent.s.02',\n",
       "  'lemmas': ['emergent', 'emerging'],\n",
       "  'definition': 'coming into existence',\n",
       "  'pos': 's',\n",
       "  'examples': ['an emergent republic'],\n",
       "  'definition_tokens': ['coming', 'into', 'existence']}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset_dataset_partial[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "id": "ELxUNoKD1Scg"
   },
   "outputs": [],
   "source": [
    "with open('words_to_id_sg.pkl', 'wb') as f:\n",
    "    pickle.dump(word_to_id, f)\n",
    "\n",
    "\n",
    "with open('id_to_word_sg.pkl', 'wb') as f:\n",
    "    pickle.dump(id_to_word, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
