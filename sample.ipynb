{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click !here goes the icon of the corresponding button in the gutter! button.\n",
    "To debug a cell, press Alt+Shift+Enter, or click !here goes the icon of the corresponding button in the gutter! button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/jupyter-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:45.459579Z",
     "start_time": "2024-11-22T00:28:42.886528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.corpus import wordnet2022 as wn22\n",
    "import nltk"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:45.761124Z",
     "start_time": "2024-11-22T00:28:45.465891Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d0db05623017d084",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/bogdan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bogdan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet2022 to\n",
      "[nltk_data]     /Users/bogdan/nltk_data...\n",
      "[nltk_data]   Package wordnet2022 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:45.770233Z",
     "start_time": "2024-11-22T00:28:45.764532Z"
    }
   },
   "cell_type": "code",
   "source": "# print(len([1 for _ in wn22.all_synsets()]))",
   "id": "c8eacbb6898765d9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare a partial segment of the WordNet2022 dataset",
   "id": "59b4aaea25511128"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:45.775667Z",
     "start_time": "2024-11-22T00:28:45.773069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "WORDS_PER_POS = 300\n",
    "EMBEDDING_DIM = 35"
   ],
   "id": "12d1778d064da179",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:49.445184Z",
     "start_time": "2024-11-22T00:28:45.777515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "synset_dataset_partial = []\n",
    "\n",
    "\n",
    "def get_synset_data(pos):\n",
    "    for i, synset in enumerate(wn22.all_synsets(pos=pos)):\n",
    "        if i == WORDS_PER_POS:\n",
    "            break\n",
    "        data = {\n",
    "            \"name\": synset.name(),\n",
    "            \"lemmas\": synset.lemma_names(),\n",
    "            \"definition\": synset.definition(),\n",
    "            'pos': synset.pos(),\n",
    "            \"examples\": synset.examples(),\n",
    "        }\n",
    "        synset_dataset_partial.append(data)\n",
    "\n",
    "\n",
    "poss = [\"a\", \"n\", \"v\", \"r\", \"s\"]\n",
    "for p in poss:\n",
    "    get_synset_data(p)"
   ],
   "id": "d03f1e1a0554eb98",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:49.450827Z",
     "start_time": "2024-11-22T00:28:49.447247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ],
   "id": "49d8cccf4df48620",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:49.458569Z",
     "start_time": "2024-11-22T00:28:49.452002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lema = WordNetLemmatizer()\n",
    "stop_words = set(sw.words('english'))"
   ],
   "id": "a2571614594a2788",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:49.464114Z",
     "start_time": "2024-11-22T00:28:49.460270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lema.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens"
   ],
   "id": "20d8912a8982413c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:53.675837Z",
     "start_time": "2024-11-22T00:28:49.465772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocabulary = set()\n",
    "for synset in synset_dataset_partial:\n",
    "    definition_tokens = process_text(synset['definition'])\n",
    "    vocabulary.update(definition_tokens)\n",
    "    examples_tokens = []\n",
    "    for example in synset['examples']:\n",
    "        example_tokens = process_text(example)\n",
    "        examples_tokens.extend(example_tokens)\n",
    "    vocabulary.update(synset['lemmas'])\n",
    "    vocabulary.update(examples_tokens)\n",
    "    synset['definition_tokens'] = definition_tokens\n",
    "    synset['examples_tokens'] = examples_tokens\n",
    "    "
   ],
   "id": "bfd2256f42cceae1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:53.686791Z",
     "start_time": "2024-11-22T00:28:53.680607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "words_to_idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "idx_to_words = {idx: word for word, idx in words_to_idx.items()}"
   ],
   "id": "b0db84df7868b623",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:53.696882Z",
     "start_time": "2024-11-22T00:28:53.692452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "synset_to_idx = {synset['name']: idx for idx, synset in enumerate(synset_dataset_partial)}\n",
    "idx_to_synset = {idx: synset for synset, idx in synset_to_idx.items()}"
   ],
   "id": "81859229a559e1b8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:53.706482Z",
     "start_time": "2024-11-22T00:28:53.700883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vocab_size = len(vocabulary)\n",
    "synset_size = len(synset_dataset_partial)"
   ],
   "id": "305b883b9649c40d",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:53.711683Z",
     "start_time": "2024-11-22T00:28:53.708128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CATEGORY_WEIGHTS = {\n",
    "    \"n\": 1.0,\n",
    "    \"v\": 0.85,\n",
    "    \"a\": 0.8,\n",
    "    \"r\": 0.65,\n",
    "    \"s\": 0.8\n",
    "}\n",
    "# Fixed weights for each category"
   ],
   "id": "a355e214cc9c1f2f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:53.717144Z",
     "start_time": "2024-11-22T00:28:53.715135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "    "
   ],
   "id": "321e411fe1fe84d2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test 1: Using torch embedding model",
   "id": "32d9e00fa6936bde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:55.548638Z",
     "start_time": "2024-11-22T00:28:53.718870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ],
   "id": "c90c6ef7e7816f6a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:55.560238Z",
     "start_time": "2024-11-22T00:28:55.551382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class WordNetEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, synset_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.synset_embeddings = nn.Embedding(synset_size, embedding_dim)\n",
    "\n",
    "    def forward(self, word_indices, synset_indices):\n",
    "        word_vecs = self.word_embeddings(word_indices)\n",
    "        synset_vecs = self.synset_embeddings(synset_indices)\n",
    "        return word_vecs, synset_vecs\n"
   ],
   "id": "72a102a63d1043af",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a7990ed501b16736"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:55.571152Z",
     "start_time": "2024-11-22T00:28:55.565640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.01\n",
    "\n"
   ],
   "id": "579a7a237a740498",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:55.576247Z",
     "start_time": "2024-11-22T00:28:55.573479Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3d9c8a6f32ab1a1",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:56.447617Z",
     "start_time": "2024-11-22T00:28:55.579131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = WordNetEmbeddings(vocab_size, synset_size, EMBEDDING_DIM)\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "\n"
   ],
   "id": "328b8fad8fa1d25b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:28:56.454129Z",
     "start_time": "2024-11-22T00:28:56.448656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, data, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for entry in data:\n",
    "            print(entry)\n",
    "            gloss_tokens = entry[\"definition_tokens\"]\n",
    "            example_tokens = entry[\"examples_tokens\"]\n",
    "            all_tokens = gloss_tokens + example_tokens\n",
    "\n",
    "            word_indices = torch.tensor([words_to_idx[word] for word in all_tokens if word in words_to_idx])\n",
    "            synset_index = torch.tensor([synset_to_idx[entry[\"name\"]]])\n",
    "\n",
    "            category = entry[\"pos\"]\n",
    "            weight = CATEGORY_WEIGHTS.get(category, 1.0)\n",
    "\n",
    "            word_vecs, synset_vecs = model(word_indices, synset_index)\n",
    "            target = torch.ones(word_vecs.shape[0])  \n",
    "            loss = criterion(word_vecs, synset_vecs.expand_as(word_vecs), target) * weight\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")\n"
   ],
   "id": "1139d7aa49b8b97",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-22T00:28:56.455890Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(model, synset_dataset_partial, EPOCHS)",
   "id": "c9725e14c285e26e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2652f8f94c39d357",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
