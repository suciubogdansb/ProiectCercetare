{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWo5kk4N6nXN",
    "outputId": "8b88169f-6fb9-4c00-f9ab-beb192c4eb95",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:21.008563Z",
     "start_time": "2025-01-06T09:00:18.622641Z"
    }
   },
   "source": "!pip install torch numpy matplotlib nltk  tqdm",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (2.3.0)\r\n",
      "Requirement already satisfied: numpy in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (3.8.0)\r\n",
      "Requirement already satisfied: nltk in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (3.9.1)\r\n",
      "Requirement already satisfied: tqdm in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (4.65.0)\r\n",
      "Requirement already satisfied: filelock in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from torch) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from torch) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from torch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from torch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from torch) (3.1.3)\r\n",
      "Requirement already satisfied: fsspec in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from torch) (2023.10.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from matplotlib) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from matplotlib) (4.25.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from matplotlib) (23.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from matplotlib) (10.2.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: click in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from nltk) (1.2.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from nltk) (2024.9.11)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iACiZ5Q03Cvh",
    "outputId": "df9889b9-85a0-4a4f-991f-1f0040a6c44f",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:23.028368Z",
     "start_time": "2025-01-06T09:00:21.015125Z"
    }
   },
   "source": [
    "!pip install ipdb"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipdb in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (0.13.13)\r\n",
      "Requirement already satisfied: ipython>=7.31.1 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from ipdb) (8.20.0)\r\n",
      "Requirement already satisfied: decorator in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from ipdb) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (0.18.1)\r\n",
      "Requirement already satisfied: matplotlib-inline in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (0.1.6)\r\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (3.0.43)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (2.15.1)\r\n",
      "Requirement already satisfied: stack-data in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (0.2.0)\r\n",
      "Requirement already satisfied: traitlets>=5 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (5.7.1)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (4.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.31.1->ipdb) (0.2.5)\r\n",
      "Requirement already satisfied: executing in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from stack-data->ipython>=7.31.1->ipdb) (0.8.3)\r\n",
      "Requirement already satisfied: asttokens in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from stack-data->ipython>=7.31.1->ipdb) (2.0.5)\r\n",
      "Requirement already satisfied: pure-eval in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from stack-data->ipython>=7.31.1->ipdb) (0.2.2)\r\n",
      "Requirement already satisfied: six in /Users/bogdan/anaconda3/envs/AI_Lab/lib/python3.11/site-packages (from asttokens->stack-data->ipython>=7.31.1->ipdb) (1.16.0)\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qtEoct266cz",
    "outputId": "5810d782-be38-49c1-855d-d998a5b7a1f4",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:26.314754Z",
     "start_time": "2025-01-06T09:00:23.032075Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/bogdan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/bogdan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/bogdan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uWj35V7w7Ek5",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:26.327545Z",
     "start_time": "2025-01-06T09:00:26.322535Z"
    }
   },
   "source": [
    "lema = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lema.lemmatize(token) for token in tokens if token.isalpha()]\n",
    "    return tokens"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YJY0PvfV7G38",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:32.002525Z",
     "start_time": "2025-01-06T09:00:26.329824Z"
    }
   },
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize definitions and build vocabulary\n",
    "def build_wordnet_vocab():\n",
    "    vocab = set()\n",
    "    definitions = {}\n",
    "\n",
    "    poses = ['a', 'r', 's', 'v', 'n']\n",
    "\n",
    "    for pos in poses:\n",
    "        for i, synset in enumerate(wn.all_synsets(pos)):\n",
    "            if i >= 500:\n",
    "                break\n",
    "\n",
    "            word = synset.name().split('.')[0]\n",
    "            gloss = synset.definition()\n",
    "            tokens = process_text(gloss)\n",
    "            definitions[word] = tokens\n",
    "            vocab.update(tokens + [word])\n",
    "\n",
    "    word_to_id = {word: idx for idx, word in enumerate(vocab)}\n",
    "    id_to_word = {idx: word for word, idx in word_to_id.items()}\n",
    "    return definitions, word_to_id, id_to_word\n",
    "\n",
    "definitions, word_to_id, id_to_word = build_wordnet_vocab()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TVNMC-Y37JJk",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:32.008730Z",
     "start_time": "2025-01-06T09:00:32.004887Z"
    }
   },
   "source": [
    "pos_idx = {\n",
    "    'padding': 0,\n",
    "    'a': 1,\n",
    "    's': 2,\n",
    "    'r': 3,\n",
    "    'v': 4,\n",
    "    'n': 5,\n",
    "    'default': 6\n",
    "}\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hbEa1v1dGIdh",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:32.016674Z",
     "start_time": "2025-01-06T09:00:32.012092Z"
    }
   },
   "source": [
    "def get_pos_weight(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    if not synsets:\n",
    "        return pos_idx['default']\n",
    "    # Use the first synset (most common sense)\n",
    "    pos = synsets[0].pos()\n",
    "    return pos_idx.get(pos, pos_idx['default'])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yWAOVcG5Gf7Y",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:35.595443Z",
     "start_time": "2025-01-06T09:00:32.018595Z"
    }
   },
   "source": [
    "import tqdm\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t93sLB4GfuX"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rW6Q0uArFWm3",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:35.605803Z",
     "start_time": "2025-01-06T09:00:35.597321Z"
    }
   },
   "source": [
    "padding_id = len(word_to_id) \n",
    "\n",
    "def generate_data(word_to_id, definitions, max_gloss_length=15):\n",
    "    \"\"\"\n",
    "    Generate word IDs, gloss IDs, gloss POS IDs, and a mask for padded glosses.\n",
    "\n",
    "    Args:\n",
    "        word_to_id (dict): Mapping from words to unique IDs.\n",
    "        definitions (dict): Dictionary mapping words to their gloss tokens.\n",
    "        max_gloss_length (int): Maximum length of gloss sequences.\n",
    "\n",
    "    Returns:\n",
    "        word_ids (torch.Tensor): Tensor of word IDs (shape: [num_words]).\n",
    "        gloss_ids (torch.Tensor): Padded tensor of gloss IDs (shape: [num_words, max_gloss_length]).\n",
    "        gloss_pos_ids (torch.Tensor): Padded tensor of gloss POS weights (shape: [num_words, max_gloss_length]).\n",
    "        gloss_mask (torch.Tensor): Boolean mask for non-padding tokens (shape: [num_words, max_gloss_length]).\n",
    "    \"\"\"\n",
    "    word_ids_ = []  # List to store word IDs\n",
    "    gloss_ids = []  # List to store gloss token IDs\n",
    "    gloss_pos_ids = []  # List to store gloss POS weights\n",
    "    gloss_masks = []  # List to store masks for padding tokens\n",
    "\n",
    "    for word, id in word_to_id.items():\n",
    "        gloss_tokens = definitions.get(word, [])  # Retrieve gloss tokens for the word\n",
    "        \n",
    "        # Convert gloss tokens to IDs and POS weights, truncated to max_gloss_length\n",
    "        gloss_idx = [word_to_id[token] for token in gloss_tokens][:max_gloss_length]\n",
    "        gloss_pos_idx = [get_pos_weight(token) for token in gloss_tokens][:max_gloss_length]\n",
    "        \n",
    "        # Create a mask for non-padding tokens\n",
    "        mask = [1] * len(gloss_idx)\n",
    "        \n",
    "        # Add padding to gloss_idx, gloss_pos_idx, and mask until max_gloss_length is reached\n",
    "        while len(gloss_idx) < max_gloss_length:\n",
    "            gloss_idx.append(padding_id)\n",
    "            gloss_pos_idx.append(pos_idx['padding'])  # Assuming `pos_idx['padding']` is predefined\n",
    "            mask.append(0)  # Padding positions are 0 in the mask\n",
    "        \n",
    "        word_ids_.append(id)\n",
    "        gloss_ids.append(gloss_idx)\n",
    "        gloss_pos_ids.append(gloss_pos_idx)\n",
    "        gloss_masks.append(mask)\n",
    "\n",
    "    # Convert to tensors\n",
    "    word_ids_ = torch.tensor(word_ids_, dtype=torch.long)  # Shape: [num_words]\n",
    "    gloss_ids = torch.tensor(gloss_ids, dtype=torch.long)  # Shape: [num_words, max_gloss_length]\n",
    "    gloss_pos_ids = torch.tensor(gloss_pos_ids, dtype=torch.long)  # Shape: [num_words, max_gloss_length]\n",
    "    gloss_masks = torch.tensor(gloss_masks, dtype=torch.bool)  # Shape: [num_words, max_gloss_length]\n",
    "\n",
    "    return word_ids_, gloss_ids, gloss_pos_ids, gloss_masks"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:35.615410Z",
     "start_time": "2025-01-06T09:00:35.612553Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:35.626284Z",
     "start_time": "2025-01-06T09:00:35.617922Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LEjgZtv-GX1O",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.474292Z",
     "start_time": "2025-01-06T09:00:35.630354Z"
    }
   },
   "source": "word_ids, gloss_ids, gloss_pos_ids, gloss_masks = generate_data(word_to_id, definitions)",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmcOqr5PGYVN",
    "outputId": "e33d505b-2f30-4161-8e88-7b2d9edf0cc8",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.483921Z",
     "start_time": "2025-01-06T09:00:37.477765Z"
    }
   },
   "source": "word_ids.shape, gloss_ids.shape, gloss_pos_ids.shape, gloss_masks.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4868]),\n",
       " torch.Size([4868, 15]),\n",
       " torch.Size([4868, 15]),\n",
       " torch.Size([4868, 15]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FscCwxlcGxng"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EeOIohOaGpDW",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.493907Z",
     "start_time": "2025-01-06T09:00:37.487550Z"
    }
   },
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 16\n",
    "dataset = TensorDataset(word_ids, gloss_ids, gloss_pos_ids, gloss_masks)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4D8BjiJeG1TI",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.501212Z",
     "start_time": "2025-01-06T09:00:37.496014Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(EmbeddingLayer, self).__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.embedding(x)\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l37OEUIUs0o-",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.508719Z",
     "start_time": "2025-01-06T09:00:37.504287Z"
    }
   },
   "source": [
    "class POSWeighting(nn.Module):\n",
    "  def __init__(self, num_pos):\n",
    "    super(POSWeighting, self).__init__()\n",
    "    self.weights = nn.Embedding(num_pos, 1)\n",
    "\n",
    "  def forward(self, pos_ids, gloss_embeddings):\n",
    "    pos_weights = self.weights(pos_ids)\n",
    "    return pos_weights * gloss_embeddings\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tcFORNDNtObn",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.520261Z",
     "start_time": "2025-01-06T09:00:37.510577Z"
    }
   },
   "source": [
    "class GlossAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(GlossAttention, self).__init__()\n",
    "        self.query = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.key = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.value = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        # Initialize weights with smaller values\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        # Initialize with smaller weights to prevent explosion\n",
    "        for module in [self.query, self.key, self.value]:\n",
    "            nn.init.xavier_uniform_(module.weight, gain=0.1)\n",
    "            nn.init.zeros_(module.bias)\n",
    "            \n",
    "    def forward(self, word_embedding, gloss_embeddings, gloss_mask):\n",
    "        if gloss_embeddings.dim() == 0 or gloss_embeddings.shape[1] == 0:\n",
    "            return word_embedding\n",
    "\n",
    "        # Scale factor for attention scores\n",
    "        scaling_factor = float(self.query.out_features) ** -0.5\n",
    "        \n",
    "        # Compute Q, K, V with gradient clipping\n",
    "        query = torch.clamp(self.query(word_embedding), -100, 100)\n",
    "        key = torch.clamp(self.key(gloss_embeddings), -100, 100)\n",
    "        value = torch.clamp(self.value(gloss_embeddings), -100, 100)\n",
    "\n",
    "        # Calculate attention scores with scaling\n",
    "        attention_scores = torch.bmm(query.unsqueeze(1), key.transpose(1, 2)) * scaling_factor\n",
    "        \n",
    "        # Apply mask if provided\n",
    "        if gloss_mask is not None:\n",
    "            attention_scores = attention_scores.masked_fill(~gloss_mask.unsqueeze(1), -1e9)\n",
    "        \n",
    "        # Apply softmax with numerical stability\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "        \n",
    "        # Add small epsilon to prevent division by zero\n",
    "        attention_weights = attention_weights + 1e-8\n",
    "        \n",
    "        # Check for NaN values\n",
    "        if torch.isnan(attention_weights).any():\n",
    "            print(\"NaN detected in attention weights\")\n",
    "            attention_weights = torch.where(\n",
    "                torch.isnan(attention_weights),\n",
    "                torch.full_like(attention_weights, 1.0 / attention_weights.size(-1)),\n",
    "                attention_weights\n",
    "            )\n",
    "\n",
    "        # Compute final attention\n",
    "        attended_embedding = torch.bmm(attention_weights, value)\n",
    "        \n",
    "        return attended_embedding.squeeze(1)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WVhYa85It0_U",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.529106Z",
     "start_time": "2025-01-06T09:00:37.522277Z"
    }
   },
   "source": [
    "class WordEmbeddingPipeline(nn.Module):\n",
    "  def __init__(self, vocab_size, embedding_dim, num_pos):\n",
    "    super(WordEmbeddingPipeline, self).__init__()\n",
    "    self.embedding_layer = EmbeddingLayer(vocab_size, embedding_dim)\n",
    "    self.pos_weighting = POSWeighting(num_pos)\n",
    "    self.gloss_attention = GlossAttention(embedding_dim)\n",
    "\n",
    "  def forward(self, word_ids_, gloss_ids_, gloss_pos_ids_, gloss_masks_):\n",
    "    word_embeddings_ = self.embedding_layer(word_ids_)\n",
    "    gloss_embeddings = self.embedding_layer(gloss_ids_)\n",
    "\n",
    "    weighted_gloss_embeddings = self.pos_weighting(gloss_pos_ids_, gloss_embeddings)\n",
    "    attended_embeddings_ = self.gloss_attention(word_embeddings_, weighted_gloss_embeddings, gloss_masks_)\n",
    "\n",
    "    return word_embeddings_, attended_embeddings_"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DznWJ37jvKc_",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.537728Z",
     "start_time": "2025-01-06T09:00:37.533396Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "c_DCoS7LzlLv",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:04:02.518709Z",
     "start_time": "2025-01-06T09:04:02.508515Z"
    }
   },
   "source": [
    "num_pos = len(pos_idx)\n",
    "vocab_size = len(word_to_id)\n",
    "embedding_dim = 100\n",
    "\n",
    "\n",
    "model = WordEmbeddingPipeline(vocab_size + 1, embedding_dim, num_pos)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5NIMrB7zn1d",
    "outputId": "6f2d0a3f-7eaf-41dc-dc19-031ee9455730",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:04:03.437649Z",
     "start_time": "2025-01-06T09:04:03.431801Z"
    }
   },
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"devve: \", device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devve:  cpu\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "udQcJ0jz3FgH",
    "outputId": "bbff76aa-73b2-4572-c98f-5459c10012e7",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.582040Z",
     "start_time": "2025-01-06T09:00:37.579290Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.592197Z",
     "start_time": "2025-01-06T09:00:37.584682Z"
    }
   },
   "cell_type": "code",
   "source": "model.eval",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of WordEmbeddingPipeline(\n",
       "  (embedding_layer): EmbeddingLayer(\n",
       "    (embedding): Embedding(4869, 100)\n",
       "  )\n",
       "  (pos_weighting): POSWeighting(\n",
       "    (weights): Embedding(7, 1)\n",
       "  )\n",
       "  (gloss_attention): GlossAttention(\n",
       "    (query): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (key): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (value): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:37.597397Z",
     "start_time": "2025-01-06T09:00:37.593925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import random"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:04:07.063167Z",
     "start_time": "2025-01-06T09:04:07.056742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_negative_samples(word_embeddings, gloss_embeddings, num_rand_sample=1, num_hard_samples=1):\n",
    "    batch_size, embedding_dim = gloss_embeddings.size()\n",
    "\n",
    "    # Random negatives\n",
    "    random_indices = [random.choice(range(batch_size)) for _ in range(batch_size * num_rand_sample)]\n",
    "    random_negatives = gloss_embeddings[random_indices]\n",
    "\n",
    "    # Hard negatives\n",
    "    similarity_scores = torch.matmul(word_embeddings, gloss_embeddings.T)\n",
    "    mask = torch.eye(batch_size, device=similarity_scores.device).bool()  # Exclude positive samples\n",
    "    similarity_scores.masked_fill_(mask, float('-inf'))  # Mask out positives\n",
    "    _, hard_negative_indices = torch.topk(similarity_scores, k=num_hard_samples, dim=-1)\n",
    "    hard_negatives = gloss_embeddings[hard_negative_indices.view(-1)]  # Flatten\n",
    "\n",
    "    # Combine random and hard negatives\n",
    "    mixed_negatives = torch.cat([random_negatives, hard_negatives], dim=0)\n",
    "\n",
    "    return mixed_negatives"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qCxsLCdGuLXK",
    "outputId": "73eb3972-5aa1-4b28-8176-7169d7baef82",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:05:31.611211Z",
     "start_time": "2025-01-06T09:04:10.718765Z"
    }
   },
   "source": [
    "\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=1e-6)\n",
    "\n",
    "patience = 3  # Number of epochs to wait for improvement\n",
    "min_delta = 0.00001 # Minimum change in los to be considered an improvement\n",
    "best_loss = float('inf')  # Initialize best loss to infinity\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "epochs = 250\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  total_loss = 0.0\n",
    "\n",
    "  with tqdm.tqdm(total=vocab_size, desc=f\"Epoch {epoch + 1}/{epochs}\") as pbar:\n",
    "   for words_id, gloss_id, gloss_pos, gloss_mask in dataloader:\n",
    "    words_id = words_id.to(device)\n",
    "    gloss_id = gloss_id.to(device)\n",
    "    gloss_pos = gloss_pos.to(device)\n",
    "    gloss_mask = gloss_mask.to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    word_embeddings, attended_embeddings = model(words_id, gloss_id, gloss_pos, gloss_mask)\n",
    "    \n",
    "    positive_target = torch.ones(word_embeddings.size(0)).to(device)\n",
    "    # \n",
    "    # # Generate mixed negatives\n",
    "    mixed_negatives = generate_negative_samples(word_embeddings, attended_embeddings)\n",
    "    # \n",
    "    # # Compute positive loss\n",
    "    positive_loss = criterion(word_embeddings, attended_embeddings, positive_target)\n",
    "\n",
    "    # Compute negative loss\n",
    "    negative_target = -torch.ones(mixed_negatives.size(0)).to(device)\n",
    "    negative_loss = criterion(word_embeddings.repeat(mixed_negatives.size(0) // word_embeddings.size(0), 1),\n",
    "                                mixed_negatives, negative_target)\n",
    "    # \n",
    "    # loss = criterion(word_embeddings, attended_embeddings)\n",
    "    loss = positive_loss + negative_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    pbar.update(batch_size)\n",
    "    pbar.set_postfix({'Loss': total_loss / (pbar.n + 1)})\n",
    "\n",
    "  avg_loss = total_loss / len(dataloader)\n",
    "  print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss}\")\n",
    "  \n",
    "  scheduler.step()\n",
    "  \n",
    "  if epoch % 10 == 0:\n",
    "      model.eval()\n",
    "      test()\n",
    "\n",
    "  if avg_loss < best_loss - min_delta:\n",
    "      best_loss = avg_loss\n",
    "      epochs_without_improvement = 0\n",
    "  else:\n",
    "      epochs_without_improvement += 1\n",
    "      if epochs_without_improvement >= patience:\n",
    "          print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "          break  # Exit the training loop"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/250: 4880it [00:04, 1050.36it/s, Loss=0.0667]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250, Loss: 1.0671117520723186\n",
      "Best similarity: 0.6911389231681824\n",
      "Worst similarity: -0.4140896201133728\n",
      "Average similarity: 0.003537511718663185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/250: 4880it [00:04, 1091.59it/s, Loss=0.0638]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/250, Loss: 1.0205749261574668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/250: 4880it [00:04, 1071.49it/s, Loss=0.0624]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/250, Loss: 0.9980231758023872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/250: 4880it [00:04, 1113.92it/s, Loss=0.0612]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/250, Loss: 0.9801908475453737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/250: 4880it [00:04, 1058.90it/s, Loss=0.0603]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/250, Loss: 0.9643614315595783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/250: 4880it [00:04, 1063.00it/s, Loss=0.0594]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/250, Loss: 0.951272466925324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/250: 4880it [00:04, 1042.85it/s, Loss=0.0586]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/250, Loss: 0.9385486264697841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/250: 4880it [00:05, 945.37it/s, Loss=0.058]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/250, Loss: 0.9280930943176394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/250: 4880it [00:04, 1052.43it/s, Loss=0.0574]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/250, Loss: 0.917869417980069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/250: 4880it [00:04, 1132.49it/s, Loss=0.0567]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/250, Loss: 0.907073543501682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/250: 4880it [00:04, 1121.07it/s, Loss=0.0558]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/250, Loss: 0.8927434053577361\n",
      "Best similarity: 0.6879138946533203\n",
      "Worst similarity: -0.5489588975906372\n",
      "Average similarity: 0.009452993540603194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/250: 4880it [00:04, 1046.61it/s, Loss=0.0557]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/250, Loss: 0.8910251294980284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/250: 4880it [00:05, 964.59it/s, Loss=0.0557]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/250, Loss: 0.8906578771403578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/250: 4880it [00:04, 1066.17it/s, Loss=0.0558]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/250, Loss: 0.8927439976911076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/250: 4880it [00:04, 997.73it/s, Loss=0.0557]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/250, Loss: 0.8913757062349164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/250: 4880it [00:04, 1140.85it/s, Loss=0.0557]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/250, Loss: 0.8920072162737612\n",
      "Early stopping triggered after 16 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuWFYNBevoDx",
    "outputId": "58378077-e4f1-47b1-a7af-0599831aa2e3",
    "ExecuteTime": {
     "end_time": "2025-01-06T09:00:46.073187Z",
     "start_time": "2025-01-06T09:00:46.072585Z"
    }
   },
   "source": [
    "for param in model.parameters():\n",
    "  print(param)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cc2ncJ3p16Q0"
   },
   "source": "model.eval()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), 'wordnet_based_embeddings.pth')",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:01:13.619005Z",
     "start_time": "2025-01-06T09:01:13.614679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:01:14.252434Z",
     "start_time": "2025-01-06T09:01:14.248173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_word_embeddings(words, word_to_id, model: WordEmbeddingPipeline):\n",
    "    word_ids = [word_to_id[word] for word in words if word in word_to_id]\n",
    "    word_ids = torch.tensor(word_ids)\n",
    "    embeddings = model.embedding_layer.embedding(word_ids).detach().numpy()  # Get embeddings from the model\n",
    "    return embeddings, word_ids"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:01:14.922799Z",
     "start_time": "2025-01-06T09:01:14.918249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_similarity(word1, word2, word_to_id, model):\n",
    "    embeddings, _ = get_word_embeddings([word1, word2], word_to_id, model)\n",
    "    similarity = cosine_similarity(embeddings[0].reshape(1, -1), embeddings[1].reshape(1, -1))[0][0]\n",
    "    return similarity\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:01:15.932090Z",
     "start_time": "2025-01-06T09:01:15.920235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word1 = \"sun\"\n",
    "word2 = \"hot\"\n",
    "similarity = calculate_similarity(word1, word2, word_to_id, model)\n",
    "print(f\"Similarity between '{word1}' and '{word2}': {similarity}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'sun' and 'hot': -0.001956711523234844\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:01:18.607991Z",
     "start_time": "2025-01-06T09:01:18.595049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_word(word, top_k=5):\n",
    "    \"\"\"Predicts the top k most similar words to the given word.\"\"\"\n",
    "\n",
    "    # Get the embedding of the input word\n",
    "    word_embedding = model.embedding_layer.embedding(torch.tensor(word_to_id[word], device=device))\n",
    "\n",
    "    # Calculate cosine similarity with all other words in the vocabulary\n",
    "    similarities = cosine_similarity(word_embedding.cpu().detach().numpy().reshape(1, -1),\n",
    "                                     model.embedding_layer.embedding.weight.cpu().detach().numpy())\n",
    "\n",
    "    # Get the indices of the top k most similar words\n",
    "    top_k_indices = np.argsort(similarities[0])[::-1][1:top_k + 1]  # Exclude the input word itself\n",
    "\n",
    "    # Get the predicted words\n",
    "    predicted_words = [id_to_word[idx] for idx in top_k_indices]\n",
    "\n",
    "    return predicted_words\n",
    "\n",
    "# Example usage:\n",
    "target_word = \"sun\"\n",
    "predicted_words = predict_word(target_word, top_k=10)\n",
    "print(f\"Target word: {target_word}\")\n",
    "print(f\"Predicted words: {predicted_words}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target word: sun\n",
      "Predicted words: ['participation', 'plant', 'onshore', 'reciprocal', 'assumed', 'satisfactorily', 'grant', 'drug', 'medicinal', 'effectively']\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:01:19.583251Z",
     "start_time": "2025-01-06T09:01:19.555122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def check_embedding_quality(word):\n",
    "    # Get the embedding of the input word\n",
    "    word_embedding = model.embedding_layer.embedding(torch.tensor(word_to_id[word], device=device))\n",
    "\n",
    "    # get gloss\n",
    "    gloss = definitions[word]\n",
    "\n",
    "    #calculate the weighted average of the the embeddings of the gloss\n",
    "    gloss_embedding = np.zeros_like(word_embedding.detach().numpy())\n",
    "    total_weight = 0\n",
    "    for token in gloss:\n",
    "        if token in word_to_id:\n",
    "            pos = get_pos_weight(token)\n",
    "            token_embedding = model.embedding_layer.embedding(torch.tensor(word_to_id[token], device=device))\n",
    "            weight = model.pos_weighting.weights(torch.tensor(pos, device=device)).detach().numpy()\n",
    "            gloss_embedding += token_embedding.detach().numpy() * weight\n",
    "            total_weight += weight\n",
    "\n",
    "\n",
    "    gloss_embedding /= total_weight\n",
    "    # print(f'gloss_embedding: {gloss_embedding}')\n",
    "\n",
    "    # print(f'nacho: {word_embedding.cpu().detach().numpy().reshape(1, -1)}')\n",
    "\n",
    "\n",
    "    #check similarity of the word and its gloss embedding\n",
    "    similarity = cosine_similarity(word_embedding.cpu().detach().numpy().reshape(1, -1),\n",
    "                                   gloss_embedding.reshape(1, -1))[0][0]\n",
    "\n",
    "    # print(f'word: {word}')\n",
    "    # print(f'gloss: {gloss}')\n",
    "    # print(f'embedding: {word_embedding}')\n",
    "    # print(word_embedding.shape)\n",
    "    # print(f'gloss_embedding: {gloss_embedding}')\n",
    "    # print(gloss_embedding.shape)\n",
    "    # print(f'similarity: {similarity}')\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "words_to_test = ['valediction', 'retreat', 'breaking_away', 'forced_landing', 'penetration',  'underachievement']\n",
    "\n",
    "for word in words_to_test:\n",
    "    similarity = check_embedding_quality(word)\n",
    "    print(f\"Similarity between '{word}' and its gloss: {similarity}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'valediction' and its gloss: -0.06518992781639099\n",
      "Similarity between 'retreat' and its gloss: 0.044464316219091415\n",
      "Similarity between 'breaking_away' and its gloss: 0.0010470787528902292\n",
      "Similarity between 'forced_landing' and its gloss: -0.11445791274309158\n",
      "Similarity between 'penetration' and its gloss: -0.02045590989291668\n",
      "Similarity between 'underachievement' and its gloss: -0.11939556151628494\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T09:01:20.797166Z",
     "start_time": "2025-01-06T09:01:20.791050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test():\n",
    "    best_sim = float('-inf')\n",
    "    worst_sim = float('inf')\n",
    "    avg_sim = 0\n",
    "    for word in definitions.keys():\n",
    "        similarity = check_embedding_quality(word)\n",
    "        avg_sim += similarity\n",
    "        best_sim = max(best_sim, similarity)\n",
    "        worst_sim = min(worst_sim, similarity)\n",
    "    \n",
    "    avg_sim /= len(definitions)\n",
    "    print(f\"Best similarity: {best_sim}\")\n",
    "    print(f\"Worst similarity: {worst_sim}\")\n",
    "    print(f\"Average similarity: {avg_sim}\")"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "AI_Lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
